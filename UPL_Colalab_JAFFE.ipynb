{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammad-shahid0749/UPL/blob/main/UPL_Colalab_JAFFE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGGfITzA-LZ5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bervRVwHp1Ga",
        "outputId": "938d81d4-52dc-4aeb-da90-b369a322e541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dassl.pytorch'...\n",
            "remote: Enumerating objects: 2477, done.\u001b[K\n",
            "remote: Counting objects: 100% (993/993), done.\u001b[K\n",
            "remote: Compressing objects: 100% (326/326), done.\u001b[K\n",
            "remote: Total 2477 (delta 769), reused 830 (delta 667), pack-reused 1484\u001b[K\n",
            "Receiving objects: 100% (2477/2477), 435.37 KiB | 4.63 MiB/s, done.\n",
            "Resolving deltas: 100% (1650/1650), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/KaiyangZhou/Dassl.pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOKRMs-vvcqN",
        "outputId": "06fdafba-ff37-4b2b-c117-b11ffc1fc7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dassl.pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Dassl.pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0jmafCWxJJ6",
        "outputId": "45138cd4-2d25-4a5a-cfdb-30154e6a99c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dassl.pytorch\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXnuOnMHvnGb",
        "outputId": "23f36c36-1997-46b6-b493-cd643ae45187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEAD is now at ac6e441 leave 2 spaces for comment\n"
          ]
        }
      ],
      "source": [
        "!git reset --hard ac6e44194b2f90e325f477aadd6d9bc3a92ce255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj8kFZCvqTBD",
        "outputId": "ba45acb4-abcc-41c3-c466-703566654fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mâœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRpdZNrDqYUH",
        "outputId": "04a8f709-063a-456d-d199-cceaa0b50dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.14.0\n",
            "  latest version: 22.9.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/dassl\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.7\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge\n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2022.9.24-ha878542_0\n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.39-hc81fddc_0\n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5\n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-12.2.0-h65d4601_19\n",
            "  libgomp            conda-forge/linux-64::libgomp-12.2.0-h65d4601_19\n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.39.4-h753d276_0\n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-12.2.0-h46fd767_19\n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4\n",
            "  ncurses            conda-forge/linux-64::ncurses-6.3-h27087fc_1\n",
            "  openssl            conda-forge/linux-64::openssl-3.0.7-h166bdaf_0\n",
            "  pip                conda-forge/noarch::pip-22.3.1-pyhd8ed1ab_0\n",
            "  python             conda-forge/linux-64::python-3.7.12-hf930737_100_cpython\n",
            "  readline           conda-forge/linux-64::readline-8.1.2-h0f457ee_0\n",
            "  setuptools         conda-forge/noarch::setuptools-65.5.1-pyhd8ed1ab_0\n",
            "  sqlite             conda-forge/linux-64::sqlite-3.39.4-h4ff8645_0\n",
            "  tk                 conda-forge/linux-64::tk-8.6.12-h27826a3_0\n",
            "  wheel              conda-forge/noarch::wheel-0.38.4-pyhd8ed1ab_0\n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0\n",
            "\n",
            "\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate dassl\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "!conda create -n dassl python=3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sxXwdGiItH4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac14fbf9-ea91-4e7c-e84b-5462809af9c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bKCEI-Kmp_L0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b8e863-12d1-4909-a842-d8e38f4da93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda activate dassl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dNdjcMlUtxM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ddd2d7e-437a-4328-d6a7-c320333c69df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ WARNING conda.core.solve:_add_specs(649): pinned spec cudatoolkit=11.2 conflicts with explicit specs.  Overriding pinned spec.\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=10.1\n",
            "    - pytorch==1.8.1\n",
            "    - torchvision==0.9.1\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-4.5          |       2_kmp_llvm           6 KB  conda-forge\n",
            "    blas-2.116                 |              mkl          13 KB  conda-forge\n",
            "    blas-devel-3.9.0           |   16_linux64_mkl          12 KB  conda-forge\n",
            "    certifi-2022.9.24          |     pyhd8ed1ab_0         155 KB  conda-forge\n",
            "    conda-22.9.0               |   py37h89c1867_1         960 KB  conda-forge\n",
            "    cudatoolkit-10.1.243       |      h8cb64d8_10       427.6 MB  conda-forge\n",
            "    freetype-2.12.1            |       hca18f0e_0         884 KB  conda-forge\n",
            "    jpeg-9e                    |       h166bdaf_2         269 KB  conda-forge\n",
            "    lcms2-2.12                 |       hddcbb42_0         443 KB  conda-forge\n",
            "    lerc-3.0                   |       h9c3ff4c_0         216 KB  conda-forge\n",
            "    libblas-3.9.0              |   16_linux64_mkl          13 KB  conda-forge\n",
            "    libcblas-3.9.0             |   16_linux64_mkl          12 KB  conda-forge\n",
            "    libdeflate-1.10            |       h7f98852_0          77 KB  conda-forge\n",
            "    libgfortran-ng-12.2.0      |      h69a702a_19          22 KB  conda-forge\n",
            "    libgfortran5-12.2.0        |      h337968e_19         1.8 MB  conda-forge\n",
            "    liblapack-3.9.0            |   16_linux64_mkl          12 KB  conda-forge\n",
            "    liblapacke-3.9.0           |   16_linux64_mkl          12 KB  conda-forge\n",
            "    libpng-1.6.38              |       h753d276_0         371 KB  conda-forge\n",
            "    libtiff-4.3.0              |       h0fcbabc_4         635 KB  conda-forge\n",
            "    libuv-1.44.2               |       h166bdaf_0         1.0 MB  conda-forge\n",
            "    libwebp-base-1.2.4         |       h166bdaf_0         404 KB  conda-forge\n",
            "    llvm-openmp-15.0.4         |       he0ac6c6_0         5.7 MB  conda-forge\n",
            "    mkl-2022.1.0               |     h84fe81f_915       199.6 MB  conda-forge\n",
            "    mkl-devel-2022.1.0         |     ha770c72_916          25 KB  conda-forge\n",
            "    mkl-include-2022.1.0       |     h84fe81f_915         745 KB  conda-forge\n",
            "    ninja-1.11.0               |       h924138e_0         2.8 MB  conda-forge\n",
            "    numpy-1.21.6               |   py37h976b520_0         6.1 MB  conda-forge\n",
            "    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n",
            "    openssl-1.1.1s             |       h166bdaf_0         2.1 MB  conda-forge\n",
            "    pillow-7.2.0               |   py37h718be6c_2         671 KB  conda-forge\n",
            "    pytorch-1.8.1              |py3.7_cuda10.1_cudnn7.6.3_0       649.3 MB  pytorch\n",
            "    pytorch-cpu-1.1.0          |      py3.7_cpu_0        53.6 MB  pytorch\n",
            "    tbb-2021.6.0               |       h924138e_1         2.0 MB  conda-forge\n",
            "    torchvision-0.9.1          |py37h9e046cd_1_cpu         6.6 MB  conda-forge\n",
            "    typing_extensions-4.4.0    |     pyha770c72_0          29 KB  conda-forge\n",
            "    zlib-1.2.13                |       h166bdaf_4          92 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        1.33 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               conda-forge/linux-64::blas-2.116-mkl\n",
            "  blas-devel         conda-forge/linux-64::blas-devel-3.9.0-16_linux64_mkl\n",
            "  cudatoolkit        conda-forge/linux-64::cudatoolkit-10.1.243-h8cb64d8_10\n",
            "  freetype           conda-forge/linux-64::freetype-2.12.1-hca18f0e_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9e-h166bdaf_2\n",
            "  lcms2              conda-forge/linux-64::lcms2-2.12-hddcbb42_0\n",
            "  lerc               conda-forge/linux-64::lerc-3.0-h9c3ff4c_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-16_linux64_mkl\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-16_linux64_mkl\n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.10-h7f98852_0\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-12.2.0-h69a702a_19\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-12.2.0-h337968e_19\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-16_linux64_mkl\n",
            "  liblapacke         conda-forge/linux-64::liblapacke-3.9.0-16_linux64_mkl\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.38-h753d276_0\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.3.0-h0fcbabc_4\n",
            "  libuv              conda-forge/linux-64::libuv-1.44.2-h166bdaf_0\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.2.4-h166bdaf_0\n",
            "  llvm-openmp        conda-forge/linux-64::llvm-openmp-15.0.4-he0ac6c6_0\n",
            "  mkl                conda-forge/linux-64::mkl-2022.1.0-h84fe81f_915\n",
            "  mkl-devel          conda-forge/linux-64::mkl-devel-2022.1.0-ha770c72_916\n",
            "  mkl-include        conda-forge/linux-64::mkl-include-2022.1.0-h84fe81f_915\n",
            "  ninja              conda-forge/linux-64::ninja-1.11.0-h924138e_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.21.6-py37h976b520_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n",
            "  pillow             conda-forge/linux-64::pillow-7.2.0-py37h718be6c_2\n",
            "  pytorch            pytorch/linux-64::pytorch-1.8.1-py3.7_cuda10.1_cudnn7.6.3_0\n",
            "  pytorch-cpu        pytorch/linux-64::pytorch-cpu-1.1.0-py3.7_cpu_0\n",
            "  tbb                conda-forge/linux-64::tbb-2021.6.0-h924138e_1\n",
            "  torchvision        conda-forge/linux-64::torchvision-0.9.1-py37h9e046cd_1_cpu\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.4.0-pyha770c72_0\n",
            "  zlib               conda-forge/linux-64::zlib-1.2.13-h166bdaf_4\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                      2022.6.15-ha878542_0 --> 2022.9.24-ha878542_0\n",
            "  certifi            conda-forge/linux-64::certifi-2022.6.~ --> conda-forge/noarch::certifi-2022.9.24-pyhd8ed1ab_0\n",
            "  conda                               4.14.0-py37h89c1867_0 --> 22.9.0-py37h89c1867_1\n",
            "  libzlib                                 1.2.12-h166bdaf_2 --> 1.2.13-h166bdaf_4\n",
            "  openssl                                 1.1.1q-h166bdaf_0 --> 1.1.1s-h166bdaf_0\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-2_kmp_llvm\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "olefile-0.46         | 32 KB     | : 100% 1.0/1 [00:00<00:00,  5.81it/s]                \n",
            "mkl-devel-2022.1.0   | 25 KB     | : 100% 1.0/1 [00:00<00:00,  8.38it/s]               \n",
            "libwebp-base-1.2.4   | 404 KB    | : 100% 1.0/1 [00:00<00:00,  2.27it/s]               \n",
            "lerc-3.0             | 216 KB    | : 100% 1.0/1 [00:00<00:00,  6.01it/s]               \n",
            "conda-22.9.0         | 960 KB    | : 100% 1.0/1 [00:00<00:00,  4.37it/s]\n",
            "mkl-include-2022.1.0 | 745 KB    | : 100% 1.0/1 [00:00<00:00,  2.25it/s]\n",
            "mkl-2022.1.0         | 199.6 MB  | : 100% 1.0/1 [00:36<00:00, 36.69s/it]               \n",
            "libuv-1.44.2         | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  5.93it/s]\n",
            "libpng-1.6.38        | 371 KB    | : 100% 1.0/1 [00:00<00:00, 10.92it/s]\n",
            "libdeflate-1.10      | 77 KB     | : 100% 1.0/1 [00:00<00:00,  6.64it/s]                \n",
            "libcblas-3.9.0       | 12 KB     | : 100% 1.0/1 [00:00<00:00,  9.09it/s]\n",
            "_openmp_mutex-4.5    | 6 KB      | : 100% 1.0/1 [00:00<00:00,  8.67it/s]\n",
            "cudatoolkit-10.1.243 | 427.6 MB  | : 100% 1.0/1 [00:49<00:00, 49.87s/it]               \n",
            "zlib-1.2.13          | 92 KB     | : 100% 1.0/1 [00:00<00:00, 22.07it/s]\n",
            "openssl-1.1.1s       | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.36it/s]\n",
            "numpy-1.21.6         | 6.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.09s/it]\n",
            "libblas-3.9.0        | 13 KB     | : 100% 1.0/1 [00:00<00:00,  7.49it/s]\n",
            "lcms2-2.12           | 443 KB    | : 100% 1.0/1 [00:00<00:00,  2.59it/s]\n",
            "libgfortran5-12.2.0  | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.38it/s]\n",
            "blas-devel-3.9.0     | 12 KB     | : 100% 1.0/1 [00:00<00:00,  7.68it/s]\n",
            "torchvision-0.9.1    | 6.6 MB    | : 100% 1.0/1 [00:00<00:00,  1.01it/s]\n",
            "jpeg-9e              | 269 KB    | : 100% 1.0/1 [00:00<00:00,  2.01it/s]               \n",
            "blas-2.116           | 13 KB     | : 100% 1.0/1 [00:00<00:00,  7.76it/s]\n",
            "pytorch-cpu-1.1.0    | 53.6 MB   | : 100% 1.0/1 [00:10<00:00, 10.39s/it]\n",
            "liblapack-3.9.0      | 12 KB     | : 100% 1.0/1 [00:00<00:00,  7.88it/s]\n",
            "certifi-2022.9.24    | 155 KB    | : 100% 1.0/1 [00:00<00:00, 17.12it/s]\n",
            "libgfortran-ng-12.2. | 22 KB     | : 100% 1.0/1 [00:00<00:00, 28.73it/s]\n",
            "typing_extensions-4. | 29 KB     | : 100% 1.0/1 [00:00<00:00, 24.25it/s]\n",
            "libtiff-4.3.0        | 635 KB    | : 100% 1.0/1 [00:00<00:00,  2.64it/s]\n",
            "pytorch-1.8.1        | 649.3 MB  | : 100% 1.0/1 [01:28<00:00, 88.40s/it]               \n",
            "tbb-2021.6.0         | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.47it/s]\n",
            "liblapacke-3.9.0     | 12 KB     | : 100% 1.0/1 [00:00<00:00,  8.96it/s]\n",
            "pillow-7.2.0         | 671 KB    | : 100% 1.0/1 [00:00<00:00,  3.30it/s]\n",
            "freetype-2.12.1      | 884 KB    | : 100% 1.0/1 [00:00<00:00,  2.36it/s]\n",
            "llvm-openmp-15.0.4   | 5.7 MB    | : 100% 1.0/1 [00:00<00:00,  1.34it/s]\n",
            "ninja-1.11.0         | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.19it/s]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "!conda install pytorch==1.8.1 torchvision==0.9.1 cudatoolkit=10.1 -c pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "70-SE7HVrrYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd6d06d-4d4f-484f-ec95-917f9072b185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dassl.pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Dassl.pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "amKERbdMtGRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8595f798-01f7-47e4-9e3b-3fc52fd6eee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dassl.pytorch\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BwRIH_BHt3Hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5529b8d-65c8-4d58-efc8-68e160659c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running develop\n",
            "/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py:147: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "  EasyInstallDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "  setuptools.SetuptoolsDeprecationWarning,\n",
            "running egg_info\n",
            "creating dassl.egg-info\n",
            "writing dassl.egg-info/PKG-INFO\n",
            "writing dependency_links to dassl.egg-info/dependency_links.txt\n",
            "writing requirements to dassl.egg-info/requires.txt\n",
            "writing top-level names to dassl.egg-info/top_level.txt\n",
            "writing manifest file 'dassl.egg-info/SOURCES.txt'\n",
            "reading manifest file 'dassl.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'dassl.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.7/site-packages/dassl.egg-link (link to .)\n",
            "Adding dassl 0.4.3 to easy-install.pth file\n",
            "\n",
            "Installed /content/Dassl.pytorch\n",
            "Processing dependencies for dassl==0.4.3\n",
            "Searching for scikit-learn\n",
            "Reading https://pypi.org/simple/scikit-learn/\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.9 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning:  is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.10 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.11 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.12 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.12.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.13 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.13.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.14 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.14.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.15.0b1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.15.0b2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.15.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.15.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.15.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.16b1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.16.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.16.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.17b1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.17 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.17.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.18rc2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.18 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.18.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.18.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.19b2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.19.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.19.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.19.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20rc1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20.3 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20.4 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.21rc2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.21.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.21.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.21.3 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.22rc2.post1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.22rc3 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.22 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.22.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.22.2.post1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.23.0rc1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.23.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.23.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.23.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.24.dev0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.24.0rc1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.24.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.24.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.24.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.0rc1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.0rc2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.0.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.0.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.1.0rc1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.1.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.1.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.1.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.1.3 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "Downloading https://files.pythonhosted.org/packages/38/bc/319f789ce0988d9bf1379d6e40498dc119b30bec133bf76cd82ca549b69a/scikit-learn-1.1.3.tar.gz#sha256=bef51978a51ec19977700fe7b86aecea49c825884f3811756b74a3b152bb4e35\n",
            "Best match: scikit-learn 1.1.3\n",
            "Processing scikit-learn-1.1.3.tar.gz\n",
            "Writing /tmp/easy_install-cdpnsye8/scikit-learn-1.1.3/setup.cfg\n",
            "Running scikit-learn-1.1.3/setup.py -q bdist_egg --dist-dir /tmp/easy_install-cdpnsye8/scikit-learn-1.1.3/egg-dist-tmp-b4de9kzl\n",
            "Partial import of sklearn during the build process.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 156, in save_modules\n",
            "    yield saved\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 198, in setup_context\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 259, in run_setup\n",
            "    _execfile(setup_script, ns)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 46, in _execfile\n",
            "    exec(code, globals, locals)\n",
            "  File \"/tmp/easy_install-cdpnsye8/scikit-learn-1.1.3/setup.py\", line 330, in <module>\n",
            "  File \"/tmp/easy_install-cdpnsye8/scikit-learn-1.1.3/setup.py\", line 301, in setup_package\n",
            "RuntimeError: Scikit-learn requires Python 3.8 or later. The current Python version is 3.7.12 installed in /usr/local/bin/python.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"setup.py\", line 46, in <module>\n",
            "    'Semi-Supervised Learning', 'Pytorch'\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
            "    return distutils.core.setup(**attrs)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
            "    return run_commands(dist)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
            "    dist.run_commands()\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 973, in run_commands\n",
            "    self.run_command(cmd)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
            "    super().run_command(command)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 992, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/develop.py\", line 34, in run\n",
            "    self.install_for_development()\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/develop.py\", line 129, in install_for_development\n",
            "    self.process_distribution(None, self.dist, not self.no_deps)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 755, in process_distribution\n",
            "    [requirement], self.local_index, self.easy_install\n",
            "  File \"/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 791, in resolve\n",
            "    replace_conflicting=replace_conflicting\n",
            "  File \"/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 1075, in best_match\n",
            "    return self.obtain(req, installer)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 1087, in obtain\n",
            "    return installer(requirement)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 681, in easy_install\n",
            "    return self.install_item(spec, dist.location, tmpdir, deps)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 707, in install_item\n",
            "    dists = self.install_eggs(spec, download, tmpdir)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 900, in install_eggs\n",
            "    return self.build_and_install(setup_script, setup_base)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 1174, in build_and_install\n",
            "    self.run_setup(setup_script, setup_base, args)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 1158, in run_setup\n",
            "    run_setup(setup_script, args)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 262, in run_setup\n",
            "    raise\n",
            "  File \"/usr/local/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 198, in setup_context\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 169, in save_modules\n",
            "    saved_exc.resume()\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 143, in resume\n",
            "    raise exc.with_traceback(self._tb)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 156, in save_modules\n",
            "    yield saved\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 198, in setup_context\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 259, in run_setup\n",
            "    _execfile(setup_script, ns)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 46, in _execfile\n",
            "    exec(code, globals, locals)\n",
            "  File \"/tmp/easy_install-cdpnsye8/scikit-learn-1.1.3/setup.py\", line 330, in <module>\n",
            "  File \"/tmp/easy_install-cdpnsye8/scikit-learn-1.1.3/setup.py\", line 301, in setup_package\n",
            "RuntimeError: Scikit-learn requires Python 3.8 or later. The current Python version is 3.7.12 installed in /usr/local/bin/python.\n"
          ]
        }
      ],
      "source": [
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vJIhk7HmzU9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e462ce-0096-44fe-d2af-33b1a5ba7950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Duedm9M5zYBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbabdbca-f1e5-4eb9-caca-7e797be66bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4I6OP0D8pgFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec19db1-7089-437c-df23-400ceb73d730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UPL'...\n",
            "remote: Enumerating objects: 36871, done.\u001b[K\n",
            "remote: Counting objects: 100% (271/271), done.\u001b[K\n",
            "remote: Compressing objects: 100% (257/257), done.\u001b[K\n",
            "remote: Total 36871 (delta 18), reused 257 (delta 11), pack-reused 36600\u001b[K\n",
            "Receiving objects: 100% (36871/36871), 924.24 MiB | 34.80 MiB/s, done.\n",
            "Resolving deltas: 100% (3736/3736), done.\n",
            "Checking out files: 100% (44025/44025), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/muhammad-shahid0749/UPL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5AjygzxZt-zs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5040570d-7ba0-48e2-b638-03c269d7a472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL\n"
          ]
        }
      ],
      "source": [
        "%cd UPL/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XlD9z1iL3icu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7de40fb-f8d5-40f7-850c-9bb4d5cb3831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dwzZY852uA7l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "fad75adb-e7ba-4cce-aa6e-55242de6ac92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex\n",
            "  Downloading regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m757.1/757.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (4.64.0)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wcwidth>=0.2.5\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.21.6)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (7.2.0)\n",
            "Collecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->-r requirements.txt (line 4)) (4.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 4)) (1.16.0)\n",
            "Installing collected packages: wcwidth, regex, python-dateutil, pyparsing, kiwisolver, ftfy, fonttools, cycler, packaging, matplotlib\n",
            "Successfully installed cycler-0.11.0 fonttools-4.38.0 ftfy-6.1.1 kiwisolver-1.4.4 matplotlib-3.5.3 packaging-21.3 pyparsing-3.0.9 python-dateutil-2.8.2 regex-2022.10.31 wcwidth-0.2.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "kiwisolver",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IU7YLTuTuFFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68d75df-f2f8-47fd-9f3d-6ab2e98b69f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RSEPoeV7Am0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4beb315-ffd4-4e05-e74d-00b874115fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyYAML, yacs\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dassl 0.4.3 requires flake8==3.7.9, which is not installed.\n",
            "dassl 0.4.3 requires future, which is not installed.\n",
            "dassl 0.4.3 requires gdown, which is not installed.\n",
            "dassl 0.4.3 requires isort==4.3.21, which is not installed.\n",
            "dassl 0.4.3 requires scikit-learn, which is not installed.\n",
            "dassl 0.4.3 requires scipy, which is not installed.\n",
            "dassl 0.4.3 requires tb-nightly, which is not installed.\n",
            "dassl 0.4.3 requires yapf==0.29.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0 yacs-0.1.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install yacs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mf4L0TugARWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895c025f-4072-4fb0-c2ba-3a41549e4208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vDz0DuYvuYcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0686f665-3fa4-4c39-e3bf-7dcdcbbe6b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL/scripts\n"
          ]
        }
      ],
      "source": [
        "%cd /content/UPL/scripts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "i2RwHBeJA2rS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab5d0245-46df-4294-87c6-e28ed95b1ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboard\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<4,>=3.9.2\n",
            "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard) (2.28.1)\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/site-packages (from tensorboard) (1.21.6)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=0.4\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard) (65.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/site-packages (from tensorboard) (0.37.1)\n",
            "Collecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.50.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.10.0-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.4.0)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, zipp, tensorboard-data-server, rsa, pyasn1-modules, protobuf, oauthlib, MarkupSafe, grpcio, cachetools, absl-py, werkzeug, requests-oauthlib, importlib-metadata, google-auth, markdown, google-auth-oauthlib, tensorboard\n",
            "Successfully installed MarkupSafe-2.1.1 absl-py-1.3.0 cachetools-5.2.0 google-auth-2.14.1 google-auth-oauthlib-0.4.6 grpcio-1.50.0 importlib-metadata-5.0.0 markdown-3.4.1 oauthlib-3.2.2 protobuf-3.20.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.2.2 zipp-3.10.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "saSnPtg9A6Zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b414080f-b0dd-4a45-e0d9-ee5daebb075b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.5.3.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/site-packages (from gdown) (2.28.1)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.5.3-py3-none-any.whl size=14821 sha256=d2644a5f3306c4db71dd58d5598f92c7a6949340236fa1815fa2474a7fa2cae2\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/8d/0b/bdcd83555c3555f91a33f6c2384428d9f163c7d75ab0d272b4\n",
            "Successfully built gdown\n",
            "Installing collected packages: soupsieve, filelock, beautifulsoup4, gdown\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dassl 0.4.3 requires flake8==3.7.9, which is not installed.\n",
            "dassl 0.4.3 requires future, which is not installed.\n",
            "dassl 0.4.3 requires isort==4.3.21, which is not installed.\n",
            "dassl 0.4.3 requires scikit-learn, which is not installed.\n",
            "dassl 0.4.3 requires scipy, which is not installed.\n",
            "dassl 0.4.3 requires tb-nightly, which is not installed.\n",
            "dassl 0.4.3 requires yapf==0.29.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beautifulsoup4-4.11.1 filelock-3.8.0 gdown-4.5.3 soupsieve-2.3.2.post1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "htlY-GeoBJ5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1628cdb2-a95a-4efd-d3a2-9c2545c856b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2936 sha256=0f3b85c0441de2528763344f621e9c0474f118829fd02431667ae84333e53ff7\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZE_Oa_qpBKDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68333df3-02d9-4991-8269-9641cbca05a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL/scripts\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JX5Hds58Biqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d353b1bc-83fb-482c-bdbe-7b27e1de5065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lANRo5sQBlYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d8cc08-fb1d-4e34-d447-d0d9ce6ecc7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pLyRVwzqCPga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95e2af5-9a84-4429-f4f6-be2d34e6ee18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=0.11\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.1.0\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.21.6)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dassl 0.4.3 requires flake8==3.7.9, which is not installed.\n",
            "dassl 0.4.3 requires future, which is not installed.\n",
            "dassl 0.4.3 requires isort==4.3.21, which is not installed.\n",
            "dassl 0.4.3 requires tb-nightly, which is not installed.\n",
            "dassl 0.4.3 requires yapf==0.29.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed joblib-1.2.0 scikit-learn-1.0.2 scipy-1.7.3 threadpoolctl-3.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "psX_qMATB1AN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7a7d40-5b20-4b98-d8b8-38abb62d696b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL/scripts\n"
          ]
        }
      ],
      "source": [
        "%cd /content/UPL/scripts/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/UPL/datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpmdv9ujAX9u",
        "outputId": "26aae7dd-4342-4c85-b449-28b72162b1e4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python jaffe.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEB-nHINAeMM",
        "outputId": "1963d292-f192-4ca2-ebc2-b31c141a410c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in jaffe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/UPL/scripts/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy9zONe1BAtg",
        "outputId": "c023ec9f-bec3-4766-ea09-cceb611c0530"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL/scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "QpuMOZrMudS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61fbb8fb-03a4-4f59-c17a-9f1ffcf7ea47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/anay_rn50_-1shots_random_init/nctx16_cscFalse_ctpend/seed1\n",
            "in jaffe\n",
            "Setting fixed seed: 1\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/anay_rn50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '-1']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/anay_rn50_-1shots_random_init/nctx16_cscFalse_ctpend/seed1\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 1\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: -1\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: []\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/anay_rn50_-1shots_random_init/nctx16_cscFalse_ctpend/seed1\n",
            "RESUME: \n",
            "SEED: 1\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: a photo of a\n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Splitting into 50% train, 20% val, and 30% test\n",
            "Saved split to /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256M/256M [00:03<00:00, 77.5MiB/s]\n",
            "Building custom CLIP\n",
            "Initial context: \"a photo of a\"\n",
            "Number of context words (tokens): 4\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "4it [00:02,  1.34it/s]\n",
            "image_features torch.Size([107, 1024])\n",
            "text_features torch.Size([7, 1024])\n",
            "100% 7/7 [00:00<00:00, 1888.23it/s]\n",
            "Acc Rate 0.4766\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 bash get_info.sh ssjaffe anay_rn50 end 16 -1 False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "9xr2tgRBrA70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0cce2a9-0b5c-4934-ad9e-36cf471e5d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run this job and save the output to ./output/ssoxford_pets/UPLTrainer/anay_rn50_-1shots_random_init/nctx16_cscFalse_ctpmiddle/seed1\n",
            "in jaffe\n",
            "Setting fixed seed: 1\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/anay_rn50.yaml\n",
            "dataset_config_file: configs/datasets/ssoxford_pets.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'middle', 'DATASET.NUM_SHOTS', '-1']\n",
            "output_dir: ./output/ssoxford_pets/UPLTrainer/anay_rn50_-1shots_random_init/nctx16_cscFalse_ctpmiddle/seed1\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 1\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSOxfordPets\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: -1\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: []\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssoxford_pets/UPLTrainer/anay_rn50_-1shots_random_init/nctx16_cscFalse_ctpmiddle/seed1\n",
            "RESUME: \n",
            "SEED: 1\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: middle\n",
            "    CSC: False\n",
            "    CTX_INIT: a photo of a\n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSOxfordPets\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSOxfordPets\n",
            "  # classes: 37\n",
            "  # train_x: 2,944\n",
            "  # val: 736\n",
            "  # test: 3,669\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initial context: \"a photo of a\"\n",
            "Number of context words (tokens): 4\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "92it [00:21,  4.20it/s]\n",
            "image_features torch.Size([2944, 1024])\n",
            "text_features torch.Size([37, 1024])\n",
            "100% 37/37 [00:00<00:00, 455.05it/s]\n",
            "Acc Rate 0.7796\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 bash get_info.sh ssoxford_pets anay_rn50 middle 16 -1 False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Kj6QxMrPu5tS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98a2441-f8e0-4377-b03d-04de0297562e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mæµå¼è¾“å‡ºå†…å®¹è¢«æˆªæ–­ï¼Œåªèƒ½æ˜¾ç¤ºæœ€åŽ 5000 è¡Œå†…å®¹ã€‚\u001b[0m\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 14101.89it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed4/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.774 (1.774)\tdata 0.567 (0.567)\teta 0:02:55\tloss 2.2109 (2.2109)\tacc 12.5000 (12.5000)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.062 (0.918)\tdata 0.000 (0.284)\teta 0:01:29\tloss 1.9727 (2.0918)\tacc 12.5000 (12.5000)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.584 (0.584)\tdata 0.522 (0.522)\teta 0:00:56\tloss 1.9404 (1.9404)\tacc 21.8750 (21.8750)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.063 (0.324)\tdata 0.000 (0.261)\teta 0:00:31\tloss 1.8691 (1.9048)\tacc 31.2500 (26.5625)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.597 (0.597)\tdata 0.535 (0.535)\teta 0:00:56\tloss 1.7666 (1.7666)\tacc 31.2500 (31.2500)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.065 (0.331)\tdata 0.000 (0.268)\teta 0:00:31\tloss 1.9385 (1.8525)\tacc 18.7500 (25.0000)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.599 (0.599)\tdata 0.537 (0.537)\teta 0:00:55\tloss 1.7129 (1.7129)\tacc 40.6250 (40.6250)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.065 (0.332)\tdata 0.000 (0.269)\teta 0:00:30\tloss 1.6201 (1.6665)\tacc 56.2500 (48.4375)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.577 (0.577)\tdata 0.514 (0.514)\teta 0:00:52\tloss 1.5693 (1.5693)\tacc 50.0000 (50.0000)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.065 (0.321)\tdata 0.001 (0.258)\teta 0:00:28\tloss 1.4639 (1.5166)\tacc 59.3750 (54.6875)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.585 (0.585)\tdata 0.510 (0.510)\teta 0:00:52\tloss 1.3164 (1.3164)\tacc 56.2500 (56.2500)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.073 (0.329)\tdata 0.000 (0.255)\teta 0:00:28\tloss 1.6621 (1.4893)\tacc 34.3750 (45.3125)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.591 (0.591)\tdata 0.528 (0.528)\teta 0:00:51\tloss 1.2461 (1.2461)\tacc 56.2500 (56.2500)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:28\tloss 1.4043 (1.3252)\tacc 46.8750 (51.5625)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.584 (0.584)\tdata 0.522 (0.522)\teta 0:00:49\tloss 1.2715 (1.2715)\tacc 50.0000 (50.0000)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.063 (0.323)\tdata 0.000 (0.261)\teta 0:00:27\tloss 1.2061 (1.2388)\tacc 56.2500 (53.1250)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.592 (0.592)\tdata 0.530 (0.530)\teta 0:00:49\tloss 1.1514 (1.1514)\tacc 65.6250 (65.6250)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.065 (0.328)\tdata 0.000 (0.265)\teta 0:00:26\tloss 1.3174 (1.2344)\tacc 56.2500 (60.9375)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.584 (0.584)\tdata 0.522 (0.522)\teta 0:00:47\tloss 0.9834 (0.9834)\tacc 68.7500 (68.7500)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.067 (0.325)\tdata 0.000 (0.261)\teta 0:00:26\tloss 1.0518 (1.0176)\tacc 56.2500 (62.5000)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.589 (0.589)\tdata 0.526 (0.526)\teta 0:00:46\tloss 1.1885 (1.1885)\tacc 56.2500 (56.2500)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.263)\teta 0:00:25\tloss 1.2715 (1.2300)\tacc 50.0000 (53.1250)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.573 (0.573)\tdata 0.511 (0.511)\teta 0:00:44\tloss 1.0420 (1.0420)\tacc 62.5000 (62.5000)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.063 (0.318)\tdata 0.000 (0.256)\teta 0:00:24\tloss 1.1816 (1.1118)\tacc 46.8750 (54.6875)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.593 (0.593)\tdata 0.530 (0.530)\teta 0:00:44\tloss 0.7734 (0.7734)\tacc 71.8750 (71.8750)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.265)\teta 0:00:24\tloss 1.0518 (0.9126)\tacc 53.1250 (62.5000)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.592 (0.592)\tdata 0.530 (0.530)\teta 0:00:43\tloss 0.9336 (0.9336)\tacc 71.8750 (71.8750)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.063 (0.328)\tdata 0.000 (0.265)\teta 0:00:23\tloss 1.1055 (1.0195)\tacc 59.3750 (65.6250)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.587 (0.587)\tdata 0.524 (0.524)\teta 0:00:41\tloss 1.0195 (1.0195)\tacc 62.5000 (62.5000)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.262)\teta 0:00:22\tloss 1.0137 (1.0166)\tacc 65.6250 (64.0625)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.582 (0.582)\tdata 0.518 (0.518)\teta 0:00:40\tloss 0.9707 (0.9707)\tacc 71.8750 (71.8750)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.259)\teta 0:00:21\tloss 1.1133 (1.0420)\tacc 53.1250 (62.5000)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.584 (0.584)\tdata 0.520 (0.520)\teta 0:00:39\tloss 1.0322 (1.0322)\tacc 59.3750 (59.3750)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.260)\teta 0:00:21\tloss 0.9282 (0.9802)\tacc 68.7500 (64.0625)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.588 (0.588)\tdata 0.525 (0.525)\teta 0:00:38\tloss 0.8521 (0.8521)\tacc 75.0000 (75.0000)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.263)\teta 0:00:20\tloss 0.8120 (0.8320)\tacc 68.7500 (71.8750)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.589 (0.589)\tdata 0.526 (0.526)\teta 0:00:37\tloss 1.0020 (1.0020)\tacc 65.6250 (65.6250)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.066 (0.327)\tdata 0.000 (0.263)\teta 0:00:20\tloss 0.9443 (0.9731)\tacc 68.7500 (67.1875)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.569 (0.569)\tdata 0.505 (0.505)\teta 0:00:34\tloss 1.0479 (1.0479)\tacc 59.3750 (59.3750)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.063 (0.316)\tdata 0.000 (0.253)\teta 0:00:18\tloss 0.7998 (0.9238)\tacc 71.8750 (65.6250)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.578 (0.578)\tdata 0.515 (0.515)\teta 0:00:34\tloss 0.9702 (0.9702)\tacc 62.5000 (62.5000)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.258)\teta 0:00:18\tloss 0.8423 (0.9062)\tacc 65.6250 (64.0625)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.581 (0.581)\tdata 0.519 (0.519)\teta 0:00:33\tloss 0.8335 (0.8335)\tacc 71.8750 (71.8750)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.260)\teta 0:00:18\tloss 0.8750 (0.8542)\tacc 68.7500 (70.3125)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.594 (0.594)\tdata 0.532 (0.532)\teta 0:00:32\tloss 0.9102 (0.9102)\tacc 65.6250 (65.6250)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.064 (0.329)\tdata 0.000 (0.266)\teta 0:00:17\tloss 1.1357 (1.0229)\tacc 56.2500 (60.9375)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.794 (0.794)\tdata 0.726 (0.726)\teta 0:00:42\tloss 0.9165 (0.9165)\tacc 71.8750 (71.8750)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.078 (0.436)\tdata 0.001 (0.363)\teta 0:00:22\tloss 0.7891 (0.8528)\tacc 68.7500 (70.3125)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.893 (0.893)\tdata 0.822 (0.822)\teta 0:00:45\tloss 0.9575 (0.9575)\tacc 62.5000 (62.5000)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.067 (0.480)\tdata 0.000 (0.411)\teta 0:00:24\tloss 0.8149 (0.8862)\tacc 68.7500 (65.6250)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.871 (0.871)\tdata 0.786 (0.786)\teta 0:00:42\tloss 0.8901 (0.8901)\tacc 68.7500 (68.7500)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.077 (0.474)\tdata 0.011 (0.398)\teta 0:00:22\tloss 1.0400 (0.9651)\tacc 65.6250 (67.1875)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.956 (0.956)\tdata 0.888 (0.888)\teta 0:00:44\tloss 0.8169 (0.8169)\tacc 75.0000 (75.0000)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.069 (0.512)\tdata 0.001 (0.444)\teta 0:00:23\tloss 0.9355 (0.8762)\tacc 68.7500 (71.8750)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.984 (0.984)\tdata 0.903 (0.903)\teta 0:00:44\tloss 0.8472 (0.8472)\tacc 75.0000 (75.0000)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.079 (0.531)\tdata 0.000 (0.452)\teta 0:00:23\tloss 0.8789 (0.8630)\tacc 71.8750 (73.4375)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.820 (0.820)\tdata 0.713 (0.713)\teta 0:00:35\tloss 0.8628 (0.8628)\tacc 68.7500 (68.7500)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.066 (0.443)\tdata 0.000 (0.356)\teta 0:00:18\tloss 0.6978 (0.7803)\tacc 81.2500 (75.0000)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.923 (0.923)\tdata 0.837 (0.837)\teta 0:00:37\tloss 0.7539 (0.7539)\tacc 78.1250 (78.1250)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.083 (0.503)\tdata 0.000 (0.419)\teta 0:00:20\tloss 0.7329 (0.7434)\tacc 81.2500 (79.6875)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.906 (0.906)\tdata 0.837 (0.837)\teta 0:00:35\tloss 0.7534 (0.7534)\tacc 78.1250 (78.1250)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.068 (0.487)\tdata 0.000 (0.419)\teta 0:00:18\tloss 0.9194 (0.8364)\tacc 71.8750 (75.0000)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.767 (0.767)\tdata 0.634 (0.634)\teta 0:00:28\tloss 0.8794 (0.8794)\tacc 71.8750 (71.8750)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.065 (0.416)\tdata 0.000 (0.317)\teta 0:00:14\tloss 0.6196 (0.7495)\tacc 75.0000 (73.4375)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.795 (0.795)\tdata 0.702 (0.702)\teta 0:00:27\tloss 0.9976 (0.9976)\tacc 62.5000 (62.5000)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.142 (0.469)\tdata 0.061 (0.381)\teta 0:00:15\tloss 0.7944 (0.8960)\tacc 75.0000 (68.7500)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.760 (0.760)\tdata 0.659 (0.659)\teta 0:00:25\tloss 0.6484 (0.6484)\tacc 78.1250 (78.1250)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.083 (0.422)\tdata 0.000 (0.330)\teta 0:00:13\tloss 0.8579 (0.7532)\tacc 68.7500 (73.4375)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.594 (0.594)\tdata 0.523 (0.523)\teta 0:00:18\tloss 0.9429 (0.9429)\tacc 62.5000 (62.5000)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.068 (0.331)\tdata 0.000 (0.261)\teta 0:00:09\tloss 0.8335 (0.8882)\tacc 81.2500 (71.8750)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.576 (0.576)\tdata 0.505 (0.505)\teta 0:00:16\tloss 0.6709 (0.6709)\tacc 84.3750 (84.3750)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.067 (0.322)\tdata 0.000 (0.253)\teta 0:00:09\tloss 0.7666 (0.7188)\tacc 78.1250 (81.2500)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.591 (0.591)\tdata 0.512 (0.512)\teta 0:00:15\tloss 0.7959 (0.7959)\tacc 81.2500 (81.2500)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.079 (0.335)\tdata 0.000 (0.256)\teta 0:00:08\tloss 0.7363 (0.7661)\tacc 71.8750 (76.5625)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.589 (0.589)\tdata 0.523 (0.523)\teta 0:00:14\tloss 0.7554 (0.7554)\tacc 65.6250 (65.6250)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.261)\teta 0:00:07\tloss 0.7109 (0.7332)\tacc 75.0000 (70.3125)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.599 (0.599)\tdata 0.535 (0.535)\teta 0:00:13\tloss 0.9189 (0.9189)\tacc 68.7500 (68.7500)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.063 (0.331)\tdata 0.000 (0.268)\teta 0:00:07\tloss 0.7710 (0.8450)\tacc 78.1250 (73.4375)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.581 (0.581)\tdata 0.519 (0.519)\teta 0:00:12\tloss 0.7803 (0.7803)\tacc 65.6250 (65.6250)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.065 (0.323)\tdata 0.000 (0.260)\teta 0:00:06\tloss 0.9912 (0.8857)\tacc 56.2500 (60.9375)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.577 (0.577)\tdata 0.514 (0.514)\teta 0:00:10\tloss 0.7461 (0.7461)\tacc 71.8750 (71.8750)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.064 (0.320)\tdata 0.000 (0.257)\teta 0:00:05\tloss 0.8301 (0.7881)\tacc 59.3750 (65.6250)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.573 (0.573)\tdata 0.508 (0.508)\teta 0:00:09\tloss 0.7319 (0.7319)\tacc 78.1250 (78.1250)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.063 (0.318)\tdata 0.000 (0.254)\teta 0:00:05\tloss 0.8833 (0.8076)\tacc 71.8750 (75.0000)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.581 (0.581)\tdata 0.518 (0.518)\teta 0:00:08\tloss 0.6084 (0.6084)\tacc 78.1250 (78.1250)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.259)\teta 0:00:04\tloss 0.7886 (0.6985)\tacc 78.1250 (78.1250)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.588 (0.588)\tdata 0.526 (0.526)\teta 0:00:07\tloss 0.5269 (0.5269)\tacc 81.2500 (81.2500)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.063 (0.325)\tdata 0.000 (0.263)\teta 0:00:03\tloss 0.8037 (0.6653)\tacc 62.5000 (71.8750)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.593 (0.593)\tdata 0.529 (0.529)\teta 0:00:06\tloss 0.9170 (0.9170)\tacc 62.5000 (62.5000)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.265)\teta 0:00:03\tloss 0.8267 (0.8718)\tacc 68.7500 (65.6250)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.582 (0.582)\tdata 0.517 (0.517)\teta 0:00:05\tloss 0.8540 (0.8540)\tacc 68.7500 (68.7500)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.063 (0.323)\tdata 0.000 (0.259)\teta 0:00:02\tloss 0.9854 (0.9197)\tacc 59.3750 (64.0625)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.576 (0.576)\tdata 0.514 (0.514)\teta 0:00:04\tloss 0.6318 (0.6318)\tacc 81.2500 (81.2500)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.063 (0.320)\tdata 0.000 (0.257)\teta 0:00:01\tloss 0.8730 (0.7524)\tacc 71.8750 (76.5625)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.594 (0.594)\tdata 0.531 (0.531)\teta 0:00:02\tloss 0.7471 (0.7471)\tacc 78.1250 (78.1250)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.063 (0.329)\tdata 0.000 (0.266)\teta 0:00:01\tloss 0.4932 (0.6201)\tacc 81.2500 (79.6875)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.594 (0.594)\tdata 0.531 (0.531)\teta 0:00:01\tloss 0.7788 (0.7788)\tacc 75.0000 (75.0000)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.064 (0.329)\tdata 0.000 (0.266)\teta 0:00:00\tloss 0.6655 (0.7222)\tacc 81.2500 (78.1250)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.573 (0.573)\tdata 0.509 (0.509)\teta 0:00:00\tloss 0.5571 (0.5571)\tacc 84.3750 (84.3750)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.065 (0.319)\tdata 0.000 (0.255)\teta 0:00:00\tloss 0.9214 (0.7393)\tacc 68.7500 (76.5625)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed4/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 33\n",
            "* accuracy: 51.56%\n",
            "* error: 48.44%\n",
            "* macro_f1: 45.34%\n",
            "=> per-class result\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 6\tacc: 66.67%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 4\tacc: 44.44%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* average: 52.38%\n",
            "Elapsed: 0:00:49\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed5\n",
            "in jaffe\n",
            "Setting fixed seed: 5\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed5\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 5\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed5\n",
            "RESUME: \n",
            "SEED: 5\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 18442.29it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed5/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.778 (1.778)\tdata 0.565 (0.565)\teta 0:02:55\tloss 1.9658 (1.9658)\tacc 12.5000 (12.5000)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.062 (0.920)\tdata 0.000 (0.283)\teta 0:01:30\tloss 1.9131 (1.9395)\tacc 21.8750 (17.1875)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.591 (0.591)\tdata 0.529 (0.529)\teta 0:00:57\tloss 1.8877 (1.8877)\tacc 28.1250 (28.1250)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.063 (0.327)\tdata 0.000 (0.264)\teta 0:00:31\tloss 1.8184 (1.8530)\tacc 50.0000 (39.0625)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.608 (0.608)\tdata 0.545 (0.545)\teta 0:00:57\tloss 1.7539 (1.7539)\tacc 43.7500 (43.7500)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.065 (0.337)\tdata 0.000 (0.273)\teta 0:00:31\tloss 1.8242 (1.7891)\tacc 25.0000 (34.3750)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.572 (0.572)\tdata 0.510 (0.510)\teta 0:00:53\tloss 1.6045 (1.6045)\tacc 40.6250 (40.6250)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.065 (0.319)\tdata 0.000 (0.255)\teta 0:00:29\tloss 1.4023 (1.5034)\tacc 50.0000 (45.3125)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.575 (0.575)\tdata 0.511 (0.511)\teta 0:00:52\tloss 1.4414 (1.4414)\tacc 43.7500 (43.7500)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.063 (0.319)\tdata 0.000 (0.256)\teta 0:00:28\tloss 1.5400 (1.4907)\tacc 31.2500 (37.5000)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.589 (0.589)\tdata 0.526 (0.526)\teta 0:00:52\tloss 1.3125 (1.3125)\tacc 59.3750 (59.3750)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.263)\teta 0:00:28\tloss 1.0869 (1.1997)\tacc 65.6250 (62.5000)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.612 (0.612)\tdata 0.549 (0.549)\teta 0:00:53\tloss 1.2314 (1.2314)\tacc 53.1250 (53.1250)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.063 (0.337)\tdata 0.000 (0.275)\teta 0:00:29\tloss 1.0488 (1.1401)\tacc 62.5000 (57.8125)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.815 (0.815)\tdata 0.736 (0.736)\teta 0:01:09\tloss 1.2109 (1.2109)\tacc 65.6250 (65.6250)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.077 (0.446)\tdata 0.001 (0.368)\teta 0:00:37\tloss 1.3818 (1.2964)\tacc 46.8750 (56.2500)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.918 (0.918)\tdata 0.853 (0.853)\teta 0:01:16\tloss 1.2266 (1.2266)\tacc 53.1250 (53.1250)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.065 (0.491)\tdata 0.000 (0.427)\teta 0:00:40\tloss 1.0635 (1.1450)\tacc 65.6250 (59.3750)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.957 (0.957)\tdata 0.870 (0.870)\teta 0:01:17\tloss 1.1748 (1.1748)\tacc 59.3750 (59.3750)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.085 (0.521)\tdata 0.001 (0.435)\teta 0:00:41\tloss 1.3965 (1.2856)\tacc 43.7500 (51.5625)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.887 (0.887)\tdata 0.817 (0.817)\teta 0:01:10\tloss 0.9219 (0.9219)\tacc 75.0000 (75.0000)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.066 (0.477)\tdata 0.001 (0.409)\teta 0:00:37\tloss 1.2432 (1.0825)\tacc 65.6250 (70.3125)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.908 (0.908)\tdata 0.839 (0.839)\teta 0:01:09\tloss 1.1846 (1.1846)\tacc 56.2500 (56.2500)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.069 (0.488)\tdata 0.001 (0.420)\teta 0:00:37\tloss 0.9971 (1.0908)\tacc 62.5000 (59.3750)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.881 (0.881)\tdata 0.814 (0.814)\teta 0:01:06\tloss 1.1992 (1.1992)\tacc 50.0000 (50.0000)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.067 (0.474)\tdata 0.001 (0.407)\teta 0:00:35\tloss 1.2168 (1.2080)\tacc 50.0000 (50.0000)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.925 (0.925)\tdata 0.857 (0.857)\teta 0:01:07\tloss 0.9507 (0.9507)\tacc 65.6250 (65.6250)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.067 (0.496)\tdata 0.000 (0.429)\teta 0:00:35\tloss 0.9961 (0.9734)\tacc 71.8750 (68.7500)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.820 (0.820)\tdata 0.728 (0.728)\teta 0:00:58\tloss 1.0146 (1.0146)\tacc 65.6250 (65.6250)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.110 (0.465)\tdata 0.032 (0.380)\teta 0:00:32\tloss 1.0332 (1.0239)\tacc 65.6250 (65.6250)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.943 (0.943)\tdata 0.840 (0.840)\teta 0:01:05\tloss 1.2920 (1.2920)\tacc 50.0000 (50.0000)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.100 (0.522)\tdata 0.000 (0.420)\teta 0:00:35\tloss 0.9756 (1.1338)\tacc 62.5000 (56.2500)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.816 (0.816)\tdata 0.746 (0.746)\teta 0:00:54\tloss 0.9497 (0.9497)\tacc 65.6250 (65.6250)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.068 (0.442)\tdata 0.001 (0.373)\teta 0:00:29\tloss 0.8047 (0.8772)\tacc 71.8750 (68.7500)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.652 (0.652)\tdata 0.584 (0.584)\teta 0:00:42\tloss 0.8433 (0.8433)\tacc 68.7500 (68.7500)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.063 (0.358)\tdata 0.000 (0.292)\teta 0:00:22\tloss 1.3193 (1.0813)\tacc 46.8750 (57.8125)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.573 (0.573)\tdata 0.508 (0.508)\teta 0:00:36\tloss 0.6479 (0.6479)\tacc 78.1250 (78.1250)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.063 (0.318)\tdata 0.000 (0.254)\teta 0:00:19\tloss 0.8599 (0.7539)\tacc 71.8750 (75.0000)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.578 (0.578)\tdata 0.513 (0.513)\teta 0:00:35\tloss 0.9888 (0.9888)\tacc 68.7500 (68.7500)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.257)\teta 0:00:19\tloss 0.8916 (0.9402)\tacc 68.7500 (68.7500)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.582 (0.582)\tdata 0.517 (0.517)\teta 0:00:34\tloss 0.8618 (0.8618)\tacc 75.0000 (75.0000)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.064 (0.323)\tdata 0.001 (0.259)\teta 0:00:18\tloss 1.0244 (0.9431)\tacc 59.3750 (67.1875)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.594 (0.594)\tdata 0.532 (0.532)\teta 0:00:33\tloss 0.7173 (0.7173)\tacc 84.3750 (84.3750)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.064 (0.329)\tdata 0.000 (0.266)\teta 0:00:18\tloss 0.5562 (0.6367)\tacc 81.2500 (82.8125)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.578 (0.578)\tdata 0.510 (0.510)\teta 0:00:31\tloss 0.6948 (0.6948)\tacc 75.0000 (75.0000)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.255)\teta 0:00:17\tloss 0.9644 (0.8296)\tacc 65.6250 (70.3125)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.597 (0.597)\tdata 0.534 (0.534)\teta 0:00:31\tloss 0.5811 (0.5811)\tacc 81.2500 (81.2500)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.063 (0.330)\tdata 0.000 (0.267)\teta 0:00:17\tloss 1.0889 (0.8350)\tacc 53.1250 (67.1875)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.573 (0.573)\tdata 0.509 (0.509)\teta 0:00:29\tloss 0.8916 (0.8916)\tacc 65.6250 (65.6250)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.065 (0.319)\tdata 0.000 (0.255)\teta 0:00:15\tloss 0.6177 (0.7546)\tacc 78.1250 (71.8750)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.597 (0.597)\tdata 0.533 (0.533)\teta 0:00:29\tloss 0.8169 (0.8169)\tacc 78.1250 (78.1250)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.063 (0.330)\tdata 0.000 (0.267)\teta 0:00:15\tloss 0.6821 (0.7495)\tacc 78.1250 (78.1250)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.594 (0.594)\tdata 0.532 (0.532)\teta 0:00:27\tloss 0.8911 (0.8911)\tacc 65.6250 (65.6250)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.064 (0.329)\tdata 0.000 (0.266)\teta 0:00:15\tloss 0.7100 (0.8005)\tacc 78.1250 (71.8750)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.608 (0.608)\tdata 0.546 (0.546)\teta 0:00:27\tloss 0.9399 (0.9399)\tacc 71.8750 (71.8750)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.063 (0.336)\tdata 0.000 (0.273)\teta 0:00:14\tloss 0.7588 (0.8494)\tacc 68.7500 (70.3125)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.592 (0.592)\tdata 0.524 (0.524)\teta 0:00:25\tloss 0.7295 (0.7295)\tacc 78.1250 (78.1250)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.063 (0.328)\tdata 0.000 (0.262)\teta 0:00:13\tloss 1.0576 (0.8936)\tacc 50.0000 (64.0625)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.581 (0.581)\tdata 0.517 (0.517)\teta 0:00:23\tloss 0.7227 (0.7227)\tacc 75.0000 (75.0000)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.258)\teta 0:00:12\tloss 0.9502 (0.8364)\tacc 68.7500 (71.8750)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.587 (0.587)\tdata 0.524 (0.524)\teta 0:00:22\tloss 0.7183 (0.7183)\tacc 81.2500 (81.2500)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.262)\teta 0:00:12\tloss 0.7588 (0.7385)\tacc 78.1250 (79.6875)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.586 (0.586)\tdata 0.524 (0.524)\teta 0:00:21\tloss 0.6367 (0.6367)\tacc 75.0000 (75.0000)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.063 (0.324)\tdata 0.000 (0.262)\teta 0:00:11\tloss 1.0420 (0.8394)\tacc 68.7500 (71.8750)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.613 (0.613)\tdata 0.550 (0.550)\teta 0:00:21\tloss 0.8604 (0.8604)\tacc 71.8750 (71.8750)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.063 (0.338)\tdata 0.000 (0.275)\teta 0:00:11\tloss 0.8311 (0.8457)\tacc 75.0000 (73.4375)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.585 (0.585)\tdata 0.522 (0.522)\teta 0:00:19\tloss 0.6382 (0.6382)\tacc 84.3750 (84.3750)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.067 (0.326)\tdata 0.000 (0.261)\teta 0:00:10\tloss 0.8315 (0.7349)\tacc 75.0000 (79.6875)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.578 (0.578)\tdata 0.516 (0.516)\teta 0:00:17\tloss 0.7856 (0.7856)\tacc 75.0000 (75.0000)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.065 (0.321)\tdata 0.000 (0.258)\teta 0:00:09\tloss 0.9854 (0.8855)\tacc 59.3750 (67.1875)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.605 (0.605)\tdata 0.542 (0.542)\teta 0:00:17\tloss 0.9629 (0.9629)\tacc 65.6250 (65.6250)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.271)\teta 0:00:09\tloss 0.8882 (0.9255)\tacc 68.7500 (67.1875)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.588 (0.588)\tdata 0.523 (0.523)\teta 0:00:15\tloss 1.0049 (1.0049)\tacc 65.6250 (65.6250)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.262)\teta 0:00:08\tloss 0.7969 (0.9009)\tacc 78.1250 (71.8750)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.623 (0.623)\tdata 0.550 (0.550)\teta 0:00:15\tloss 0.7124 (0.7124)\tacc 75.0000 (75.0000)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.071 (0.347)\tdata 0.000 (0.275)\teta 0:00:08\tloss 0.5493 (0.6309)\tacc 81.2500 (78.1250)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.566 (0.566)\tdata 0.501 (0.501)\teta 0:00:13\tloss 0.7427 (0.7427)\tacc 75.0000 (75.0000)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.064 (0.315)\tdata 0.000 (0.251)\teta 0:00:06\tloss 0.7036 (0.7231)\tacc 71.8750 (73.4375)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.565 (0.565)\tdata 0.502 (0.502)\teta 0:00:11\tloss 0.7168 (0.7168)\tacc 75.0000 (75.0000)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.064 (0.315)\tdata 0.000 (0.251)\teta 0:00:06\tloss 0.7173 (0.7170)\tacc 71.8750 (73.4375)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.572 (0.572)\tdata 0.506 (0.506)\teta 0:00:10\tloss 0.5518 (0.5518)\tacc 75.0000 (75.0000)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.063 (0.317)\tdata 0.000 (0.253)\teta 0:00:05\tloss 0.8643 (0.7080)\tacc 68.7500 (71.8750)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.581 (0.581)\tdata 0.518 (0.518)\teta 0:00:09\tloss 0.8052 (0.8052)\tacc 71.8750 (71.8750)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.065 (0.323)\tdata 0.000 (0.259)\teta 0:00:05\tloss 0.5835 (0.6943)\tacc 84.3750 (78.1250)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.586 (0.586)\tdata 0.522 (0.522)\teta 0:00:08\tloss 0.9834 (0.9834)\tacc 65.6250 (65.6250)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.063 (0.325)\tdata 0.000 (0.261)\teta 0:00:04\tloss 0.6401 (0.8118)\tacc 81.2500 (73.4375)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.587 (0.587)\tdata 0.522 (0.522)\teta 0:00:07\tloss 0.6758 (0.6758)\tacc 62.5000 (62.5000)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.261)\teta 0:00:03\tloss 0.8413 (0.7585)\tacc 65.6250 (64.0625)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.569 (0.569)\tdata 0.504 (0.504)\teta 0:00:06\tloss 0.5801 (0.5801)\tacc 78.1250 (78.1250)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.063 (0.316)\tdata 0.000 (0.252)\teta 0:00:03\tloss 0.5879 (0.5840)\tacc 81.2500 (79.6875)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.570 (0.570)\tdata 0.507 (0.507)\teta 0:00:05\tloss 0.7480 (0.7480)\tacc 68.7500 (68.7500)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.066 (0.318)\tdata 0.000 (0.254)\teta 0:00:02\tloss 0.4949 (0.6215)\tacc 84.3750 (76.5625)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.582 (0.582)\tdata 0.511 (0.511)\teta 0:00:04\tloss 0.7109 (0.7109)\tacc 78.1250 (78.1250)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.071 (0.327)\tdata 0.000 (0.256)\teta 0:00:01\tloss 0.6646 (0.6877)\tacc 75.0000 (76.5625)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.610 (0.610)\tdata 0.527 (0.527)\teta 0:00:03\tloss 0.8799 (0.8799)\tacc 68.7500 (68.7500)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.082 (0.346)\tdata 0.000 (0.264)\teta 0:00:01\tloss 0.7158 (0.7979)\tacc 75.0000 (71.8750)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.607 (0.607)\tdata 0.542 (0.542)\teta 0:00:01\tloss 0.8008 (0.8008)\tacc 71.8750 (71.8750)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.063 (0.335)\tdata 0.000 (0.271)\teta 0:00:00\tloss 0.6191 (0.7100)\tacc 81.2500 (76.5625)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.589 (0.589)\tdata 0.526 (0.526)\teta 0:00:00\tloss 0.7207 (0.7207)\tacc 75.0000 (75.0000)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.063 (0.326)\tdata 0.000 (0.263)\teta 0:00:00\tloss 0.8325 (0.7766)\tacc 68.7500 (71.8750)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed5/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 28\n",
            "* accuracy: 43.75%\n",
            "* error: 56.25%\n",
            "* macro_f1: 38.02%\n",
            "=> per-class result\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* average: 44.44%\n",
            "Elapsed: 0:00:49\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed6\n",
            "in jaffe\n",
            "Setting fixed seed: 6\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed6\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 6\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed6\n",
            "RESUME: \n",
            "SEED: 6\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 16266.00it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed6/tensorboard\n",
            "epoch [1/50][1/2]\ttime 2.174 (2.174)\tdata 0.748 (0.748)\teta 0:03:35\tloss 1.9863 (1.9863)\tacc 6.2500 (6.2500)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.067 (1.120)\tdata 0.001 (0.374)\teta 0:01:49\tloss 1.9756 (1.9810)\tacc 3.1250 (4.6875)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.653 (0.653)\tdata 0.590 (0.590)\teta 0:01:03\tloss 2.0273 (2.0273)\tacc 6.2500 (6.2500)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.064 (0.358)\tdata 0.000 (0.295)\teta 0:00:34\tloss 1.9004 (1.9639)\tacc 37.5000 (21.8750)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.605 (0.605)\tdata 0.543 (0.543)\teta 0:00:57\tloss 1.8467 (1.8467)\tacc 37.5000 (37.5000)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.272)\teta 0:00:31\tloss 1.8330 (1.8398)\tacc 25.0000 (31.2500)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.591 (0.591)\tdata 0.527 (0.527)\teta 0:00:54\tloss 1.7764 (1.7764)\tacc 43.7500 (43.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.063 (0.327)\tdata 0.000 (0.264)\teta 0:00:30\tloss 1.6670 (1.7217)\tacc 59.3750 (51.5625)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.596 (0.596)\tdata 0.533 (0.533)\teta 0:00:54\tloss 1.7090 (1.7090)\tacc 34.3750 (34.3750)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:29\tloss 1.3936 (1.5513)\tacc 59.3750 (46.8750)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.590 (0.590)\tdata 0.524 (0.524)\teta 0:00:52\tloss 1.7002 (1.7002)\tacc 34.3750 (34.3750)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.064 (0.327)\tdata 0.001 (0.262)\teta 0:00:28\tloss 1.5693 (1.6348)\tacc 40.6250 (37.5000)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.575 (0.575)\tdata 0.508 (0.508)\teta 0:00:49\tloss 1.4619 (1.4619)\tacc 43.7500 (43.7500)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.062 (0.318)\tdata 0.000 (0.254)\teta 0:00:27\tloss 1.2188 (1.3403)\tacc 78.1250 (60.9375)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.581 (0.581)\tdata 0.505 (0.505)\teta 0:00:49\tloss 1.1191 (1.1191)\tacc 68.7500 (68.7500)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.073 (0.327)\tdata 0.000 (0.253)\teta 0:00:27\tloss 1.1807 (1.1499)\tacc 59.3750 (64.0625)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.592 (0.592)\tdata 0.524 (0.524)\teta 0:00:49\tloss 1.1318 (1.1318)\tacc 68.7500 (68.7500)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.067 (0.330)\tdata 0.000 (0.262)\teta 0:00:27\tloss 1.2461 (1.1890)\tacc 59.3750 (64.0625)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.584 (0.584)\tdata 0.520 (0.520)\teta 0:00:47\tloss 1.1748 (1.1748)\tacc 68.7500 (68.7500)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.260)\teta 0:00:25\tloss 1.2002 (1.1875)\tacc 65.6250 (67.1875)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.582 (0.582)\tdata 0.516 (0.516)\teta 0:00:45\tloss 1.0420 (1.0420)\tacc 56.2500 (56.2500)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.258)\teta 0:00:25\tloss 1.0068 (1.0244)\tacc 68.7500 (62.5000)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.587 (0.587)\tdata 0.523 (0.523)\teta 0:00:45\tloss 0.9966 (0.9966)\tacc 68.7500 (68.7500)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.261)\teta 0:00:24\tloss 0.9766 (0.9866)\tacc 59.3750 (64.0625)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.572 (0.572)\tdata 0.508 (0.508)\teta 0:00:42\tloss 1.3145 (1.3145)\tacc 53.1250 (53.1250)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.254)\teta 0:00:23\tloss 1.0977 (1.2061)\tacc 68.7500 (60.9375)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.592 (0.592)\tdata 0.530 (0.530)\teta 0:00:43\tloss 1.1641 (1.1641)\tacc 53.1250 (53.1250)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.265)\teta 0:00:23\tloss 0.8154 (0.9897)\tacc 75.0000 (64.0625)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.582 (0.582)\tdata 0.520 (0.520)\teta 0:00:41\tloss 1.0518 (1.0518)\tacc 56.2500 (56.2500)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.073 (0.328)\tdata 0.000 (0.260)\teta 0:00:22\tloss 1.0684 (1.0601)\tacc 59.3750 (57.8125)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.565 (0.565)\tdata 0.501 (0.501)\teta 0:00:38\tloss 0.8828 (0.8828)\tacc 75.0000 (75.0000)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.063 (0.314)\tdata 0.000 (0.250)\teta 0:00:21\tloss 1.0205 (0.9517)\tacc 78.1250 (76.5625)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.587 (0.587)\tdata 0.525 (0.525)\teta 0:00:39\tloss 0.9321 (0.9321)\tacc 62.5000 (62.5000)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.063 (0.325)\tdata 0.000 (0.263)\teta 0:00:21\tloss 1.0410 (0.9866)\tacc 62.5000 (62.5000)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.577 (0.577)\tdata 0.515 (0.515)\teta 0:00:37\tloss 0.9712 (0.9712)\tacc 68.7500 (68.7500)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.063 (0.320)\tdata 0.000 (0.258)\teta 0:00:20\tloss 0.8232 (0.8972)\tacc 75.0000 (71.8750)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.571 (0.571)\tdata 0.507 (0.507)\teta 0:00:35\tloss 1.0312 (1.0312)\tacc 62.5000 (62.5000)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.064 (0.317)\tdata 0.000 (0.254)\teta 0:00:19\tloss 1.0596 (1.0454)\tacc 56.2500 (59.3750)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.597 (0.597)\tdata 0.534 (0.534)\teta 0:00:36\tloss 0.7896 (0.7896)\tacc 71.8750 (71.8750)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:19\tloss 0.9414 (0.8655)\tacc 65.6250 (68.7500)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.570 (0.570)\tdata 0.507 (0.507)\teta 0:00:33\tloss 1.0098 (1.0098)\tacc 62.5000 (62.5000)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.064 (0.317)\tdata 0.000 (0.253)\teta 0:00:18\tloss 0.7197 (0.8647)\tacc 84.3750 (73.4375)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.579 (0.579)\tdata 0.517 (0.517)\teta 0:00:33\tloss 0.7061 (0.7061)\tacc 78.1250 (78.1250)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.063 (0.321)\tdata 0.000 (0.259)\teta 0:00:17\tloss 0.9810 (0.8435)\tacc 65.6250 (71.8750)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.581 (0.581)\tdata 0.519 (0.519)\teta 0:00:31\tloss 0.6670 (0.6670)\tacc 84.3750 (84.3750)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.260)\teta 0:00:17\tloss 0.9717 (0.8193)\tacc 62.5000 (73.4375)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.593 (0.593)\tdata 0.530 (0.530)\teta 0:00:31\tloss 1.0586 (1.0586)\tacc 62.5000 (62.5000)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.063 (0.328)\tdata 0.000 (0.265)\teta 0:00:17\tloss 0.9390 (0.9988)\tacc 71.8750 (67.1875)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.597 (0.597)\tdata 0.524 (0.524)\teta 0:00:30\tloss 1.0342 (1.0342)\tacc 59.3750 (59.3750)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.072 (0.334)\tdata 0.000 (0.262)\teta 0:00:16\tloss 0.9321 (0.9832)\tacc 68.7500 (64.0625)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.594 (0.594)\tdata 0.530 (0.530)\teta 0:00:29\tloss 0.8589 (0.8589)\tacc 68.7500 (68.7500)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.063 (0.329)\tdata 0.000 (0.265)\teta 0:00:15\tloss 0.8779 (0.8684)\tacc 71.8750 (70.3125)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.583 (0.583)\tdata 0.519 (0.519)\teta 0:00:27\tloss 0.9302 (0.9302)\tacc 75.0000 (75.0000)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.260)\teta 0:00:14\tloss 0.7427 (0.8364)\tacc 75.0000 (75.0000)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.577 (0.577)\tdata 0.515 (0.515)\teta 0:00:25\tloss 1.0352 (1.0352)\tacc 59.3750 (59.3750)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.063 (0.320)\tdata 0.000 (0.258)\teta 0:00:14\tloss 0.8667 (0.9509)\tacc 56.2500 (57.8125)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.609 (0.609)\tdata 0.547 (0.547)\teta 0:00:26\tloss 0.9097 (0.9097)\tacc 59.3750 (59.3750)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.063 (0.336)\tdata 0.000 (0.274)\teta 0:00:14\tloss 0.8550 (0.8823)\tacc 62.5000 (60.9375)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.585 (0.585)\tdata 0.521 (0.521)\teta 0:00:23\tloss 0.6636 (0.6636)\tacc 81.2500 (81.2500)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.065 (0.325)\tdata 0.000 (0.261)\teta 0:00:13\tloss 0.9692 (0.8164)\tacc 59.3750 (70.3125)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.602 (0.602)\tdata 0.540 (0.540)\teta 0:00:23\tloss 0.8286 (0.8286)\tacc 78.1250 (78.1250)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.063 (0.332)\tdata 0.000 (0.270)\teta 0:00:12\tloss 0.6753 (0.7520)\tacc 84.3750 (81.2500)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.579 (0.579)\tdata 0.517 (0.517)\teta 0:00:21\tloss 0.6372 (0.6372)\tacc 78.1250 (78.1250)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.259)\teta 0:00:11\tloss 0.9536 (0.7954)\tacc 68.7500 (73.4375)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.598 (0.598)\tdata 0.535 (0.535)\teta 0:00:20\tloss 0.7358 (0.7358)\tacc 68.7500 (68.7500)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.063 (0.331)\tdata 0.000 (0.268)\teta 0:00:11\tloss 0.7119 (0.7239)\tacc 71.8750 (70.3125)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.616 (0.616)\tdata 0.552 (0.552)\teta 0:00:20\tloss 0.6504 (0.6504)\tacc 71.8750 (71.8750)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.065 (0.341)\tdata 0.000 (0.276)\teta 0:00:10\tloss 0.9077 (0.7791)\tacc 68.7500 (70.3125)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.584 (0.584)\tdata 0.522 (0.522)\teta 0:00:18\tloss 0.9429 (0.9429)\tacc 68.7500 (68.7500)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.261)\teta 0:00:09\tloss 0.7349 (0.8389)\tacc 75.0000 (71.8750)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.595 (0.595)\tdata 0.531 (0.531)\teta 0:00:17\tloss 0.9922 (0.9922)\tacc 75.0000 (75.0000)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.265)\teta 0:00:09\tloss 0.7222 (0.8572)\tacc 71.8750 (73.4375)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.603 (0.603)\tdata 0.522 (0.522)\teta 0:00:16\tloss 0.9961 (0.9961)\tacc 53.1250 (53.1250)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.065 (0.334)\tdata 0.000 (0.261)\teta 0:00:08\tloss 0.6763 (0.8362)\tacc 71.8750 (62.5000)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.862 (0.862)\tdata 0.777 (0.777)\teta 0:00:21\tloss 0.7935 (0.7935)\tacc 68.7500 (68.7500)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.064 (0.463)\tdata 0.000 (0.389)\teta 0:00:11\tloss 1.0996 (0.9465)\tacc 53.1250 (60.9375)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.950 (0.950)\tdata 0.883 (0.883)\teta 0:00:21\tloss 1.0166 (1.0166)\tacc 65.6250 (65.6250)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.066 (0.508)\tdata 0.001 (0.442)\teta 0:00:11\tloss 0.7686 (0.8926)\tacc 75.0000 (70.3125)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.937 (0.937)\tdata 0.869 (0.869)\teta 0:00:19\tloss 0.9663 (0.9663)\tacc 68.7500 (68.7500)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.068 (0.502)\tdata 0.000 (0.435)\teta 0:00:10\tloss 0.8813 (0.9238)\tacc 75.0000 (71.8750)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.972 (0.972)\tdata 0.895 (0.895)\teta 0:00:18\tloss 0.6094 (0.6094)\tacc 81.2500 (81.2500)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.066 (0.519)\tdata 0.000 (0.447)\teta 0:00:09\tloss 1.0674 (0.8384)\tacc 71.8750 (76.5625)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.934 (0.934)\tdata 0.838 (0.838)\teta 0:00:15\tloss 0.9126 (0.9126)\tacc 71.8750 (71.8750)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.139 (0.537)\tdata 0.071 (0.455)\teta 0:00:08\tloss 0.5571 (0.7349)\tacc 81.2500 (76.5625)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 1.034 (1.034)\tdata 0.941 (0.941)\teta 0:00:15\tloss 0.7676 (0.7676)\tacc 71.8750 (71.8750)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.089 (0.561)\tdata 0.001 (0.471)\teta 0:00:07\tloss 0.7700 (0.7688)\tacc 75.0000 (73.4375)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.965 (0.965)\tdata 0.882 (0.882)\teta 0:00:12\tloss 0.8120 (0.8120)\tacc 71.8750 (71.8750)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.076 (0.520)\tdata 0.001 (0.442)\teta 0:00:06\tloss 0.6763 (0.7441)\tacc 78.1250 (75.0000)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 1.021 (1.021)\tdata 0.918 (0.918)\teta 0:00:11\tloss 0.8350 (0.8350)\tacc 71.8750 (71.8750)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.087 (0.554)\tdata 0.001 (0.460)\teta 0:00:05\tloss 0.7314 (0.7832)\tacc 81.2500 (76.5625)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.993 (0.993)\tdata 0.906 (0.906)\teta 0:00:08\tloss 0.6411 (0.6411)\tacc 81.2500 (81.2500)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.077 (0.535)\tdata 0.001 (0.453)\teta 0:00:04\tloss 0.7803 (0.7107)\tacc 65.6250 (73.4375)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.975 (0.975)\tdata 0.900 (0.900)\teta 0:00:06\tloss 0.7998 (0.7998)\tacc 81.2500 (81.2500)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.073 (0.524)\tdata 0.001 (0.450)\teta 0:00:03\tloss 0.8916 (0.8457)\tacc 71.8750 (76.5625)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.877 (0.877)\tdata 0.803 (0.803)\teta 0:00:04\tloss 0.6997 (0.6997)\tacc 87.5000 (87.5000)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.066 (0.471)\tdata 0.001 (0.402)\teta 0:00:01\tloss 0.5737 (0.6367)\tacc 84.3750 (85.9375)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.903 (0.903)\tdata 0.834 (0.834)\teta 0:00:02\tloss 0.8740 (0.8740)\tacc 68.7500 (68.7500)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.067 (0.485)\tdata 0.000 (0.417)\teta 0:00:00\tloss 0.7920 (0.8330)\tacc 75.0000 (71.8750)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.822 (0.822)\tdata 0.753 (0.753)\teta 0:00:00\tloss 0.8848 (0.8848)\tacc 75.0000 (75.0000)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.069 (0.446)\tdata 0.001 (0.377)\teta 0:00:00\tloss 0.9536 (0.9192)\tacc 65.6250 (70.3125)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed6/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 28\n",
            "* accuracy: 43.75%\n",
            "* error: 56.25%\n",
            "* macro_f1: 37.31%\n",
            "=> per-class result\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 6\tacc: 66.67%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 2\tacc: 22.22%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* average: 44.44%\n",
            "Elapsed: 0:00:52\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed7\n",
            "in jaffe\n",
            "Setting fixed seed: 7\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed7\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 7\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed7\n",
            "RESUME: \n",
            "SEED: 7\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 16429.84it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed7/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.817 (1.817)\tdata 0.577 (0.577)\teta 0:02:59\tloss 1.8975 (1.8975)\tacc 9.3750 (9.3750)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.063 (0.940)\tdata 0.000 (0.289)\teta 0:01:32\tloss 2.0039 (1.9507)\tacc 12.5000 (10.9375)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.593 (0.593)\tdata 0.530 (0.530)\teta 0:00:57\tloss 1.9600 (1.9600)\tacc 12.5000 (12.5000)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.065 (0.329)\tdata 0.000 (0.265)\teta 0:00:31\tloss 1.6270 (1.7935)\tacc 46.8750 (29.6875)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.577 (0.577)\tdata 0.513 (0.513)\teta 0:00:54\tloss 1.6592 (1.6592)\tacc 40.6250 (40.6250)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.256)\teta 0:00:30\tloss 1.3760 (1.5176)\tacc 53.1250 (46.8750)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.578 (0.578)\tdata 0.513 (0.513)\teta 0:00:53\tloss 1.3867 (1.3867)\tacc 56.2500 (56.2500)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.257)\teta 0:00:29\tloss 1.2266 (1.3066)\tacc 59.3750 (57.8125)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.577 (0.577)\tdata 0.514 (0.514)\teta 0:00:52\tloss 1.2529 (1.2529)\tacc 56.2500 (56.2500)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.065 (0.321)\tdata 0.000 (0.257)\teta 0:00:28\tloss 1.1436 (1.1982)\tacc 65.6250 (60.9375)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.582 (0.582)\tdata 0.519 (0.519)\teta 0:00:51\tloss 1.3047 (1.3047)\tacc 56.2500 (56.2500)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.260)\teta 0:00:28\tloss 1.1172 (1.2109)\tacc 68.7500 (62.5000)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.561 (0.561)\tdata 0.496 (0.496)\teta 0:00:48\tloss 1.3037 (1.3037)\tacc 53.1250 (53.1250)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.065 (0.313)\tdata 0.000 (0.248)\teta 0:00:26\tloss 0.9380 (1.1208)\tacc 71.8750 (62.5000)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.573 (0.573)\tdata 0.509 (0.509)\teta 0:00:48\tloss 1.0908 (1.0908)\tacc 59.3750 (59.3750)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.065 (0.319)\tdata 0.000 (0.255)\teta 0:00:26\tloss 1.2393 (1.1650)\tacc 37.5000 (48.4375)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.589 (0.589)\tdata 0.527 (0.527)\teta 0:00:48\tloss 1.0127 (1.0127)\tacc 65.6250 (65.6250)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.065 (0.327)\tdata 0.000 (0.263)\teta 0:00:26\tloss 1.2305 (1.1216)\tacc 59.3750 (62.5000)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.572 (0.572)\tdata 0.509 (0.509)\teta 0:00:46\tloss 0.9785 (0.9785)\tacc 68.7500 (68.7500)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.255)\teta 0:00:25\tloss 1.0117 (0.9951)\tacc 68.7500 (68.7500)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.593 (0.593)\tdata 0.530 (0.530)\teta 0:00:46\tloss 0.9116 (0.9116)\tacc 62.5000 (62.5000)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.065 (0.329)\tdata 0.000 (0.265)\teta 0:00:25\tloss 1.2695 (1.0906)\tacc 46.8750 (54.6875)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.574 (0.574)\tdata 0.510 (0.510)\teta 0:00:44\tloss 0.8662 (0.8662)\tacc 75.0000 (75.0000)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.065 (0.320)\tdata 0.000 (0.255)\teta 0:00:24\tloss 0.9834 (0.9248)\tacc 68.7500 (71.8750)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.592 (0.592)\tdata 0.528 (0.528)\teta 0:00:44\tloss 0.7783 (0.7783)\tacc 81.2500 (81.2500)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:24\tloss 1.0537 (0.9160)\tacc 59.3750 (70.3125)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.586 (0.586)\tdata 0.524 (0.524)\teta 0:00:42\tloss 1.0371 (1.0371)\tacc 62.5000 (62.5000)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.262)\teta 0:00:23\tloss 1.1875 (1.1123)\tacc 50.0000 (56.2500)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.577 (0.577)\tdata 0.514 (0.514)\teta 0:00:40\tloss 0.8193 (0.8193)\tacc 71.8750 (71.8750)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.257)\teta 0:00:22\tloss 1.0020 (0.9106)\tacc 65.6250 (68.7500)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.571 (0.571)\tdata 0.507 (0.507)\teta 0:00:39\tloss 1.0605 (1.0605)\tacc 62.5000 (62.5000)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.254)\teta 0:00:21\tloss 0.8745 (0.9675)\tacc 65.6250 (64.0625)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.585 (0.585)\tdata 0.523 (0.523)\teta 0:00:39\tloss 0.7900 (0.7900)\tacc 62.5000 (62.5000)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.262)\teta 0:00:21\tloss 1.0000 (0.8950)\tacc 68.7500 (65.6250)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.593 (0.593)\tdata 0.528 (0.528)\teta 0:00:38\tloss 0.9512 (0.9512)\tacc 62.5000 (62.5000)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:21\tloss 1.0420 (0.9966)\tacc 68.7500 (65.6250)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.589 (0.589)\tdata 0.524 (0.524)\teta 0:00:37\tloss 0.9028 (0.9028)\tacc 65.6250 (65.6250)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.065 (0.327)\tdata 0.000 (0.262)\teta 0:00:20\tloss 1.0117 (0.9573)\tacc 62.5000 (64.0625)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.582 (0.582)\tdata 0.519 (0.519)\teta 0:00:35\tloss 0.9985 (0.9985)\tacc 62.5000 (62.5000)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.260)\teta 0:00:19\tloss 0.9741 (0.9863)\tacc 68.7500 (65.6250)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.574 (0.574)\tdata 0.509 (0.509)\teta 0:00:33\tloss 1.0537 (1.0537)\tacc 62.5000 (62.5000)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.065 (0.320)\tdata 0.000 (0.255)\teta 0:00:18\tloss 0.8164 (0.9351)\tacc 65.6250 (64.0625)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.583 (0.583)\tdata 0.519 (0.519)\teta 0:00:33\tloss 1.0293 (1.0293)\tacc 53.1250 (53.1250)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.260)\teta 0:00:18\tloss 0.9561 (0.9927)\tacc 68.7500 (60.9375)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.599 (0.599)\tdata 0.533 (0.533)\teta 0:00:32\tloss 0.7739 (0.7739)\tacc 75.0000 (75.0000)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.071 (0.335)\tdata 0.001 (0.267)\teta 0:00:18\tloss 0.8779 (0.8259)\tacc 68.7500 (71.8750)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.862 (0.862)\tdata 0.784 (0.784)\teta 0:00:45\tloss 0.5869 (0.5869)\tacc 87.5000 (87.5000)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.088 (0.475)\tdata 0.012 (0.398)\teta 0:00:24\tloss 0.8535 (0.7202)\tacc 71.8750 (79.6875)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.980 (0.980)\tdata 0.877 (0.877)\teta 0:00:49\tloss 0.7949 (0.7949)\tacc 81.2500 (81.2500)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.089 (0.535)\tdata 0.002 (0.439)\teta 0:00:26\tloss 0.7988 (0.7969)\tacc 59.3750 (70.3125)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.909 (0.909)\tdata 0.835 (0.835)\teta 0:00:44\tloss 0.7700 (0.7700)\tacc 78.1250 (78.1250)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.071 (0.490)\tdata 0.000 (0.418)\teta 0:00:23\tloss 1.1211 (0.9456)\tacc 53.1250 (65.6250)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.881 (0.881)\tdata 0.786 (0.786)\teta 0:00:41\tloss 0.9023 (0.9023)\tacc 65.6250 (65.6250)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.084 (0.482)\tdata 0.000 (0.393)\teta 0:00:22\tloss 0.8950 (0.8987)\tacc 75.0000 (70.3125)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.962 (0.962)\tdata 0.876 (0.876)\teta 0:00:43\tloss 0.7134 (0.7134)\tacc 78.1250 (78.1250)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.083 (0.523)\tdata 0.000 (0.438)\teta 0:00:23\tloss 1.0430 (0.8782)\tacc 65.6250 (71.8750)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.966 (0.966)\tdata 0.898 (0.898)\teta 0:00:41\tloss 0.8633 (0.8633)\tacc 68.7500 (68.7500)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.066 (0.516)\tdata 0.000 (0.449)\teta 0:00:21\tloss 0.6968 (0.7800)\tacc 81.2500 (75.0000)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.846 (0.846)\tdata 0.768 (0.768)\teta 0:00:34\tloss 0.9956 (0.9956)\tacc 65.6250 (65.6250)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.075 (0.461)\tdata 0.001 (0.384)\teta 0:00:18\tloss 0.7710 (0.8833)\tacc 78.1250 (71.8750)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.770 (0.770)\tdata 0.647 (0.647)\teta 0:00:30\tloss 0.9395 (0.9395)\tacc 56.2500 (56.2500)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.076 (0.423)\tdata 0.010 (0.329)\teta 0:00:16\tloss 0.6997 (0.8196)\tacc 78.1250 (67.1875)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.897 (0.897)\tdata 0.805 (0.805)\teta 0:00:33\tloss 0.8345 (0.8345)\tacc 78.1250 (78.1250)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.085 (0.491)\tdata 0.000 (0.403)\teta 0:00:17\tloss 0.7344 (0.7844)\tacc 75.0000 (76.5625)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.784 (0.784)\tdata 0.692 (0.692)\teta 0:00:27\tloss 0.7437 (0.7437)\tacc 78.1250 (78.1250)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.062 (0.423)\tdata 0.000 (0.346)\teta 0:00:14\tloss 1.0332 (0.8884)\tacc 65.6250 (71.8750)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.584 (0.584)\tdata 0.521 (0.521)\teta 0:00:19\tloss 0.8291 (0.8291)\tacc 65.6250 (65.6250)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.261)\teta 0:00:10\tloss 0.5996 (0.7144)\tacc 78.1250 (71.8750)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.572 (0.572)\tdata 0.507 (0.507)\teta 0:00:17\tloss 0.8564 (0.8564)\tacc 71.8750 (71.8750)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.254)\teta 0:00:09\tloss 0.8315 (0.8440)\tacc 75.0000 (73.4375)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.598 (0.598)\tdata 0.522 (0.522)\teta 0:00:17\tloss 0.6982 (0.6982)\tacc 78.1250 (78.1250)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.076 (0.337)\tdata 0.000 (0.261)\teta 0:00:09\tloss 0.8027 (0.7505)\tacc 71.8750 (75.0000)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.592 (0.592)\tdata 0.526 (0.526)\teta 0:00:15\tloss 0.9502 (0.9502)\tacc 68.7500 (68.7500)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.065 (0.328)\tdata 0.000 (0.263)\teta 0:00:08\tloss 0.7314 (0.8408)\tacc 81.2500 (75.0000)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.595 (0.595)\tdata 0.532 (0.532)\teta 0:00:14\tloss 0.6860 (0.6860)\tacc 78.1250 (78.1250)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.064 (0.329)\tdata 0.000 (0.266)\teta 0:00:07\tloss 0.8359 (0.7610)\tacc 65.6250 (71.8750)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.589 (0.589)\tdata 0.526 (0.526)\teta 0:00:13\tloss 0.7036 (0.7036)\tacc 68.7500 (68.7500)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.263)\teta 0:00:07\tloss 0.9517 (0.8276)\tacc 62.5000 (65.6250)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.574 (0.574)\tdata 0.511 (0.511)\teta 0:00:12\tloss 0.9009 (0.9009)\tacc 71.8750 (71.8750)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.065 (0.319)\tdata 0.000 (0.256)\teta 0:00:06\tloss 0.5532 (0.7271)\tacc 78.1250 (75.0000)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.575 (0.575)\tdata 0.513 (0.513)\teta 0:00:10\tloss 0.9175 (0.9175)\tacc 65.6250 (65.6250)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.063 (0.319)\tdata 0.000 (0.257)\teta 0:00:05\tloss 0.8066 (0.8621)\tacc 75.0000 (70.3125)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.593 (0.593)\tdata 0.517 (0.517)\teta 0:00:10\tloss 0.7231 (0.7231)\tacc 84.3750 (84.3750)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.073 (0.333)\tdata 0.000 (0.259)\teta 0:00:05\tloss 0.6455 (0.6843)\tacc 78.1250 (81.2500)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.592 (0.592)\tdata 0.527 (0.527)\teta 0:00:08\tloss 0.6191 (0.6191)\tacc 75.0000 (75.0000)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:04\tloss 0.7866 (0.7029)\tacc 75.0000 (75.0000)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.589 (0.589)\tdata 0.525 (0.525)\teta 0:00:07\tloss 0.6826 (0.6826)\tacc 78.1250 (78.1250)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.262)\teta 0:00:03\tloss 0.4868 (0.5847)\tacc 81.2500 (79.6875)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.561 (0.561)\tdata 0.497 (0.497)\teta 0:00:06\tloss 0.7007 (0.7007)\tacc 71.8750 (71.8750)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.064 (0.313)\tdata 0.000 (0.249)\teta 0:00:03\tloss 0.8726 (0.7866)\tacc 71.8750 (71.8750)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.579 (0.579)\tdata 0.517 (0.517)\teta 0:00:05\tloss 0.9336 (0.9336)\tacc 81.2500 (81.2500)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.259)\teta 0:00:02\tloss 1.0615 (0.9976)\tacc 62.5000 (71.8750)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.609 (0.609)\tdata 0.546 (0.546)\teta 0:00:04\tloss 0.8340 (0.8340)\tacc 71.8750 (71.8750)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.063 (0.336)\tdata 0.000 (0.273)\teta 0:00:02\tloss 0.6304 (0.7322)\tacc 78.1250 (75.0000)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.583 (0.583)\tdata 0.520 (0.520)\teta 0:00:02\tloss 1.0352 (1.0352)\tacc 56.2500 (56.2500)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.260)\teta 0:00:01\tloss 0.6201 (0.8276)\tacc 78.1250 (67.1875)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.616 (0.616)\tdata 0.540 (0.540)\teta 0:00:01\tloss 0.9160 (0.9160)\tacc 65.6250 (65.6250)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.074 (0.345)\tdata 0.000 (0.270)\teta 0:00:00\tloss 0.5928 (0.7544)\tacc 78.1250 (71.8750)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.606 (0.606)\tdata 0.542 (0.542)\teta 0:00:00\tloss 1.0195 (1.0195)\tacc 65.6250 (65.6250)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.065 (0.336)\tdata 0.001 (0.271)\teta 0:00:00\tloss 0.6079 (0.8137)\tacc 84.3750 (75.0000)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed7/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 26\n",
            "* accuracy: 40.62%\n",
            "* error: 59.38%\n",
            "* macro_f1: 34.84%\n",
            "=> per-class result\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 2\tacc: 22.22%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 2\tacc: 22.22%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* average: 41.27%\n",
            "Elapsed: 0:00:49\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed8\n",
            "in jaffe\n",
            "Setting fixed seed: 8\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed8\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 8\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed8\n",
            "RESUME: \n",
            "SEED: 8\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 14972.02it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed8/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.819 (1.819)\tdata 0.579 (0.579)\teta 0:03:00\tloss 2.2676 (2.2676)\tacc 3.1250 (3.1250)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.062 (0.940)\tdata 0.000 (0.290)\teta 0:01:32\tloss 1.9678 (2.1177)\tacc 21.8750 (12.5000)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.600 (0.600)\tdata 0.538 (0.538)\teta 0:00:58\tloss 1.9004 (1.9004)\tacc 18.7500 (18.7500)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.064 (0.332)\tdata 0.000 (0.269)\teta 0:00:31\tloss 1.7080 (1.8042)\tacc 43.7500 (31.2500)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.595 (0.595)\tdata 0.532 (0.532)\teta 0:00:56\tloss 1.6523 (1.6523)\tacc 37.5000 (37.5000)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.064 (0.329)\tdata 0.000 (0.266)\teta 0:00:30\tloss 1.5205 (1.5864)\tacc 56.2500 (46.8750)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.578 (0.578)\tdata 0.516 (0.516)\teta 0:00:53\tloss 1.3574 (1.3574)\tacc 59.3750 (59.3750)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.063 (0.321)\tdata 0.000 (0.258)\teta 0:00:29\tloss 1.3896 (1.3735)\tacc 46.8750 (53.1250)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.586 (0.586)\tdata 0.523 (0.523)\teta 0:00:53\tloss 1.1504 (1.1504)\tacc 65.6250 (65.6250)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.262)\teta 0:00:29\tloss 1.4502 (1.3003)\tacc 37.5000 (51.5625)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.578 (0.578)\tdata 0.516 (0.516)\teta 0:00:51\tloss 1.3008 (1.3008)\tacc 56.2500 (56.2500)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.258)\teta 0:00:28\tloss 1.4990 (1.3999)\tacc 40.6250 (48.4375)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.590 (0.590)\tdata 0.527 (0.527)\teta 0:00:51\tloss 1.2461 (1.2461)\tacc 62.5000 (62.5000)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.063 (0.327)\tdata 0.000 (0.264)\teta 0:00:28\tloss 1.4492 (1.3477)\tacc 46.8750 (54.6875)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.936 (0.936)\tdata 0.842 (0.842)\teta 0:01:19\tloss 1.1152 (1.1152)\tacc 65.6250 (65.6250)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.076 (0.506)\tdata 0.001 (0.421)\teta 0:00:42\tloss 1.3457 (1.2305)\tacc 50.0000 (57.8125)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.946 (0.946)\tdata 0.867 (0.867)\teta 0:01:18\tloss 1.0850 (1.0850)\tacc 59.3750 (59.3750)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.074 (0.510)\tdata 0.000 (0.434)\teta 0:00:41\tloss 1.5049 (1.2949)\tacc 46.8750 (53.1250)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.906 (0.906)\tdata 0.830 (0.830)\teta 0:01:13\tloss 1.3369 (1.3369)\tacc 56.2500 (56.2500)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.067 (0.487)\tdata 0.001 (0.415)\teta 0:00:38\tloss 1.1641 (1.2505)\tacc 56.2500 (56.2500)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.953 (0.953)\tdata 0.885 (0.885)\teta 0:01:15\tloss 1.0361 (1.0361)\tacc 68.7500 (68.7500)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.067 (0.510)\tdata 0.001 (0.443)\teta 0:00:39\tloss 0.9546 (0.9954)\tacc 65.6250 (67.1875)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.902 (0.902)\tdata 0.821 (0.821)\teta 0:01:09\tloss 0.9175 (0.9175)\tacc 59.3750 (59.3750)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.080 (0.491)\tdata 0.001 (0.411)\teta 0:00:37\tloss 1.0596 (0.9885)\tacc 75.0000 (67.1875)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.883 (0.883)\tdata 0.810 (0.810)\teta 0:01:06\tloss 1.0693 (1.0693)\tacc 62.5000 (62.5000)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.069 (0.476)\tdata 0.000 (0.405)\teta 0:00:35\tloss 1.3740 (1.2217)\tacc 46.8750 (54.6875)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.910 (0.910)\tdata 0.841 (0.841)\teta 0:01:06\tloss 0.8647 (0.8647)\tacc 75.0000 (75.0000)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.068 (0.489)\tdata 0.001 (0.421)\teta 0:00:35\tloss 0.9907 (0.9277)\tacc 62.5000 (68.7500)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.921 (0.921)\tdata 0.854 (0.854)\teta 0:01:05\tloss 0.9336 (0.9336)\tacc 78.1250 (78.1250)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.068 (0.495)\tdata 0.001 (0.427)\teta 0:00:34\tloss 1.1201 (1.0269)\tacc 56.2500 (67.1875)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.850 (0.850)\tdata 0.769 (0.769)\teta 0:00:58\tloss 0.9941 (0.9941)\tacc 71.8750 (71.8750)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.068 (0.459)\tdata 0.000 (0.384)\teta 0:00:31\tloss 0.8940 (0.9441)\tacc 78.1250 (75.0000)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.933 (0.933)\tdata 0.867 (0.867)\teta 0:01:02\tloss 0.9316 (0.9316)\tacc 65.6250 (65.6250)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.067 (0.500)\tdata 0.001 (0.434)\teta 0:00:33\tloss 0.9619 (0.9468)\tacc 68.7500 (67.1875)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.575 (0.575)\tdata 0.512 (0.512)\teta 0:00:37\tloss 0.8491 (0.8491)\tacc 71.8750 (71.8750)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.063 (0.319)\tdata 0.000 (0.256)\teta 0:00:20\tloss 0.7842 (0.8167)\tacc 68.7500 (70.3125)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.587 (0.587)\tdata 0.523 (0.523)\teta 0:00:37\tloss 1.1152 (1.1152)\tacc 59.3750 (59.3750)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.262)\teta 0:00:20\tloss 0.7422 (0.9287)\tacc 78.1250 (68.7500)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.582 (0.582)\tdata 0.519 (0.519)\teta 0:00:35\tloss 0.7314 (0.7314)\tacc 81.2500 (81.2500)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.260)\teta 0:00:19\tloss 0.8589 (0.7952)\tacc 68.7500 (75.0000)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.586 (0.586)\tdata 0.521 (0.521)\teta 0:00:34\tloss 0.6758 (0.6758)\tacc 78.1250 (78.1250)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.261)\teta 0:00:18\tloss 0.8462 (0.7610)\tacc 78.1250 (78.1250)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.590 (0.590)\tdata 0.527 (0.527)\teta 0:00:33\tloss 0.7510 (0.7510)\tacc 71.8750 (71.8750)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.065 (0.328)\tdata 0.000 (0.264)\teta 0:00:18\tloss 1.0156 (0.8833)\tacc 65.6250 (68.7500)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.608 (0.608)\tdata 0.544 (0.544)\teta 0:00:33\tloss 0.7690 (0.7690)\tacc 75.0000 (75.0000)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.065 (0.336)\tdata 0.000 (0.272)\teta 0:00:18\tloss 0.9863 (0.8777)\tacc 71.8750 (73.4375)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.584 (0.584)\tdata 0.522 (0.522)\teta 0:00:30\tloss 0.6978 (0.6978)\tacc 78.1250 (78.1250)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.261)\teta 0:00:16\tloss 1.0557 (0.8767)\tacc 62.5000 (70.3125)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.579 (0.579)\tdata 0.516 (0.516)\teta 0:00:29\tloss 0.7769 (0.7769)\tacc 68.7500 (68.7500)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.258)\teta 0:00:16\tloss 0.6685 (0.7227)\tacc 78.1250 (73.4375)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.581 (0.581)\tdata 0.517 (0.517)\teta 0:00:28\tloss 1.0293 (1.0293)\tacc 68.7500 (68.7500)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.259)\teta 0:00:15\tloss 0.7798 (0.9045)\tacc 62.5000 (65.6250)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.599 (0.599)\tdata 0.536 (0.536)\teta 0:00:28\tloss 0.9927 (0.9927)\tacc 62.5000 (62.5000)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.268)\teta 0:00:15\tloss 0.7603 (0.8765)\tacc 71.8750 (67.1875)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.581 (0.581)\tdata 0.517 (0.517)\teta 0:00:26\tloss 0.9814 (0.9814)\tacc 68.7500 (68.7500)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.071 (0.326)\tdata 0.000 (0.258)\teta 0:00:14\tloss 0.8345 (0.9080)\tacc 71.8750 (70.3125)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.578 (0.578)\tdata 0.515 (0.515)\teta 0:00:24\tloss 0.8569 (0.8569)\tacc 75.0000 (75.0000)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.066 (0.322)\tdata 0.000 (0.258)\teta 0:00:13\tloss 0.7939 (0.8254)\tacc 68.7500 (71.8750)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.568 (0.568)\tdata 0.504 (0.504)\teta 0:00:23\tloss 0.7095 (0.7095)\tacc 78.1250 (78.1250)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.065 (0.317)\tdata 0.000 (0.252)\teta 0:00:12\tloss 0.9321 (0.8208)\tacc 75.0000 (76.5625)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.582 (0.582)\tdata 0.520 (0.520)\teta 0:00:22\tloss 0.9072 (0.9072)\tacc 65.6250 (65.6250)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.260)\teta 0:00:12\tloss 0.6743 (0.7908)\tacc 71.8750 (68.7500)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.617 (0.617)\tdata 0.541 (0.541)\teta 0:00:22\tloss 0.7310 (0.7310)\tacc 68.7500 (68.7500)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.075 (0.346)\tdata 0.000 (0.270)\teta 0:00:12\tloss 0.8789 (0.8049)\tacc 71.8750 (70.3125)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.589 (0.589)\tdata 0.526 (0.526)\teta 0:00:20\tloss 0.8716 (0.8716)\tacc 65.6250 (65.6250)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.263)\teta 0:00:11\tloss 0.8965 (0.8840)\tacc 68.7500 (67.1875)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.588 (0.588)\tdata 0.522 (0.522)\teta 0:00:19\tloss 0.9292 (0.9292)\tacc 71.8750 (71.8750)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.261)\teta 0:00:10\tloss 0.6196 (0.7744)\tacc 87.5000 (79.6875)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.577 (0.577)\tdata 0.513 (0.513)\teta 0:00:17\tloss 0.8457 (0.8457)\tacc 75.0000 (75.0000)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.065 (0.321)\tdata 0.000 (0.257)\teta 0:00:09\tloss 0.6743 (0.7600)\tacc 71.8750 (73.4375)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.571 (0.571)\tdata 0.509 (0.509)\teta 0:00:16\tloss 0.6699 (0.6699)\tacc 78.1250 (78.1250)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.065 (0.318)\tdata 0.000 (0.255)\teta 0:00:08\tloss 0.7090 (0.6895)\tacc 81.2500 (79.6875)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.587 (0.587)\tdata 0.525 (0.525)\teta 0:00:15\tloss 0.5210 (0.5210)\tacc 84.3750 (84.3750)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.065 (0.326)\tdata 0.000 (0.262)\teta 0:00:08\tloss 0.9131 (0.7170)\tacc 71.8750 (78.1250)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.597 (0.597)\tdata 0.534 (0.534)\teta 0:00:14\tloss 0.6094 (0.6094)\tacc 87.5000 (87.5000)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:07\tloss 0.7817 (0.6956)\tacc 65.6250 (76.5625)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.579 (0.579)\tdata 0.507 (0.507)\teta 0:00:13\tloss 0.6553 (0.6553)\tacc 81.2500 (81.2500)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.069 (0.324)\tdata 0.000 (0.254)\teta 0:00:07\tloss 0.7900 (0.7227)\tacc 71.8750 (76.5625)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.578 (0.578)\tdata 0.510 (0.510)\teta 0:00:12\tloss 0.5088 (0.5088)\tacc 81.2500 (81.2500)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.255)\teta 0:00:06\tloss 0.5913 (0.5500)\tacc 81.2500 (81.2500)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.590 (0.590)\tdata 0.525 (0.525)\teta 0:00:11\tloss 0.8184 (0.8184)\tacc 81.2500 (81.2500)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.263)\teta 0:00:05\tloss 0.8955 (0.8569)\tacc 68.7500 (75.0000)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.614 (0.614)\tdata 0.550 (0.550)\teta 0:00:10\tloss 0.7217 (0.7217)\tacc 78.1250 (78.1250)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.065 (0.339)\tdata 0.000 (0.275)\teta 0:00:05\tloss 0.7397 (0.7307)\tacc 75.0000 (76.5625)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.601 (0.601)\tdata 0.538 (0.538)\teta 0:00:09\tloss 0.7065 (0.7065)\tacc 78.1250 (78.1250)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.064 (0.333)\tdata 0.000 (0.269)\teta 0:00:04\tloss 0.6445 (0.6755)\tacc 78.1250 (78.1250)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.592 (0.592)\tdata 0.529 (0.529)\teta 0:00:07\tloss 0.7480 (0.7480)\tacc 75.0000 (75.0000)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.063 (0.328)\tdata 0.000 (0.265)\teta 0:00:03\tloss 0.6333 (0.6907)\tacc 84.3750 (79.6875)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.582 (0.582)\tdata 0.517 (0.517)\teta 0:00:06\tloss 0.9199 (0.9199)\tacc 65.6250 (65.6250)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.063 (0.323)\tdata 0.000 (0.259)\teta 0:00:03\tloss 1.0127 (0.9663)\tacc 62.5000 (64.0625)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.576 (0.576)\tdata 0.513 (0.513)\teta 0:00:05\tloss 0.6431 (0.6431)\tacc 84.3750 (84.3750)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.064 (0.320)\tdata 0.000 (0.257)\teta 0:00:02\tloss 0.8213 (0.7322)\tacc 75.0000 (79.6875)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.596 (0.596)\tdata 0.532 (0.532)\teta 0:00:04\tloss 0.4592 (0.4592)\tacc 84.3750 (84.3750)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.266)\teta 0:00:01\tloss 0.5527 (0.5060)\tacc 84.3750 (84.3750)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.592 (0.592)\tdata 0.528 (0.528)\teta 0:00:02\tloss 0.5156 (0.5156)\tacc 87.5000 (87.5000)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:01\tloss 0.6387 (0.5771)\tacc 78.1250 (82.8125)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.599 (0.599)\tdata 0.534 (0.534)\teta 0:00:01\tloss 0.8145 (0.8145)\tacc 71.8750 (71.8750)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.064 (0.332)\tdata 0.000 (0.267)\teta 0:00:00\tloss 0.9702 (0.8923)\tacc 68.7500 (70.3125)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.573 (0.573)\tdata 0.508 (0.508)\teta 0:00:00\tloss 0.6333 (0.6333)\tacc 78.1250 (78.1250)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.254)\teta 0:00:00\tloss 0.8613 (0.7473)\tacc 71.8750 (75.0000)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed8/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 32\n",
            "* accuracy: 50.00%\n",
            "* error: 50.00%\n",
            "* macro_f1: 42.26%\n",
            "=> per-class result\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 7\tacc: 77.78%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* average: 50.79%\n",
            "Elapsed: 0:00:49\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed9\n",
            "in jaffe\n",
            "Setting fixed seed: 9\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed9\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 9\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed9\n",
            "RESUME: \n",
            "SEED: 9\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 11231.88it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed9/tensorboard\n",
            "epoch [1/50][1/2]\ttime 2.092 (2.092)\tdata 0.816 (0.816)\teta 0:03:27\tloss 1.9199 (1.9199)\tacc 12.5000 (12.5000)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.062 (1.077)\tdata 0.000 (0.408)\teta 0:01:45\tloss 1.8613 (1.8906)\tacc 21.8750 (17.1875)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.601 (0.601)\tdata 0.539 (0.539)\teta 0:00:58\tloss 1.8379 (1.8379)\tacc 12.5000 (12.5000)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.064 (0.332)\tdata 0.001 (0.270)\teta 0:00:31\tloss 1.6533 (1.7456)\tacc 31.2500 (21.8750)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.573 (0.573)\tdata 0.507 (0.507)\teta 0:00:54\tloss 1.6309 (1.6309)\tacc 46.8750 (46.8750)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.063 (0.318)\tdata 0.000 (0.253)\teta 0:00:29\tloss 1.5918 (1.6113)\tacc 43.7500 (45.3125)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.583 (0.583)\tdata 0.521 (0.521)\teta 0:00:54\tloss 1.4795 (1.4795)\tacc 43.7500 (43.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.063 (0.323)\tdata 0.000 (0.261)\teta 0:00:29\tloss 1.5830 (1.5312)\tacc 28.1250 (35.9375)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.589 (0.589)\tdata 0.525 (0.525)\teta 0:00:53\tloss 1.3555 (1.3555)\tacc 53.1250 (53.1250)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.063 (0.326)\tdata 0.000 (0.263)\teta 0:00:29\tloss 1.2236 (1.2896)\tacc 65.6250 (59.3750)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.583 (0.583)\tdata 0.520 (0.520)\teta 0:00:51\tloss 1.1855 (1.1855)\tacc 53.1250 (53.1250)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.260)\teta 0:00:28\tloss 1.2051 (1.1953)\tacc 59.3750 (56.2500)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.596 (0.596)\tdata 0.533 (0.533)\teta 0:00:51\tloss 1.4824 (1.4824)\tacc 46.8750 (46.8750)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:28\tloss 1.2227 (1.3525)\tacc 50.0000 (48.4375)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.580 (0.580)\tdata 0.518 (0.518)\teta 0:00:49\tloss 1.2158 (1.2158)\tacc 56.2500 (56.2500)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.259)\teta 0:00:27\tloss 1.2510 (1.2334)\tacc 50.0000 (53.1250)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.588 (0.588)\tdata 0.526 (0.526)\teta 0:00:48\tloss 1.2295 (1.2295)\tacc 56.2500 (56.2500)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.063 (0.326)\tdata 0.000 (0.263)\teta 0:00:26\tloss 1.0938 (1.1616)\tacc 68.7500 (62.5000)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.576 (0.576)\tdata 0.514 (0.514)\teta 0:00:46\tloss 1.1426 (1.1426)\tacc 59.3750 (59.3750)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.064 (0.320)\tdata 0.001 (0.257)\teta 0:00:25\tloss 1.2529 (1.1978)\tacc 50.0000 (54.6875)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.594 (0.594)\tdata 0.532 (0.532)\teta 0:00:46\tloss 1.2080 (1.2080)\tacc 65.6250 (65.6250)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.066 (0.330)\tdata 0.000 (0.266)\teta 0:00:25\tloss 1.0723 (1.1401)\tacc 68.7500 (67.1875)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.583 (0.583)\tdata 0.518 (0.518)\teta 0:00:44\tloss 1.0283 (1.0283)\tacc 65.6250 (65.6250)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.259)\teta 0:00:24\tloss 1.0928 (1.0605)\tacc 56.2500 (60.9375)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.591 (0.591)\tdata 0.529 (0.529)\teta 0:00:44\tloss 1.1885 (1.1885)\tacc 62.5000 (62.5000)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.066 (0.328)\tdata 0.000 (0.265)\teta 0:00:24\tloss 1.0488 (1.1187)\tacc 75.0000 (68.7500)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.591 (0.591)\tdata 0.529 (0.529)\teta 0:00:43\tloss 0.8154 (0.8154)\tacc 68.7500 (68.7500)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:23\tloss 1.1719 (0.9937)\tacc 56.2500 (62.5000)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.582 (0.582)\tdata 0.518 (0.518)\teta 0:00:41\tloss 0.9678 (0.9678)\tacc 56.2500 (56.2500)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.259)\teta 0:00:22\tloss 1.0859 (1.0269)\tacc 65.6250 (60.9375)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.592 (0.592)\tdata 0.530 (0.530)\teta 0:00:40\tloss 0.8970 (0.8970)\tacc 62.5000 (62.5000)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.063 (0.328)\tdata 0.000 (0.265)\teta 0:00:22\tloss 1.0781 (0.9875)\tacc 59.3750 (60.9375)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.594 (0.594)\tdata 0.532 (0.532)\teta 0:00:39\tloss 1.1543 (1.1543)\tacc 65.6250 (65.6250)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.065 (0.330)\tdata 0.000 (0.266)\teta 0:00:21\tloss 1.0254 (1.0898)\tacc 68.7500 (67.1875)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.593 (0.593)\tdata 0.531 (0.531)\teta 0:00:38\tloss 1.0186 (1.0186)\tacc 65.6250 (65.6250)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.266)\teta 0:00:21\tloss 0.9512 (0.9849)\tacc 59.3750 (62.5000)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.595 (0.595)\tdata 0.533 (0.533)\teta 0:00:37\tloss 0.8848 (0.8848)\tacc 68.7500 (68.7500)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.063 (0.329)\tdata 0.000 (0.266)\teta 0:00:20\tloss 0.8877 (0.8862)\tacc 71.8750 (70.3125)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.618 (0.618)\tdata 0.556 (0.556)\teta 0:00:37\tloss 0.9331 (0.9331)\tacc 50.0000 (50.0000)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.063 (0.341)\tdata 0.000 (0.278)\teta 0:00:20\tloss 0.6699 (0.8015)\tacc 75.0000 (62.5000)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.572 (0.572)\tdata 0.508 (0.508)\teta 0:00:33\tloss 1.0225 (1.0225)\tacc 62.5000 (62.5000)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.254)\teta 0:00:18\tloss 0.8184 (0.9204)\tacc 84.3750 (73.4375)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.591 (0.591)\tdata 0.527 (0.527)\teta 0:00:33\tloss 0.8750 (0.8750)\tacc 68.7500 (68.7500)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:18\tloss 0.8496 (0.8623)\tacc 68.7500 (68.7500)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.602 (0.602)\tdata 0.540 (0.540)\teta 0:00:33\tloss 0.6016 (0.6016)\tacc 84.3750 (84.3750)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.063 (0.333)\tdata 0.000 (0.270)\teta 0:00:17\tloss 0.9805 (0.7910)\tacc 65.6250 (75.0000)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.609 (0.609)\tdata 0.546 (0.546)\teta 0:00:32\tloss 0.9751 (0.9751)\tacc 56.2500 (56.2500)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.065 (0.337)\tdata 0.000 (0.273)\teta 0:00:17\tloss 0.8359 (0.9055)\tacc 68.7500 (62.5000)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.579 (0.579)\tdata 0.517 (0.517)\teta 0:00:29\tloss 1.0303 (1.0303)\tacc 59.3750 (59.3750)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.258)\teta 0:00:16\tloss 0.8350 (0.9326)\tacc 65.6250 (62.5000)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.586 (0.586)\tdata 0.523 (0.523)\teta 0:00:28\tloss 0.9380 (0.9380)\tacc 71.8750 (71.8750)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.065 (0.325)\tdata 0.000 (0.262)\teta 0:00:15\tloss 0.9341 (0.9360)\tacc 68.7500 (70.3125)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.612 (0.612)\tdata 0.551 (0.551)\teta 0:00:28\tloss 1.0830 (1.0830)\tacc 71.8750 (71.8750)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.064 (0.338)\tdata 0.000 (0.275)\teta 0:00:15\tloss 0.6821 (0.8826)\tacc 78.1250 (75.0000)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.589 (0.589)\tdata 0.525 (0.525)\teta 0:00:26\tloss 1.0322 (1.0322)\tacc 65.6250 (65.6250)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.263)\teta 0:00:14\tloss 0.8813 (0.9568)\tacc 71.8750 (68.7500)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.589 (0.589)\tdata 0.525 (0.525)\teta 0:00:25\tloss 0.7627 (0.7627)\tacc 75.0000 (75.0000)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.065 (0.327)\tdata 0.000 (0.263)\teta 0:00:13\tloss 0.8184 (0.7905)\tacc 65.6250 (70.3125)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.585 (0.585)\tdata 0.522 (0.522)\teta 0:00:23\tloss 0.6455 (0.6455)\tacc 75.0000 (75.0000)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.067 (0.326)\tdata 0.000 (0.261)\teta 0:00:13\tloss 0.8057 (0.7256)\tacc 71.8750 (73.4375)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.592 (0.592)\tdata 0.528 (0.528)\teta 0:00:23\tloss 0.7861 (0.7861)\tacc 71.8750 (71.8750)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:12\tloss 0.9590 (0.8726)\tacc 71.8750 (71.8750)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.581 (0.581)\tdata 0.518 (0.518)\teta 0:00:21\tloss 0.8169 (0.8169)\tacc 68.7500 (68.7500)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.069 (0.325)\tdata 0.000 (0.259)\teta 0:00:11\tloss 0.7446 (0.7808)\tacc 75.0000 (71.8750)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.582 (0.582)\tdata 0.518 (0.518)\teta 0:00:20\tloss 1.0225 (1.0225)\tacc 53.1250 (53.1250)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.063 (0.323)\tdata 0.000 (0.259)\teta 0:00:10\tloss 0.7969 (0.9097)\tacc 71.8750 (62.5000)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.607 (0.607)\tdata 0.532 (0.532)\teta 0:00:20\tloss 0.6587 (0.6587)\tacc 84.3750 (84.3750)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.074 (0.340)\tdata 0.000 (0.266)\teta 0:00:10\tloss 0.8472 (0.7529)\tacc 68.7500 (76.5625)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.584 (0.584)\tdata 0.515 (0.515)\teta 0:00:18\tloss 0.9033 (0.9033)\tacc 65.6250 (65.6250)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.063 (0.324)\tdata 0.001 (0.258)\teta 0:00:09\tloss 0.7275 (0.8154)\tacc 75.0000 (70.3125)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.592 (0.592)\tdata 0.529 (0.529)\teta 0:00:17\tloss 0.8604 (0.8604)\tacc 68.7500 (68.7500)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.265)\teta 0:00:09\tloss 0.6064 (0.7334)\tacc 81.2500 (75.0000)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.574 (0.574)\tdata 0.510 (0.510)\teta 0:00:15\tloss 0.5718 (0.5718)\tacc 75.0000 (75.0000)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.064 (0.319)\tdata 0.000 (0.255)\teta 0:00:08\tloss 0.9912 (0.7815)\tacc 65.6250 (70.3125)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.582 (0.582)\tdata 0.518 (0.518)\teta 0:00:14\tloss 0.6079 (0.6079)\tacc 90.6250 (90.6250)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.063 (0.323)\tdata 0.000 (0.259)\teta 0:00:07\tloss 0.6050 (0.6064)\tacc 84.3750 (87.5000)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.596 (0.596)\tdata 0.529 (0.529)\teta 0:00:13\tloss 0.7510 (0.7510)\tacc 68.7500 (68.7500)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.065 (0.330)\tdata 0.000 (0.265)\teta 0:00:07\tloss 0.6958 (0.7234)\tacc 68.7500 (68.7500)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.634 (0.634)\tdata 0.549 (0.549)\teta 0:00:13\tloss 0.6978 (0.6978)\tacc 78.1250 (78.1250)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.096 (0.365)\tdata 0.027 (0.288)\teta 0:00:07\tloss 0.8901 (0.7939)\tacc 53.1250 (65.6250)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.930 (0.930)\tdata 0.864 (0.864)\teta 0:00:17\tloss 0.7192 (0.7192)\tacc 78.1250 (78.1250)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.067 (0.499)\tdata 0.000 (0.432)\teta 0:00:08\tloss 0.7217 (0.7205)\tacc 68.7500 (73.4375)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.910 (0.910)\tdata 0.842 (0.842)\teta 0:00:15\tloss 0.5874 (0.5874)\tacc 84.3750 (84.3750)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.067 (0.489)\tdata 0.001 (0.421)\teta 0:00:07\tloss 0.6553 (0.6213)\tacc 71.8750 (78.1250)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.912 (0.912)\tdata 0.830 (0.830)\teta 0:00:13\tloss 0.8311 (0.8311)\tacc 68.7500 (68.7500)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.081 (0.497)\tdata 0.000 (0.415)\teta 0:00:06\tloss 0.6968 (0.7639)\tacc 84.3750 (76.5625)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.905 (0.905)\tdata 0.838 (0.838)\teta 0:00:11\tloss 0.6885 (0.6885)\tacc 84.3750 (84.3750)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.067 (0.486)\tdata 0.000 (0.419)\teta 0:00:05\tloss 0.8125 (0.7505)\tacc 62.5000 (73.4375)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.933 (0.933)\tdata 0.866 (0.866)\teta 0:00:10\tloss 0.7114 (0.7114)\tacc 68.7500 (68.7500)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.068 (0.500)\tdata 0.001 (0.433)\teta 0:00:05\tloss 1.2041 (0.9578)\tacc 56.2500 (62.5000)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.908 (0.908)\tdata 0.829 (0.829)\teta 0:00:08\tloss 1.2275 (1.2275)\tacc 53.1250 (53.1250)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.076 (0.492)\tdata 0.000 (0.415)\teta 0:00:03\tloss 0.6504 (0.9390)\tacc 68.7500 (60.9375)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.983 (0.983)\tdata 0.867 (0.867)\teta 0:00:06\tloss 0.8604 (0.8604)\tacc 68.7500 (68.7500)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.090 (0.537)\tdata 0.000 (0.434)\teta 0:00:03\tloss 0.5225 (0.6914)\tacc 84.3750 (76.5625)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 1.000 (1.000)\tdata 0.905 (0.905)\teta 0:00:05\tloss 0.8633 (0.8633)\tacc 65.6250 (65.6250)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.082 (0.541)\tdata 0.001 (0.453)\teta 0:00:02\tloss 0.8560 (0.8596)\tacc 68.7500 (67.1875)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.965 (0.965)\tdata 0.876 (0.876)\teta 0:00:02\tloss 0.6646 (0.6646)\tacc 68.7500 (68.7500)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.079 (0.522)\tdata 0.000 (0.438)\teta 0:00:01\tloss 0.7178 (0.6912)\tacc 75.0000 (71.8750)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.890 (0.890)\tdata 0.813 (0.813)\teta 0:00:00\tloss 0.6040 (0.6040)\tacc 78.1250 (78.1250)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.070 (0.480)\tdata 0.000 (0.407)\teta 0:00:00\tloss 0.9458 (0.7749)\tacc 65.6250 (71.8750)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed9/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 27\n",
            "* accuracy: 42.19%\n",
            "* error: 57.81%\n",
            "* macro_f1: 35.90%\n",
            "=> per-class result\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 2\tacc: 22.22%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* average: 42.86%\n",
            "Elapsed: 0:00:51\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed10\n",
            "in jaffe\n",
            "Setting fixed seed: 10\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed10\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 10\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed10\n",
            "RESUME: \n",
            "SEED: 10\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 16710.37it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed10/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.782 (1.782)\tdata 0.566 (0.566)\teta 0:02:56\tloss 2.7168 (2.7168)\tacc 12.5000 (12.5000)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.062 (0.922)\tdata 0.000 (0.283)\teta 0:01:30\tloss 1.9795 (2.3481)\tacc 34.3750 (23.4375)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.574 (0.574)\tdata 0.510 (0.510)\teta 0:00:55\tloss 2.1465 (2.1465)\tacc 21.8750 (21.8750)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.064 (0.319)\tdata 0.000 (0.255)\teta 0:00:30\tloss 1.9053 (2.0259)\tacc 12.5000 (17.1875)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.585 (0.585)\tdata 0.521 (0.521)\teta 0:00:55\tloss 1.8340 (1.8340)\tacc 25.0000 (25.0000)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.260)\teta 0:00:30\tloss 1.8096 (1.8218)\tacc 37.5000 (31.2500)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.592 (0.592)\tdata 0.529 (0.529)\teta 0:00:55\tloss 1.7188 (1.7188)\tacc 43.7500 (43.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.065 (0.329)\tdata 0.000 (0.265)\teta 0:00:30\tloss 1.7568 (1.7378)\tacc 15.6250 (29.6875)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.595 (0.595)\tdata 0.532 (0.532)\teta 0:00:54\tloss 1.5840 (1.5840)\tacc 65.6250 (65.6250)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.266)\teta 0:00:29\tloss 1.5625 (1.5732)\tacc 43.7500 (54.6875)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.573 (0.573)\tdata 0.509 (0.509)\teta 0:00:50\tloss 1.3594 (1.3594)\tacc 65.6250 (65.6250)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.254)\teta 0:00:28\tloss 1.3916 (1.3755)\tacc 53.1250 (59.3750)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.588 (0.588)\tdata 0.525 (0.525)\teta 0:00:51\tloss 1.4590 (1.4590)\tacc 56.2500 (56.2500)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.263)\teta 0:00:28\tloss 1.1904 (1.3247)\tacc 59.3750 (57.8125)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.592 (0.592)\tdata 0.530 (0.530)\teta 0:00:50\tloss 1.0850 (1.0850)\tacc 62.5000 (62.5000)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.265)\teta 0:00:27\tloss 1.3477 (1.2163)\tacc 50.0000 (56.2500)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.583 (0.583)\tdata 0.521 (0.521)\teta 0:00:48\tloss 1.1641 (1.1641)\tacc 62.5000 (62.5000)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.261)\teta 0:00:26\tloss 1.0957 (1.1299)\tacc 62.5000 (62.5000)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.609 (0.609)\tdata 0.537 (0.537)\teta 0:00:49\tloss 1.0576 (1.0576)\tacc 62.5000 (62.5000)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.071 (0.340)\tdata 0.000 (0.269)\teta 0:00:27\tloss 0.9575 (1.0076)\tacc 65.6250 (64.0625)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.579 (0.579)\tdata 0.516 (0.516)\teta 0:00:45\tloss 0.9009 (0.9009)\tacc 71.8750 (71.8750)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.068 (0.323)\tdata 0.000 (0.258)\teta 0:00:25\tloss 1.1348 (1.0178)\tacc 65.6250 (68.7500)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.571 (0.571)\tdata 0.508 (0.508)\teta 0:00:43\tloss 1.0596 (1.0596)\tacc 53.1250 (53.1250)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.254)\teta 0:00:24\tloss 1.2256 (1.1426)\tacc 62.5000 (57.8125)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.605 (0.605)\tdata 0.541 (0.541)\teta 0:00:45\tloss 1.0576 (1.0576)\tacc 68.7500 (68.7500)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.271)\teta 0:00:24\tloss 1.0010 (1.0293)\tacc 65.6250 (67.1875)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.589 (0.589)\tdata 0.524 (0.524)\teta 0:00:42\tloss 1.1543 (1.1543)\tacc 53.1250 (53.1250)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.065 (0.327)\tdata 0.000 (0.262)\teta 0:00:23\tloss 1.2266 (1.1904)\tacc 46.8750 (50.0000)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.578 (0.578)\tdata 0.516 (0.516)\teta 0:00:41\tloss 0.8848 (0.8848)\tacc 65.6250 (65.6250)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.065 (0.322)\tdata 0.000 (0.258)\teta 0:00:22\tloss 1.1953 (1.0400)\tacc 56.2500 (60.9375)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.614 (0.614)\tdata 0.538 (0.538)\teta 0:00:42\tloss 0.9141 (0.9141)\tacc 68.7500 (68.7500)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.075 (0.345)\tdata 0.001 (0.269)\teta 0:00:23\tloss 1.2861 (1.1001)\tacc 59.3750 (64.0625)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.572 (0.572)\tdata 0.506 (0.506)\teta 0:00:38\tloss 0.5767 (0.5767)\tacc 84.3750 (84.3750)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.253)\teta 0:00:20\tloss 1.3652 (0.9709)\tacc 37.5000 (60.9375)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.582 (0.582)\tdata 0.519 (0.519)\teta 0:00:37\tloss 0.9502 (0.9502)\tacc 71.8750 (71.8750)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.260)\teta 0:00:20\tloss 0.9551 (0.9526)\tacc 65.6250 (68.7500)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.615 (0.615)\tdata 0.553 (0.553)\teta 0:00:38\tloss 0.9331 (0.9331)\tacc 71.8750 (71.8750)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.064 (0.339)\tdata 0.000 (0.276)\teta 0:00:21\tloss 0.9585 (0.9458)\tacc 65.6250 (68.7500)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.600 (0.600)\tdata 0.536 (0.536)\teta 0:00:36\tloss 1.1377 (1.1377)\tacc 65.6250 (65.6250)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.064 (0.332)\tdata 0.000 (0.268)\teta 0:00:19\tloss 1.0215 (1.0796)\tacc 62.5000 (64.0625)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.599 (0.599)\tdata 0.536 (0.536)\teta 0:00:35\tloss 1.0674 (1.0674)\tacc 59.3750 (59.3750)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.268)\teta 0:00:19\tloss 0.8164 (0.9419)\tacc 78.1250 (68.7500)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.981 (0.981)\tdata 0.913 (0.913)\teta 0:00:55\tloss 1.1543 (1.1543)\tacc 68.7500 (68.7500)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.066 (0.524)\tdata 0.000 (0.456)\teta 0:00:29\tloss 0.8149 (0.9846)\tacc 84.3750 (76.5625)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.892 (0.892)\tdata 0.816 (0.816)\teta 0:00:49\tloss 0.7686 (0.7686)\tacc 68.7500 (68.7500)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.067 (0.480)\tdata 0.000 (0.408)\teta 0:00:25\tloss 1.1846 (0.9766)\tacc 71.8750 (70.3125)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.863 (0.863)\tdata 0.795 (0.795)\teta 0:00:45\tloss 0.6338 (0.6338)\tacc 84.3750 (84.3750)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.068 (0.466)\tdata 0.001 (0.398)\teta 0:00:24\tloss 1.0928 (0.8633)\tacc 56.2500 (70.3125)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.954 (0.954)\tdata 0.888 (0.888)\teta 0:00:48\tloss 1.0303 (1.0303)\tacc 71.8750 (71.8750)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.068 (0.511)\tdata 0.001 (0.444)\teta 0:00:25\tloss 0.7886 (0.9094)\tacc 75.0000 (73.4375)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.932 (0.932)\tdata 0.847 (0.847)\teta 0:00:45\tloss 1.0215 (1.0215)\tacc 68.7500 (68.7500)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.082 (0.507)\tdata 0.000 (0.424)\teta 0:00:24\tloss 0.6509 (0.8362)\tacc 78.1250 (73.4375)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.874 (0.874)\tdata 0.785 (0.785)\teta 0:00:41\tloss 0.8159 (0.8159)\tacc 81.2500 (81.2500)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.066 (0.470)\tdata 0.001 (0.393)\teta 0:00:21\tloss 0.6724 (0.7441)\tacc 84.3750 (82.8125)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.865 (0.865)\tdata 0.798 (0.798)\teta 0:00:38\tloss 0.8965 (0.8965)\tacc 62.5000 (62.5000)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.070 (0.468)\tdata 0.000 (0.399)\teta 0:00:20\tloss 0.8481 (0.8723)\tacc 65.6250 (64.0625)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.932 (0.932)\tdata 0.864 (0.864)\teta 0:00:40\tloss 0.8223 (0.8223)\tacc 71.8750 (71.8750)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.068 (0.500)\tdata 0.001 (0.432)\teta 0:00:20\tloss 0.8188 (0.8206)\tacc 78.1250 (75.0000)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.842 (0.842)\tdata 0.775 (0.775)\teta 0:00:34\tloss 0.8193 (0.8193)\tacc 75.0000 (75.0000)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.067 (0.454)\tdata 0.001 (0.388)\teta 0:00:18\tloss 0.7407 (0.7800)\tacc 71.8750 (73.4375)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.779 (0.779)\tdata 0.672 (0.672)\teta 0:00:30\tloss 0.7856 (0.7856)\tacc 68.7500 (68.7500)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.067 (0.423)\tdata 0.000 (0.336)\teta 0:00:16\tloss 0.8198 (0.8027)\tacc 78.1250 (73.4375)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.594 (0.594)\tdata 0.517 (0.517)\teta 0:00:21\tloss 0.8687 (0.8687)\tacc 71.8750 (71.8750)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.074 (0.334)\tdata 0.000 (0.259)\teta 0:00:12\tloss 0.8906 (0.8796)\tacc 75.0000 (73.4375)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.597 (0.597)\tdata 0.535 (0.535)\teta 0:00:20\tloss 0.9038 (0.9038)\tacc 62.5000 (62.5000)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.268)\teta 0:00:11\tloss 0.6641 (0.7839)\tacc 68.7500 (65.6250)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.587 (0.587)\tdata 0.525 (0.525)\teta 0:00:19\tloss 0.6865 (0.6865)\tacc 71.8750 (71.8750)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.065 (0.326)\tdata 0.000 (0.263)\teta 0:00:10\tloss 0.9746 (0.8306)\tacc 59.3750 (65.6250)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.611 (0.611)\tdata 0.535 (0.535)\teta 0:00:18\tloss 0.7305 (0.7305)\tacc 75.0000 (75.0000)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.075 (0.343)\tdata 0.000 (0.268)\teta 0:00:10\tloss 0.7183 (0.7244)\tacc 68.7500 (71.8750)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.583 (0.583)\tdata 0.520 (0.520)\teta 0:00:16\tloss 1.0508 (1.0508)\tacc 56.2500 (56.2500)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.063 (0.323)\tdata 0.000 (0.260)\teta 0:00:09\tloss 0.9731 (1.0120)\tacc 68.7500 (62.5000)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.601 (0.601)\tdata 0.538 (0.538)\teta 0:00:16\tloss 0.7524 (0.7524)\tacc 75.0000 (75.0000)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.065 (0.333)\tdata 0.000 (0.269)\teta 0:00:08\tloss 0.8843 (0.8184)\tacc 65.6250 (70.3125)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.582 (0.582)\tdata 0.519 (0.519)\teta 0:00:14\tloss 0.7896 (0.7896)\tacc 68.7500 (68.7500)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.066 (0.324)\tdata 0.000 (0.260)\teta 0:00:07\tloss 1.0332 (0.9114)\tacc 59.3750 (64.0625)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.585 (0.585)\tdata 0.522 (0.522)\teta 0:00:13\tloss 0.8618 (0.8618)\tacc 71.8750 (71.8750)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.261)\teta 0:00:07\tloss 0.8315 (0.8467)\tacc 75.0000 (73.4375)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.598 (0.598)\tdata 0.522 (0.522)\teta 0:00:12\tloss 0.5479 (0.5479)\tacc 81.2500 (81.2500)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.074 (0.336)\tdata 0.000 (0.261)\teta 0:00:06\tloss 0.8560 (0.7019)\tacc 68.7500 (75.0000)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.598 (0.598)\tdata 0.526 (0.526)\teta 0:00:11\tloss 0.8530 (0.8530)\tacc 65.6250 (65.6250)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.066 (0.332)\tdata 0.001 (0.263)\teta 0:00:05\tloss 0.6152 (0.7341)\tacc 78.1250 (71.8750)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.585 (0.585)\tdata 0.522 (0.522)\teta 0:00:09\tloss 0.5103 (0.5103)\tacc 84.3750 (84.3750)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.261)\teta 0:00:05\tloss 0.7021 (0.6062)\tacc 81.2500 (82.8125)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.589 (0.589)\tdata 0.526 (0.526)\teta 0:00:08\tloss 0.6611 (0.6611)\tacc 75.0000 (75.0000)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.065 (0.327)\tdata 0.000 (0.263)\teta 0:00:04\tloss 1.0195 (0.8403)\tacc 68.7500 (71.8750)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.595 (0.595)\tdata 0.531 (0.531)\teta 0:00:07\tloss 0.6699 (0.6699)\tacc 75.0000 (75.0000)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.064 (0.329)\tdata 0.000 (0.266)\teta 0:00:03\tloss 0.8311 (0.7505)\tacc 71.8750 (73.4375)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.603 (0.603)\tdata 0.540 (0.540)\teta 0:00:06\tloss 1.0898 (1.0898)\tacc 62.5000 (62.5000)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.064 (0.333)\tdata 0.000 (0.270)\teta 0:00:03\tloss 0.7275 (0.9087)\tacc 75.0000 (68.7500)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.631 (0.631)\tdata 0.569 (0.569)\teta 0:00:05\tloss 1.0000 (1.0000)\tacc 59.3750 (59.3750)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.064 (0.348)\tdata 0.000 (0.285)\teta 0:00:02\tloss 0.6729 (0.8364)\tacc 75.0000 (67.1875)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.584 (0.584)\tdata 0.522 (0.522)\teta 0:00:04\tloss 0.5679 (0.5679)\tacc 84.3750 (84.3750)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.068 (0.326)\tdata 0.000 (0.261)\teta 0:00:01\tloss 0.9614 (0.7646)\tacc 65.6250 (75.0000)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.589 (0.589)\tdata 0.525 (0.525)\teta 0:00:02\tloss 0.8286 (0.8286)\tacc 65.6250 (65.6250)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.263)\teta 0:00:01\tloss 0.8071 (0.8179)\tacc 78.1250 (71.8750)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.582 (0.582)\tdata 0.508 (0.508)\teta 0:00:01\tloss 0.7651 (0.7651)\tacc 75.0000 (75.0000)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.072 (0.327)\tdata 0.000 (0.254)\teta 0:00:00\tloss 1.1221 (0.9436)\tacc 65.6250 (70.3125)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.579 (0.579)\tdata 0.514 (0.514)\teta 0:00:00\tloss 0.6260 (0.6260)\tacc 75.0000 (75.0000)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.257)\teta 0:00:00\tloss 1.0361 (0.8311)\tacc 59.3750 (67.1875)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed10/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 36\n",
            "* accuracy: 56.25%\n",
            "* error: 43.75%\n",
            "* macro_f1: 47.99%\n",
            "=> per-class result\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 4\tacc: 44.44%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 6\tacc: 66.67%\n",
            "* average: 57.14%\n",
            "Elapsed: 0:00:49\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed11\n",
            "in jaffe\n",
            "Setting fixed seed: 11\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed11\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 11\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed11\n",
            "RESUME: \n",
            "SEED: 11\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 11772.30it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed11/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.789 (1.789)\tdata 0.573 (0.573)\teta 0:02:57\tloss 1.9355 (1.9355)\tacc 15.6250 (15.6250)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.062 (0.926)\tdata 0.000 (0.287)\teta 0:01:30\tloss 1.9346 (1.9351)\tacc 25.0000 (20.3125)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.579 (0.579)\tdata 0.516 (0.516)\teta 0:00:56\tloss 1.9131 (1.9131)\tacc 12.5000 (12.5000)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.258)\teta 0:00:30\tloss 2.0020 (1.9575)\tacc 25.0000 (18.7500)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.592 (0.592)\tdata 0.530 (0.530)\teta 0:00:56\tloss 1.9062 (1.9062)\tacc 12.5000 (12.5000)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.265)\teta 0:00:30\tloss 1.5879 (1.7471)\tacc 56.2500 (34.3750)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.609 (0.609)\tdata 0.547 (0.547)\teta 0:00:56\tloss 1.8359 (1.8359)\tacc 18.7500 (18.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.065 (0.337)\tdata 0.000 (0.273)\teta 0:00:31\tloss 1.7158 (1.7759)\tacc 40.6250 (29.6875)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.591 (0.591)\tdata 0.528 (0.528)\teta 0:00:53\tloss 1.5908 (1.5908)\tacc 40.6250 (40.6250)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.065 (0.328)\tdata 0.000 (0.264)\teta 0:00:29\tloss 1.8408 (1.7158)\tacc 43.7500 (42.1875)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.974 (0.974)\tdata 0.905 (0.905)\teta 0:01:26\tloss 1.6230 (1.6230)\tacc 56.2500 (56.2500)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.067 (0.521)\tdata 0.000 (0.452)\teta 0:00:45\tloss 1.5889 (1.6060)\tacc 50.0000 (53.1250)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.847 (0.847)\tdata 0.780 (0.780)\teta 0:01:13\tloss 1.6260 (1.6260)\tacc 46.8750 (46.8750)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.065 (0.456)\tdata 0.001 (0.390)\teta 0:00:39\tloss 1.4756 (1.5508)\tacc 40.6250 (43.7500)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.861 (0.861)\tdata 0.782 (0.782)\teta 0:01:13\tloss 1.4375 (1.4375)\tacc 40.6250 (40.6250)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.066 (0.463)\tdata 0.000 (0.391)\teta 0:00:38\tloss 1.4746 (1.4561)\tacc 46.8750 (43.7500)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.969 (0.969)\tdata 0.872 (0.872)\teta 0:01:20\tloss 1.4951 (1.4951)\tacc 50.0000 (50.0000)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.084 (0.526)\tdata 0.000 (0.436)\teta 0:00:43\tloss 1.4033 (1.4492)\tacc 40.6250 (45.3125)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.967 (0.967)\tdata 0.898 (0.898)\teta 0:01:18\tloss 1.4131 (1.4131)\tacc 59.3750 (59.3750)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.067 (0.517)\tdata 0.001 (0.449)\teta 0:00:41\tloss 1.1494 (1.2812)\tacc 62.5000 (60.9375)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.851 (0.851)\tdata 0.751 (0.751)\teta 0:01:07\tloss 1.1270 (1.1270)\tacc 59.3750 (59.3750)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.066 (0.459)\tdata 0.000 (0.375)\teta 0:00:35\tloss 1.2588 (1.1929)\tacc 43.7500 (51.5625)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.896 (0.896)\tdata 0.811 (0.811)\teta 0:01:09\tloss 1.0625 (1.0625)\tacc 59.3750 (59.3750)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.084 (0.490)\tdata 0.001 (0.406)\teta 0:00:37\tloss 1.0898 (1.0762)\tacc 62.5000 (60.9375)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.853 (0.853)\tdata 0.784 (0.784)\teta 0:01:03\tloss 1.1963 (1.1963)\tacc 56.2500 (56.2500)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.067 (0.460)\tdata 0.000 (0.392)\teta 0:00:34\tloss 0.9072 (1.0518)\tacc 71.8750 (64.0625)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.893 (0.893)\tdata 0.812 (0.812)\teta 0:01:05\tloss 1.2754 (1.2754)\tacc 50.0000 (50.0000)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.066 (0.479)\tdata 0.001 (0.406)\teta 0:00:34\tloss 1.0186 (1.1470)\tacc 53.1250 (51.5625)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.896 (0.896)\tdata 0.813 (0.813)\teta 0:01:03\tloss 0.8569 (0.8569)\tacc 78.1250 (78.1250)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.067 (0.482)\tdata 0.001 (0.407)\teta 0:00:33\tloss 1.1035 (0.9802)\tacc 56.2500 (67.1875)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.579 (0.579)\tdata 0.515 (0.515)\teta 0:00:39\tloss 1.1377 (1.1377)\tacc 68.7500 (68.7500)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.065 (0.322)\tdata 0.000 (0.258)\teta 0:00:21\tloss 0.9561 (1.0469)\tacc 65.6250 (67.1875)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.586 (0.586)\tdata 0.523 (0.523)\teta 0:00:39\tloss 1.0488 (1.0488)\tacc 62.5000 (62.5000)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.065 (0.326)\tdata 0.000 (0.262)\teta 0:00:21\tloss 0.9551 (1.0020)\tacc 65.6250 (64.0625)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.581 (0.581)\tdata 0.517 (0.517)\teta 0:00:37\tloss 0.9438 (0.9438)\tacc 65.6250 (65.6250)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.259)\teta 0:00:20\tloss 1.2295 (1.0867)\tacc 62.5000 (64.0625)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.643 (0.643)\tdata 0.567 (0.567)\teta 0:00:40\tloss 1.0967 (1.0967)\tacc 62.5000 (62.5000)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.074 (0.359)\tdata 0.000 (0.284)\teta 0:00:22\tloss 0.8750 (0.9858)\tacc 68.7500 (65.6250)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.611 (0.611)\tdata 0.549 (0.549)\teta 0:00:37\tloss 1.1201 (1.1201)\tacc 65.6250 (65.6250)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.068 (0.339)\tdata 0.000 (0.274)\teta 0:00:20\tloss 0.9712 (1.0457)\tacc 68.7500 (67.1875)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.596 (0.596)\tdata 0.534 (0.534)\teta 0:00:35\tloss 1.3477 (1.3477)\tacc 40.6250 (40.6250)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:19\tloss 1.0225 (1.1851)\tacc 59.3750 (50.0000)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.601 (0.601)\tdata 0.529 (0.529)\teta 0:00:34\tloss 1.0215 (1.0215)\tacc 65.6250 (65.6250)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.070 (0.336)\tdata 0.000 (0.264)\teta 0:00:18\tloss 0.8296 (0.9255)\tacc 71.8750 (68.7500)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.583 (0.583)\tdata 0.518 (0.518)\teta 0:00:32\tloss 0.8438 (0.8438)\tacc 71.8750 (71.8750)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.259)\teta 0:00:17\tloss 1.0615 (0.9526)\tacc 62.5000 (67.1875)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.597 (0.597)\tdata 0.535 (0.535)\teta 0:00:31\tloss 1.1924 (1.1924)\tacc 50.0000 (50.0000)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.268)\teta 0:00:17\tloss 0.8364 (1.0144)\tacc 75.0000 (62.5000)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.577 (0.577)\tdata 0.513 (0.513)\teta 0:00:29\tloss 1.3457 (1.3457)\tacc 43.7500 (43.7500)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.065 (0.321)\tdata 0.000 (0.257)\teta 0:00:16\tloss 0.9238 (1.1348)\tacc 75.0000 (59.3750)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.582 (0.582)\tdata 0.519 (0.519)\teta 0:00:28\tloss 0.7866 (0.7866)\tacc 78.1250 (78.1250)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.260)\teta 0:00:15\tloss 0.9248 (0.8557)\tacc 75.0000 (76.5625)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.591 (0.591)\tdata 0.527 (0.527)\teta 0:00:27\tloss 1.0234 (1.0234)\tacc 65.6250 (65.6250)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:15\tloss 0.8457 (0.9346)\tacc 71.8750 (68.7500)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.583 (0.583)\tdata 0.520 (0.520)\teta 0:00:26\tloss 1.0654 (1.0654)\tacc 75.0000 (75.0000)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.260)\teta 0:00:14\tloss 0.8950 (0.9802)\tacc 81.2500 (78.1250)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.604 (0.604)\tdata 0.541 (0.541)\teta 0:00:25\tloss 0.9531 (0.9531)\tacc 68.7500 (68.7500)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.271)\teta 0:00:14\tloss 0.8330 (0.8931)\tacc 75.0000 (71.8750)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.597 (0.597)\tdata 0.535 (0.535)\teta 0:00:24\tloss 0.7407 (0.7407)\tacc 81.2500 (81.2500)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.268)\teta 0:00:13\tloss 0.7744 (0.7576)\tacc 78.1250 (79.6875)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.583 (0.583)\tdata 0.519 (0.519)\teta 0:00:22\tloss 0.7695 (0.7695)\tacc 68.7500 (68.7500)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.260)\teta 0:00:12\tloss 0.6631 (0.7163)\tacc 87.5000 (78.1250)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.584 (0.584)\tdata 0.519 (0.519)\teta 0:00:21\tloss 0.7202 (0.7202)\tacc 81.2500 (81.2500)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.260)\teta 0:00:11\tloss 0.9170 (0.8186)\tacc 71.8750 (76.5625)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.580 (0.580)\tdata 0.516 (0.516)\teta 0:00:20\tloss 0.5469 (0.5469)\tacc 84.3750 (84.3750)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.065 (0.322)\tdata 0.000 (0.258)\teta 0:00:10\tloss 0.7925 (0.6697)\tacc 75.0000 (79.6875)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.588 (0.588)\tdata 0.514 (0.514)\teta 0:00:19\tloss 1.0234 (1.0234)\tacc 65.6250 (65.6250)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.072 (0.330)\tdata 0.000 (0.257)\teta 0:00:10\tloss 0.8911 (0.9573)\tacc 65.6250 (65.6250)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.596 (0.596)\tdata 0.528 (0.528)\teta 0:00:18\tloss 0.8491 (0.8491)\tacc 78.1250 (78.1250)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.066 (0.331)\tdata 0.000 (0.264)\teta 0:00:09\tloss 0.7383 (0.7937)\tacc 81.2500 (79.6875)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.568 (0.568)\tdata 0.503 (0.503)\teta 0:00:16\tloss 1.0020 (1.0020)\tacc 59.3750 (59.3750)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.065 (0.317)\tdata 0.000 (0.252)\teta 0:00:08\tloss 0.9541 (0.9780)\tacc 68.7500 (64.0625)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.581 (0.581)\tdata 0.519 (0.519)\teta 0:00:15\tloss 1.0371 (1.0371)\tacc 56.2500 (56.2500)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.065 (0.323)\tdata 0.000 (0.259)\teta 0:00:08\tloss 0.6138 (0.8254)\tacc 81.2500 (68.7500)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.584 (0.584)\tdata 0.519 (0.519)\teta 0:00:14\tloss 0.8311 (0.8311)\tacc 71.8750 (71.8750)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.064 (0.324)\tdata 0.001 (0.260)\teta 0:00:07\tloss 0.8608 (0.8459)\tacc 68.7500 (70.3125)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.572 (0.572)\tdata 0.509 (0.509)\teta 0:00:13\tloss 0.9170 (0.9170)\tacc 71.8750 (71.8750)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.065 (0.319)\tdata 0.000 (0.254)\teta 0:00:07\tloss 1.0928 (1.0049)\tacc 56.2500 (64.0625)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.592 (0.592)\tdata 0.529 (0.529)\teta 0:00:12\tloss 0.9131 (0.9131)\tacc 68.7500 (68.7500)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.065 (0.328)\tdata 0.000 (0.265)\teta 0:00:06\tloss 0.8867 (0.8999)\tacc 65.6250 (67.1875)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.602 (0.602)\tdata 0.533 (0.533)\teta 0:00:11\tloss 0.6914 (0.6914)\tacc 78.1250 (78.1250)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.064 (0.333)\tdata 0.001 (0.267)\teta 0:00:05\tloss 0.8120 (0.7517)\tacc 71.8750 (75.0000)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.581 (0.581)\tdata 0.519 (0.519)\teta 0:00:09\tloss 0.9746 (0.9746)\tacc 75.0000 (75.0000)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.259)\teta 0:00:05\tloss 0.5591 (0.7668)\tacc 81.2500 (78.1250)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.584 (0.584)\tdata 0.521 (0.521)\teta 0:00:08\tloss 0.6104 (0.6104)\tacc 75.0000 (75.0000)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.261)\teta 0:00:04\tloss 0.9653 (0.7878)\tacc 75.0000 (75.0000)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.593 (0.593)\tdata 0.522 (0.522)\teta 0:00:07\tloss 0.8628 (0.8628)\tacc 75.0000 (75.0000)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.063 (0.328)\tdata 0.000 (0.261)\teta 0:00:03\tloss 0.9443 (0.9036)\tacc 71.8750 (73.4375)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.585 (0.585)\tdata 0.521 (0.521)\teta 0:00:06\tloss 0.9155 (0.9155)\tacc 59.3750 (59.3750)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.066 (0.326)\tdata 0.001 (0.261)\teta 0:00:03\tloss 0.6328 (0.7742)\tacc 84.3750 (71.8750)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.578 (0.578)\tdata 0.510 (0.510)\teta 0:00:05\tloss 1.0420 (1.0420)\tacc 62.5000 (62.5000)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.064 (0.321)\tdata 0.000 (0.255)\teta 0:00:02\tloss 0.9473 (0.9946)\tacc 50.0000 (56.2500)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.598 (0.598)\tdata 0.525 (0.525)\teta 0:00:04\tloss 0.7793 (0.7793)\tacc 71.8750 (71.8750)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.262)\teta 0:00:01\tloss 0.7310 (0.7551)\tacc 81.2500 (76.5625)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.577 (0.577)\tdata 0.513 (0.513)\teta 0:00:02\tloss 0.8506 (0.8506)\tacc 62.5000 (62.5000)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.069 (0.323)\tdata 0.000 (0.257)\teta 0:00:01\tloss 0.6069 (0.7288)\tacc 87.5000 (75.0000)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.597 (0.597)\tdata 0.533 (0.533)\teta 0:00:01\tloss 1.0771 (1.0771)\tacc 59.3750 (59.3750)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.266)\teta 0:00:00\tloss 0.7578 (0.9175)\tacc 75.0000 (67.1875)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.590 (0.590)\tdata 0.526 (0.526)\teta 0:00:00\tloss 0.8774 (0.8774)\tacc 75.0000 (75.0000)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.263)\teta 0:00:00\tloss 0.9482 (0.9128)\tacc 62.5000 (68.7500)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed11/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 27\n",
            "* accuracy: 42.19%\n",
            "* error: 57.81%\n",
            "* macro_f1: 33.52%\n",
            "=> per-class result\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* average: 42.86%\n",
            "Elapsed: 0:00:49\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed12\n",
            "in jaffe\n",
            "Setting fixed seed: 12\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed12\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 12\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed12\n",
            "RESUME: \n",
            "SEED: 12\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 16902.78it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed12/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.816 (1.816)\tdata 0.563 (0.563)\teta 0:02:59\tloss 1.8818 (1.8818)\tacc 25.0000 (25.0000)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.063 (0.939)\tdata 0.001 (0.282)\teta 0:01:32\tloss 1.9307 (1.9062)\tacc 21.8750 (23.4375)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.576 (0.576)\tdata 0.513 (0.513)\teta 0:00:55\tloss 1.9883 (1.9883)\tacc 21.8750 (21.8750)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.064 (0.320)\tdata 0.000 (0.257)\teta 0:00:30\tloss 1.8076 (1.8979)\tacc 43.7500 (32.8125)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.585 (0.585)\tdata 0.520 (0.520)\teta 0:00:55\tloss 1.6660 (1.6660)\tacc 59.3750 (59.3750)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.065 (0.325)\tdata 0.000 (0.260)\teta 0:00:30\tloss 1.5273 (1.5967)\tacc 43.7500 (51.5625)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.596 (0.596)\tdata 0.534 (0.534)\teta 0:00:55\tloss 1.2822 (1.2822)\tacc 50.0000 (50.0000)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.063 (0.329)\tdata 0.000 (0.267)\teta 0:00:30\tloss 1.0977 (1.1899)\tacc 75.0000 (62.5000)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.593 (0.593)\tdata 0.531 (0.531)\teta 0:00:54\tloss 1.2529 (1.2529)\tacc 65.6250 (65.6250)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.063 (0.328)\tdata 0.000 (0.266)\teta 0:00:29\tloss 1.1367 (1.1948)\tacc 50.0000 (57.8125)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.605 (0.605)\tdata 0.541 (0.541)\teta 0:00:53\tloss 1.1084 (1.1084)\tacc 62.5000 (62.5000)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.063 (0.334)\tdata 0.000 (0.271)\teta 0:00:29\tloss 1.1172 (1.1128)\tacc 62.5000 (62.5000)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.583 (0.583)\tdata 0.519 (0.519)\teta 0:00:50\tloss 1.1475 (1.1475)\tacc 59.3750 (59.3750)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.260)\teta 0:00:27\tloss 1.2070 (1.1772)\tacc 62.5000 (60.9375)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.581 (0.581)\tdata 0.514 (0.514)\teta 0:00:49\tloss 1.0020 (1.0020)\tacc 65.6250 (65.6250)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.257)\teta 0:00:27\tloss 1.0508 (1.0264)\tacc 68.7500 (67.1875)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.611 (0.611)\tdata 0.536 (0.536)\teta 0:00:50\tloss 0.9868 (0.9868)\tacc 62.5000 (62.5000)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.071 (0.341)\tdata 0.000 (0.268)\teta 0:00:27\tloss 0.9150 (0.9509)\tacc 68.7500 (65.6250)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.610 (0.610)\tdata 0.543 (0.543)\teta 0:00:49\tloss 1.0283 (1.0283)\tacc 56.2500 (56.2500)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.063 (0.337)\tdata 0.000 (0.271)\teta 0:00:26\tloss 0.7456 (0.8870)\tacc 75.0000 (65.6250)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.596 (0.596)\tdata 0.534 (0.534)\teta 0:00:47\tloss 1.2383 (1.2383)\tacc 56.2500 (56.2500)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.063 (0.330)\tdata 0.000 (0.267)\teta 0:00:25\tloss 0.8291 (1.0337)\tacc 68.7500 (62.5000)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.585 (0.585)\tdata 0.521 (0.521)\teta 0:00:45\tloss 0.8184 (0.8184)\tacc 75.0000 (75.0000)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.261)\teta 0:00:24\tloss 0.7070 (0.7627)\tacc 81.2500 (78.1250)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.591 (0.591)\tdata 0.528 (0.528)\teta 0:00:44\tloss 1.0566 (1.0566)\tacc 53.1250 (53.1250)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:24\tloss 1.0557 (1.0562)\tacc 65.6250 (59.3750)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.599 (0.599)\tdata 0.525 (0.525)\teta 0:00:43\tloss 0.9307 (0.9307)\tacc 65.6250 (65.6250)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.070 (0.335)\tdata 0.000 (0.263)\teta 0:00:24\tloss 0.7964 (0.8635)\tacc 75.0000 (70.3125)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.614 (0.614)\tdata 0.551 (0.551)\teta 0:00:43\tloss 0.9761 (0.9761)\tacc 65.6250 (65.6250)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.064 (0.339)\tdata 0.000 (0.276)\teta 0:00:23\tloss 0.7705 (0.8733)\tacc 71.8750 (68.7500)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.589 (0.589)\tdata 0.527 (0.527)\teta 0:00:40\tloss 0.9370 (0.9370)\tacc 62.5000 (62.5000)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.065 (0.327)\tdata 0.000 (0.263)\teta 0:00:22\tloss 1.0371 (0.9871)\tacc 62.5000 (62.5000)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.590 (0.590)\tdata 0.527 (0.527)\teta 0:00:39\tloss 0.7598 (0.7598)\tacc 71.8750 (71.8750)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.063 (0.327)\tdata 0.000 (0.264)\teta 0:00:21\tloss 0.9917 (0.8757)\tacc 65.6250 (68.7500)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.592 (0.592)\tdata 0.529 (0.529)\teta 0:00:38\tloss 0.6895 (0.6895)\tacc 84.3750 (84.3750)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.265)\teta 0:00:20\tloss 0.9023 (0.7959)\tacc 68.7500 (76.5625)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.628 (0.628)\tdata 0.566 (0.566)\teta 0:00:39\tloss 1.1035 (1.1035)\tacc 59.3750 (59.3750)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.064 (0.346)\tdata 0.001 (0.283)\teta 0:00:21\tloss 0.8110 (0.9573)\tacc 71.8750 (65.6250)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.600 (0.600)\tdata 0.538 (0.538)\teta 0:00:36\tloss 0.5889 (0.5889)\tacc 81.2500 (81.2500)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.064 (0.332)\tdata 0.000 (0.269)\teta 0:00:19\tloss 1.0840 (0.8364)\tacc 68.7500 (75.0000)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.591 (0.591)\tdata 0.526 (0.526)\teta 0:00:34\tloss 0.7080 (0.7080)\tacc 71.8750 (71.8750)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.263)\teta 0:00:19\tloss 0.6201 (0.6641)\tacc 81.2500 (76.5625)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.600 (0.600)\tdata 0.537 (0.537)\teta 0:00:34\tloss 0.6460 (0.6460)\tacc 78.1250 (78.1250)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.065 (0.333)\tdata 0.000 (0.269)\teta 0:00:18\tloss 0.8760 (0.7610)\tacc 68.7500 (73.4375)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.630 (0.630)\tdata 0.567 (0.567)\teta 0:00:34\tloss 0.9302 (0.9302)\tacc 65.6250 (65.6250)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.065 (0.347)\tdata 0.000 (0.284)\teta 0:00:18\tloss 0.8247 (0.8774)\tacc 71.8750 (68.7500)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.587 (0.587)\tdata 0.523 (0.523)\teta 0:00:31\tloss 0.4717 (0.4717)\tacc 87.5000 (87.5000)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.262)\teta 0:00:16\tloss 0.7373 (0.6045)\tacc 75.0000 (81.2500)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.591 (0.591)\tdata 0.528 (0.528)\teta 0:00:30\tloss 0.5459 (0.5459)\tacc 84.3750 (84.3750)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.065 (0.328)\tdata 0.000 (0.264)\teta 0:00:16\tloss 0.7041 (0.6250)\tacc 81.2500 (82.8125)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.591 (0.591)\tdata 0.528 (0.528)\teta 0:00:28\tloss 0.6104 (0.6104)\tacc 78.1250 (78.1250)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:15\tloss 0.9678 (0.7891)\tacc 62.5000 (70.3125)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.580 (0.580)\tdata 0.515 (0.515)\teta 0:00:27\tloss 0.4827 (0.4827)\tacc 87.5000 (87.5000)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.258)\teta 0:00:14\tloss 0.6616 (0.5721)\tacc 81.2500 (84.3750)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.594 (0.594)\tdata 0.532 (0.532)\teta 0:00:26\tloss 0.6064 (0.6064)\tacc 78.1250 (78.1250)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.063 (0.329)\tdata 0.000 (0.266)\teta 0:00:14\tloss 0.7363 (0.6714)\tacc 78.1250 (78.1250)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.571 (0.571)\tdata 0.506 (0.506)\teta 0:00:24\tloss 0.6450 (0.6450)\tacc 78.1250 (78.1250)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.065 (0.318)\tdata 0.000 (0.253)\teta 0:00:13\tloss 0.7295 (0.6873)\tacc 71.8750 (75.0000)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.581 (0.581)\tdata 0.516 (0.516)\teta 0:00:23\tloss 0.7573 (0.7573)\tacc 71.8750 (71.8750)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.065 (0.323)\tdata 0.000 (0.258)\teta 0:00:12\tloss 0.6597 (0.7085)\tacc 75.0000 (73.4375)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.580 (0.580)\tdata 0.515 (0.515)\teta 0:00:22\tloss 0.7090 (0.7090)\tacc 75.0000 (75.0000)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.258)\teta 0:00:12\tloss 0.7983 (0.7537)\tacc 68.7500 (71.8750)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.587 (0.587)\tdata 0.522 (0.522)\teta 0:00:21\tloss 0.8169 (0.8169)\tacc 71.8750 (71.8750)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.261)\teta 0:00:11\tloss 0.6450 (0.7310)\tacc 81.2500 (76.5625)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.591 (0.591)\tdata 0.528 (0.528)\teta 0:00:20\tloss 0.8882 (0.8882)\tacc 62.5000 (62.5000)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.264)\teta 0:00:11\tloss 0.3079 (0.5980)\tacc 90.6250 (76.5625)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.605 (0.605)\tdata 0.539 (0.539)\teta 0:00:19\tloss 0.7886 (0.7886)\tacc 68.7500 (68.7500)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.063 (0.334)\tdata 0.000 (0.269)\teta 0:00:10\tloss 0.5620 (0.6753)\tacc 84.3750 (76.5625)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.573 (0.573)\tdata 0.508 (0.508)\teta 0:00:17\tloss 0.6187 (0.6187)\tacc 78.1250 (78.1250)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.065 (0.319)\tdata 0.000 (0.254)\teta 0:00:09\tloss 0.8721 (0.7454)\tacc 62.5000 (70.3125)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.618 (0.618)\tdata 0.553 (0.553)\teta 0:00:17\tloss 0.6860 (0.6860)\tacc 65.6250 (65.6250)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.064 (0.341)\tdata 0.000 (0.277)\teta 0:00:09\tloss 0.7461 (0.7161)\tacc 75.0000 (70.3125)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.659 (0.659)\tdata 0.588 (0.588)\teta 0:00:17\tloss 0.7295 (0.7295)\tacc 75.0000 (75.0000)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.066 (0.362)\tdata 0.001 (0.295)\teta 0:00:09\tloss 0.7065 (0.7180)\tacc 75.0000 (75.0000)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.853 (0.853)\tdata 0.761 (0.761)\teta 0:00:21\tloss 0.6548 (0.6548)\tacc 78.1250 (78.1250)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.065 (0.459)\tdata 0.001 (0.381)\teta 0:00:11\tloss 0.4695 (0.5621)\tacc 87.5000 (82.8125)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.835 (0.835)\tdata 0.749 (0.749)\teta 0:00:19\tloss 0.5015 (0.5015)\tacc 84.3750 (84.3750)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.082 (0.459)\tdata 0.000 (0.375)\teta 0:00:10\tloss 0.6123 (0.5569)\tacc 81.2500 (82.8125)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.833 (0.833)\tdata 0.753 (0.753)\teta 0:00:17\tloss 0.6816 (0.6816)\tacc 75.0000 (75.0000)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.090 (0.462)\tdata 0.022 (0.388)\teta 0:00:09\tloss 0.7979 (0.7397)\tacc 68.7500 (71.8750)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.846 (0.846)\tdata 0.749 (0.749)\teta 0:00:16\tloss 0.7847 (0.7847)\tacc 68.7500 (68.7500)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.084 (0.465)\tdata 0.001 (0.375)\teta 0:00:08\tloss 0.7314 (0.7581)\tacc 68.7500 (68.7500)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.959 (0.959)\tdata 0.878 (0.878)\teta 0:00:16\tloss 0.7568 (0.7568)\tacc 71.8750 (71.8750)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.079 (0.519)\tdata 0.000 (0.439)\teta 0:00:08\tloss 0.6919 (0.7244)\tacc 87.5000 (79.6875)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.880 (0.880)\tdata 0.807 (0.807)\teta 0:00:13\tloss 0.6392 (0.6392)\tacc 84.3750 (84.3750)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.069 (0.474)\tdata 0.000 (0.403)\teta 0:00:06\tloss 0.6177 (0.6284)\tacc 84.3750 (84.3750)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.856 (0.856)\tdata 0.783 (0.783)\teta 0:00:11\tloss 0.8281 (0.8281)\tacc 62.5000 (62.5000)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.065 (0.461)\tdata 0.000 (0.391)\teta 0:00:05\tloss 0.5020 (0.6650)\tacc 78.1250 (70.3125)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.922 (0.922)\tdata 0.854 (0.854)\teta 0:00:10\tloss 0.7466 (0.7466)\tacc 75.0000 (75.0000)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.067 (0.495)\tdata 0.001 (0.427)\teta 0:00:04\tloss 0.8013 (0.7739)\tacc 71.8750 (73.4375)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.929 (0.929)\tdata 0.848 (0.848)\teta 0:00:08\tloss 0.4368 (0.4368)\tacc 84.3750 (84.3750)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.068 (0.498)\tdata 0.000 (0.424)\teta 0:00:03\tloss 0.7061 (0.5714)\tacc 75.0000 (79.6875)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.891 (0.891)\tdata 0.803 (0.803)\teta 0:00:06\tloss 0.6714 (0.6714)\tacc 78.1250 (78.1250)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.080 (0.485)\tdata 0.000 (0.401)\teta 0:00:02\tloss 0.6577 (0.6646)\tacc 75.0000 (76.5625)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.602 (0.602)\tdata 0.535 (0.535)\teta 0:00:03\tloss 0.4814 (0.4814)\tacc 84.3750 (84.3750)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.065 (0.334)\tdata 0.000 (0.268)\teta 0:00:01\tloss 0.6172 (0.5493)\tacc 81.2500 (82.8125)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.596 (0.596)\tdata 0.533 (0.533)\teta 0:00:01\tloss 0.5308 (0.5308)\tacc 75.0000 (75.0000)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:00\tloss 0.7749 (0.6528)\tacc 68.7500 (71.8750)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.593 (0.593)\tdata 0.531 (0.531)\teta 0:00:00\tloss 0.8306 (0.8306)\tacc 62.5000 (62.5000)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.065 (0.329)\tdata 0.000 (0.266)\teta 0:00:00\tloss 0.7632 (0.7969)\tacc 71.8750 (67.1875)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed12/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 30\n",
            "* accuracy: 46.88%\n",
            "* error: 53.12%\n",
            "* macro_f1: 40.04%\n",
            "=> per-class result\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 4\tacc: 44.44%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 7\tacc: 77.78%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 2\tacc: 22.22%\n",
            "* average: 47.62%\n",
            "Elapsed: 0:00:50\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed13\n",
            "in jaffe\n",
            "Setting fixed seed: 13\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed13\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 13\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed13\n",
            "RESUME: \n",
            "SEED: 13\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 11896.32it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed13/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.918 (1.918)\tdata 0.702 (0.702)\teta 0:03:09\tloss 3.2051 (3.2051)\tacc 3.1250 (3.1250)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.063 (0.990)\tdata 0.000 (0.351)\teta 0:01:37\tloss 2.9551 (3.0801)\tacc 6.2500 (4.6875)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.581 (0.581)\tdata 0.515 (0.515)\teta 0:00:56\tloss 2.6953 (2.6953)\tacc 3.1250 (3.1250)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.065 (0.323)\tdata 0.000 (0.257)\teta 0:00:31\tloss 1.8164 (2.2559)\tacc 34.3750 (18.7500)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.589 (0.589)\tdata 0.526 (0.526)\teta 0:00:55\tloss 1.8340 (1.8340)\tacc 34.3750 (34.3750)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.263)\teta 0:00:30\tloss 1.9053 (1.8696)\tacc 34.3750 (34.3750)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.596 (0.596)\tdata 0.533 (0.533)\teta 0:00:55\tloss 1.8945 (1.8945)\tacc 31.2500 (31.2500)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.065 (0.331)\tdata 0.000 (0.267)\teta 0:00:30\tloss 1.8672 (1.8809)\tacc 31.2500 (31.2500)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.604 (0.604)\tdata 0.542 (0.542)\teta 0:00:54\tloss 1.8398 (1.8398)\tacc 31.2500 (31.2500)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.271)\teta 0:00:30\tloss 2.0605 (1.9502)\tacc 15.6250 (23.4375)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.614 (0.614)\tdata 0.551 (0.551)\teta 0:00:54\tloss 1.9541 (1.9541)\tacc 18.7500 (18.7500)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.064 (0.339)\tdata 0.000 (0.275)\teta 0:00:29\tloss 1.7637 (1.8589)\tacc 53.1250 (35.9375)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.592 (0.592)\tdata 0.529 (0.529)\teta 0:00:51\tloss 1.9053 (1.9053)\tacc 25.0000 (25.0000)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.064 (0.328)\tdata 0.001 (0.265)\teta 0:00:28\tloss 1.8604 (1.8828)\tacc 31.2500 (28.1250)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.578 (0.578)\tdata 0.514 (0.514)\teta 0:00:49\tloss 1.8398 (1.8398)\tacc 31.2500 (31.2500)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.065 (0.322)\tdata 0.000 (0.257)\teta 0:00:27\tloss 1.8369 (1.8384)\tacc 31.2500 (31.2500)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.600 (0.600)\tdata 0.526 (0.526)\teta 0:00:49\tloss 1.8662 (1.8662)\tacc 31.2500 (31.2500)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.063 (0.332)\tdata 0.000 (0.263)\teta 0:00:27\tloss 1.7441 (1.8052)\tacc 46.8750 (39.0625)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.607 (0.607)\tdata 0.544 (0.544)\teta 0:00:49\tloss 1.7021 (1.7021)\tacc 43.7500 (43.7500)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.065 (0.336)\tdata 0.000 (0.272)\teta 0:00:26\tloss 1.8955 (1.7988)\tacc 28.1250 (35.9375)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.589 (0.589)\tdata 0.528 (0.528)\teta 0:00:46\tloss 1.7549 (1.7549)\tacc 34.3750 (34.3750)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.264)\teta 0:00:25\tloss 1.7852 (1.7700)\tacc 37.5000 (35.9375)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.610 (0.610)\tdata 0.546 (0.546)\teta 0:00:46\tloss 1.7227 (1.7227)\tacc 37.5000 (37.5000)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.063 (0.336)\tdata 0.000 (0.273)\teta 0:00:25\tloss 1.8379 (1.7803)\tacc 25.0000 (31.2500)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.586 (0.586)\tdata 0.524 (0.524)\teta 0:00:43\tloss 1.6914 (1.6914)\tacc 43.7500 (43.7500)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.262)\teta 0:00:24\tloss 1.7930 (1.7422)\tacc 31.2500 (37.5000)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.596 (0.596)\tdata 0.533 (0.533)\teta 0:00:43\tloss 1.8271 (1.8271)\tacc 34.3750 (34.3750)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.063 (0.330)\tdata 0.000 (0.267)\teta 0:00:23\tloss 1.6338 (1.7305)\tacc 50.0000 (42.1875)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.591 (0.591)\tdata 0.526 (0.526)\teta 0:00:41\tloss 1.6045 (1.6045)\tacc 46.8750 (46.8750)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.063 (0.327)\tdata 0.000 (0.263)\teta 0:00:22\tloss 1.8643 (1.7344)\tacc 31.2500 (39.0625)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.870 (0.870)\tdata 0.799 (0.799)\teta 0:01:00\tloss 1.6758 (1.6758)\tacc 46.8750 (46.8750)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.066 (0.468)\tdata 0.000 (0.400)\teta 0:00:31\tloss 1.7490 (1.7124)\tacc 37.5000 (42.1875)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.977 (0.977)\tdata 0.881 (0.881)\teta 0:01:05\tloss 1.7139 (1.7139)\tacc 40.6250 (40.6250)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.078 (0.527)\tdata 0.000 (0.440)\teta 0:00:34\tloss 1.6943 (1.7041)\tacc 46.8750 (43.7500)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.944 (0.944)\tdata 0.872 (0.872)\teta 0:01:01\tloss 1.7832 (1.7832)\tacc 40.6250 (40.6250)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.069 (0.507)\tdata 0.000 (0.436)\teta 0:00:32\tloss 1.4746 (1.6289)\tacc 56.2500 (48.4375)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.933 (0.933)\tdata 0.864 (0.864)\teta 0:00:58\tloss 1.5996 (1.5996)\tacc 46.8750 (46.8750)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.067 (0.500)\tdata 0.000 (0.432)\teta 0:00:30\tloss 1.8096 (1.7046)\tacc 31.2500 (39.0625)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.805 (0.805)\tdata 0.737 (0.737)\teta 0:00:49\tloss 1.6602 (1.6602)\tacc 40.6250 (40.6250)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.066 (0.436)\tdata 0.000 (0.369)\teta 0:00:26\tloss 1.6299 (1.6450)\tacc 43.7500 (42.1875)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.906 (0.906)\tdata 0.837 (0.837)\teta 0:00:53\tloss 1.4824 (1.4824)\tacc 50.0000 (50.0000)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.067 (0.486)\tdata 0.000 (0.419)\teta 0:00:28\tloss 1.5752 (1.5288)\tacc 40.6250 (45.3125)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.836 (0.836)\tdata 0.738 (0.738)\teta 0:00:47\tloss 1.6250 (1.6250)\tacc 34.3750 (34.3750)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.067 (0.452)\tdata 0.000 (0.369)\teta 0:00:25\tloss 1.5020 (1.5635)\tacc 53.1250 (43.7500)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.913 (0.913)\tdata 0.830 (0.830)\teta 0:00:50\tloss 1.4844 (1.4844)\tacc 56.2500 (56.2500)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.082 (0.498)\tdata 0.001 (0.415)\teta 0:00:26\tloss 1.5488 (1.5166)\tacc 50.0000 (53.1250)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.821 (0.821)\tdata 0.754 (0.754)\teta 0:00:43\tloss 1.5889 (1.5889)\tacc 40.6250 (40.6250)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.067 (0.444)\tdata 0.000 (0.377)\teta 0:00:23\tloss 1.5703 (1.5796)\tacc 40.6250 (40.6250)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.935 (0.935)\tdata 0.858 (0.858)\teta 0:00:47\tloss 1.3125 (1.3125)\tacc 59.3750 (59.3750)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.067 (0.501)\tdata 0.001 (0.429)\teta 0:00:25\tloss 1.6143 (1.4634)\tacc 43.7500 (51.5625)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.698 (0.698)\tdata 0.636 (0.636)\teta 0:00:34\tloss 1.5410 (1.5410)\tacc 50.0000 (50.0000)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.064 (0.381)\tdata 0.000 (0.318)\teta 0:00:18\tloss 1.5176 (1.5293)\tacc 46.8750 (48.4375)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.611 (0.611)\tdata 0.548 (0.548)\teta 0:00:28\tloss 1.5127 (1.5127)\tacc 43.7500 (43.7500)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.063 (0.337)\tdata 0.000 (0.274)\teta 0:00:15\tloss 1.5586 (1.5356)\tacc 43.7500 (43.7500)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.592 (0.592)\tdata 0.525 (0.525)\teta 0:00:26\tloss 1.3789 (1.3789)\tacc 56.2500 (56.2500)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.263)\teta 0:00:14\tloss 1.5508 (1.4648)\tacc 46.8750 (51.5625)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.588 (0.588)\tdata 0.525 (0.525)\teta 0:00:25\tloss 1.4629 (1.4629)\tacc 46.8750 (46.8750)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.063 (0.326)\tdata 0.000 (0.263)\teta 0:00:13\tloss 1.3232 (1.3931)\tacc 56.2500 (51.5625)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.609 (0.609)\tdata 0.537 (0.537)\teta 0:00:24\tloss 1.1992 (1.1992)\tacc 65.6250 (65.6250)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.069 (0.339)\tdata 0.000 (0.268)\teta 0:00:13\tloss 1.5811 (1.3901)\tacc 43.7500 (54.6875)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.596 (0.596)\tdata 0.534 (0.534)\teta 0:00:23\tloss 1.5908 (1.5908)\tacc 40.6250 (40.6250)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:12\tloss 1.5225 (1.5566)\tacc 37.5000 (39.0625)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.599 (0.599)\tdata 0.537 (0.537)\teta 0:00:22\tloss 1.4795 (1.4795)\tacc 43.7500 (43.7500)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.065 (0.332)\tdata 0.000 (0.268)\teta 0:00:11\tloss 1.3232 (1.4014)\tacc 50.0000 (46.8750)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.584 (0.584)\tdata 0.520 (0.520)\teta 0:00:20\tloss 1.4326 (1.4326)\tacc 53.1250 (53.1250)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.063 (0.324)\tdata 0.000 (0.260)\teta 0:00:11\tloss 1.4795 (1.4561)\tacc 37.5000 (45.3125)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.591 (0.591)\tdata 0.519 (0.519)\teta 0:00:19\tloss 1.5127 (1.5127)\tacc 34.3750 (34.3750)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.070 (0.331)\tdata 0.000 (0.260)\teta 0:00:10\tloss 1.4180 (1.4653)\tacc 53.1250 (43.7500)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.601 (0.601)\tdata 0.537 (0.537)\teta 0:00:18\tloss 1.4316 (1.4316)\tacc 50.0000 (50.0000)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.064 (0.332)\tdata 0.000 (0.269)\teta 0:00:09\tloss 1.3418 (1.3867)\tacc 53.1250 (51.5625)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.596 (0.596)\tdata 0.533 (0.533)\teta 0:00:17\tloss 1.4062 (1.4062)\tacc 43.7500 (43.7500)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.063 (0.329)\tdata 0.000 (0.267)\teta 0:00:09\tloss 1.3428 (1.3745)\tacc 56.2500 (50.0000)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.615 (0.615)\tdata 0.548 (0.548)\teta 0:00:16\tloss 1.4531 (1.4531)\tacc 43.7500 (43.7500)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.063 (0.339)\tdata 0.001 (0.274)\teta 0:00:08\tloss 1.4043 (1.4287)\tacc 46.8750 (45.3125)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.617 (0.617)\tdata 0.554 (0.554)\teta 0:00:15\tloss 1.5186 (1.5186)\tacc 37.5000 (37.5000)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.064 (0.340)\tdata 0.000 (0.277)\teta 0:00:08\tloss 1.3350 (1.4268)\tacc 56.2500 (46.8750)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.592 (0.592)\tdata 0.529 (0.529)\teta 0:00:13\tloss 1.2812 (1.2812)\tacc 50.0000 (50.0000)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.265)\teta 0:00:07\tloss 1.6074 (1.4443)\tacc 37.5000 (43.7500)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.592 (0.592)\tdata 0.530 (0.530)\teta 0:00:12\tloss 1.5146 (1.5146)\tacc 43.7500 (43.7500)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.067 (0.330)\tdata 0.000 (0.265)\teta 0:00:06\tloss 1.5273 (1.5210)\tacc 34.3750 (39.0625)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.590 (0.590)\tdata 0.525 (0.525)\teta 0:00:11\tloss 1.4248 (1.4248)\tacc 46.8750 (46.8750)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.263)\teta 0:00:05\tloss 1.4219 (1.4233)\tacc 50.0000 (48.4375)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.604 (0.604)\tdata 0.541 (0.541)\teta 0:00:10\tloss 1.3252 (1.3252)\tacc 50.0000 (50.0000)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.065 (0.335)\tdata 0.000 (0.271)\teta 0:00:05\tloss 1.4238 (1.3745)\tacc 50.0000 (50.0000)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.605 (0.605)\tdata 0.542 (0.542)\teta 0:00:09\tloss 1.3682 (1.3682)\tacc 50.0000 (50.0000)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.065 (0.335)\tdata 0.000 (0.271)\teta 0:00:04\tloss 1.5293 (1.4487)\tacc 37.5000 (43.7500)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.579 (0.579)\tdata 0.515 (0.515)\teta 0:00:07\tloss 1.3770 (1.3770)\tacc 56.2500 (56.2500)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.258)\teta 0:00:03\tloss 1.3799 (1.3784)\tacc 50.0000 (53.1250)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.583 (0.583)\tdata 0.520 (0.520)\teta 0:00:06\tloss 1.4941 (1.4941)\tacc 43.7500 (43.7500)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.260)\teta 0:00:03\tloss 1.4902 (1.4922)\tacc 40.6250 (42.1875)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.577 (0.577)\tdata 0.512 (0.512)\teta 0:00:05\tloss 1.3340 (1.3340)\tacc 56.2500 (56.2500)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.065 (0.321)\tdata 0.000 (0.256)\teta 0:00:02\tloss 1.4531 (1.3936)\tacc 40.6250 (48.4375)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.576 (0.576)\tdata 0.513 (0.513)\teta 0:00:04\tloss 1.3203 (1.3203)\tacc 56.2500 (56.2500)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.064 (0.320)\tdata 0.000 (0.257)\teta 0:00:01\tloss 1.3975 (1.3589)\tacc 46.8750 (51.5625)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.599 (0.599)\tdata 0.535 (0.535)\teta 0:00:02\tloss 1.5840 (1.5840)\tacc 40.6250 (40.6250)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.063 (0.331)\tdata 0.000 (0.268)\teta 0:00:01\tloss 1.3857 (1.4849)\tacc 43.7500 (42.1875)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.597 (0.597)\tdata 0.533 (0.533)\teta 0:00:01\tloss 1.3906 (1.3906)\tacc 46.8750 (46.8750)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:00\tloss 1.3750 (1.3828)\tacc 46.8750 (46.8750)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.602 (0.602)\tdata 0.539 (0.539)\teta 0:00:00\tloss 1.3945 (1.3945)\tacc 50.0000 (50.0000)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.064 (0.333)\tdata 0.000 (0.270)\teta 0:00:00\tloss 1.5459 (1.4702)\tacc 40.6250 (45.3125)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed13/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 22\n",
            "* accuracy: 34.38%\n",
            "* error: 65.62%\n",
            "* macro_f1: 22.38%\n",
            "=> per-class result\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* average: 34.92%\n",
            "Elapsed: 0:00:50\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed14\n",
            "in jaffe\n",
            "Setting fixed seed: 14\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed14\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 14\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed14\n",
            "RESUME: \n",
            "SEED: 14\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 15759.60it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed14/tensorboard\n",
            "epoch [1/50][1/2]\ttime 2.169 (2.169)\tdata 0.809 (0.809)\teta 0:03:34\tloss 1.9385 (1.9385)\tacc 21.8750 (21.8750)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.064 (1.117)\tdata 0.000 (0.405)\teta 0:01:49\tloss 1.8174 (1.8779)\tacc 25.0000 (23.4375)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.924 (0.924)\tdata 0.855 (0.855)\teta 0:01:29\tloss 1.9121 (1.9121)\tacc 18.7500 (18.7500)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.067 (0.496)\tdata 0.000 (0.427)\teta 0:00:47\tloss 1.7910 (1.8516)\tacc 34.3750 (26.5625)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.822 (0.822)\tdata 0.742 (0.742)\teta 0:01:18\tloss 1.7734 (1.7734)\tacc 37.5000 (37.5000)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.075 (0.448)\tdata 0.000 (0.371)\teta 0:00:42\tloss 1.5908 (1.6821)\tacc 50.0000 (43.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.878 (0.878)\tdata 0.811 (0.811)\teta 0:01:21\tloss 1.5586 (1.5586)\tacc 46.8750 (46.8750)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.068 (0.473)\tdata 0.000 (0.406)\teta 0:00:43\tloss 1.4648 (1.5117)\tacc 50.0000 (48.4375)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.907 (0.907)\tdata 0.839 (0.839)\teta 0:01:22\tloss 1.3408 (1.3408)\tacc 53.1250 (53.1250)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.067 (0.487)\tdata 0.000 (0.419)\teta 0:00:43\tloss 1.3613 (1.3511)\tacc 46.8750 (50.0000)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.946 (0.946)\tdata 0.879 (0.879)\teta 0:01:24\tloss 1.0996 (1.0996)\tacc 71.8750 (71.8750)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.066 (0.506)\tdata 0.001 (0.440)\teta 0:00:44\tloss 1.2881 (1.1938)\tacc 56.2500 (64.0625)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.944 (0.944)\tdata 0.857 (0.857)\teta 0:01:22\tloss 1.2881 (1.2881)\tacc 46.8750 (46.8750)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.086 (0.515)\tdata 0.000 (0.428)\teta 0:00:44\tloss 1.1191 (1.2036)\tacc 62.5000 (54.6875)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.883 (0.883)\tdata 0.814 (0.814)\teta 0:01:15\tloss 1.2109 (1.2109)\tacc 56.2500 (56.2500)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.066 (0.475)\tdata 0.000 (0.407)\teta 0:00:39\tloss 1.0459 (1.1284)\tacc 62.5000 (59.3750)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.946 (0.946)\tdata 0.859 (0.859)\teta 0:01:18\tloss 1.0635 (1.0635)\tacc 65.6250 (65.6250)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.066 (0.506)\tdata 0.000 (0.430)\teta 0:00:41\tloss 1.5469 (1.3052)\tacc 43.7500 (54.6875)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.593 (0.593)\tdata 0.530 (0.530)\teta 0:00:48\tloss 1.1475 (1.1475)\tacc 65.6250 (65.6250)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.065 (0.329)\tdata 0.000 (0.265)\teta 0:00:26\tloss 1.4668 (1.3071)\tacc 46.8750 (56.2500)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.586 (0.586)\tdata 0.522 (0.522)\teta 0:00:46\tloss 0.8384 (0.8384)\tacc 84.3750 (84.3750)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.063 (0.325)\tdata 0.000 (0.261)\teta 0:00:25\tloss 1.2080 (1.0232)\tacc 53.1250 (68.7500)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.583 (0.583)\tdata 0.518 (0.518)\teta 0:00:44\tloss 1.0850 (1.0850)\tacc 62.5000 (62.5000)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.259)\teta 0:00:24\tloss 1.0732 (1.0791)\tacc 75.0000 (68.7500)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.596 (0.596)\tdata 0.533 (0.533)\teta 0:00:44\tloss 1.1465 (1.1465)\tacc 56.2500 (56.2500)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:24\tloss 0.8115 (0.9790)\tacc 81.2500 (68.7500)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.577 (0.577)\tdata 0.514 (0.514)\teta 0:00:42\tloss 1.3643 (1.3643)\tacc 50.0000 (50.0000)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.064 (0.320)\tdata 0.001 (0.257)\teta 0:00:23\tloss 0.8452 (1.1047)\tacc 75.0000 (62.5000)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.610 (0.610)\tdata 0.545 (0.545)\teta 0:00:43\tloss 0.7368 (0.7368)\tacc 78.1250 (78.1250)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.063 (0.336)\tdata 0.000 (0.272)\teta 0:00:23\tloss 0.9570 (0.8469)\tacc 75.0000 (76.5625)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.590 (0.590)\tdata 0.525 (0.525)\teta 0:00:40\tloss 1.0107 (1.0107)\tacc 62.5000 (62.5000)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.263)\teta 0:00:22\tloss 1.0342 (1.0225)\tacc 65.6250 (64.0625)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.591 (0.591)\tdata 0.519 (0.519)\teta 0:00:39\tloss 1.0293 (1.0293)\tacc 68.7500 (68.7500)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.072 (0.332)\tdata 0.000 (0.259)\teta 0:00:21\tloss 0.7607 (0.8950)\tacc 75.0000 (71.8750)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.604 (0.604)\tdata 0.540 (0.540)\teta 0:00:39\tloss 0.9199 (0.9199)\tacc 71.8750 (71.8750)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.270)\teta 0:00:21\tloss 0.8481 (0.8840)\tacc 71.8750 (71.8750)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.590 (0.590)\tdata 0.526 (0.526)\teta 0:00:37\tloss 0.9844 (0.9844)\tacc 65.6250 (65.6250)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.263)\teta 0:00:20\tloss 0.7935 (0.8889)\tacc 75.0000 (70.3125)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.598 (0.598)\tdata 0.535 (0.535)\teta 0:00:36\tloss 0.8760 (0.8760)\tacc 75.0000 (75.0000)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.268)\teta 0:00:19\tloss 0.7178 (0.7969)\tacc 81.2500 (78.1250)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.605 (0.605)\tdata 0.541 (0.541)\teta 0:00:35\tloss 0.7520 (0.7520)\tacc 68.7500 (68.7500)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.271)\teta 0:00:19\tloss 0.7407 (0.7463)\tacc 78.1250 (73.4375)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.570 (0.570)\tdata 0.506 (0.506)\teta 0:00:32\tloss 1.0928 (1.0928)\tacc 59.3750 (59.3750)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.066 (0.318)\tdata 0.000 (0.253)\teta 0:00:17\tloss 1.0312 (1.0620)\tacc 59.3750 (59.3750)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.577 (0.577)\tdata 0.515 (0.515)\teta 0:00:31\tloss 0.8452 (0.8452)\tacc 71.8750 (71.8750)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.064 (0.320)\tdata 0.000 (0.257)\teta 0:00:17\tloss 0.9907 (0.9180)\tacc 65.6250 (68.7500)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.584 (0.584)\tdata 0.518 (0.518)\teta 0:00:30\tloss 0.6543 (0.6543)\tacc 81.2500 (81.2500)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.259)\teta 0:00:16\tloss 0.9756 (0.8149)\tacc 65.6250 (73.4375)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.596 (0.596)\tdata 0.532 (0.532)\teta 0:00:30\tloss 1.0518 (1.0518)\tacc 59.3750 (59.3750)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.266)\teta 0:00:16\tloss 0.5591 (0.8054)\tacc 78.1250 (68.7500)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.593 (0.593)\tdata 0.529 (0.529)\teta 0:00:29\tloss 0.7446 (0.7446)\tacc 75.0000 (75.0000)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.064 (0.329)\tdata 0.000 (0.265)\teta 0:00:15\tloss 0.9585 (0.8516)\tacc 71.8750 (73.4375)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.585 (0.585)\tdata 0.521 (0.521)\teta 0:00:27\tloss 0.7207 (0.7207)\tacc 75.0000 (75.0000)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.063 (0.324)\tdata 0.000 (0.260)\teta 0:00:14\tloss 0.8174 (0.7690)\tacc 71.8750 (73.4375)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.596 (0.596)\tdata 0.525 (0.525)\teta 0:00:26\tloss 0.8921 (0.8921)\tacc 65.6250 (65.6250)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.263)\teta 0:00:14\tloss 0.7412 (0.8167)\tacc 68.7500 (67.1875)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.571 (0.571)\tdata 0.507 (0.507)\teta 0:00:24\tloss 0.7095 (0.7095)\tacc 75.0000 (75.0000)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.253)\teta 0:00:13\tloss 0.6807 (0.6951)\tacc 78.1250 (76.5625)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.593 (0.593)\tdata 0.531 (0.531)\teta 0:00:24\tloss 0.6426 (0.6426)\tacc 78.1250 (78.1250)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.065 (0.329)\tdata 0.000 (0.266)\teta 0:00:13\tloss 0.8945 (0.7686)\tacc 62.5000 (70.3125)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.612 (0.612)\tdata 0.549 (0.549)\teta 0:00:23\tloss 0.8096 (0.8096)\tacc 75.0000 (75.0000)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.063 (0.338)\tdata 0.000 (0.275)\teta 0:00:12\tloss 0.7393 (0.7744)\tacc 68.7500 (71.8750)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.593 (0.593)\tdata 0.531 (0.531)\teta 0:00:21\tloss 0.8564 (0.8564)\tacc 65.6250 (65.6250)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.064 (0.329)\tdata 0.000 (0.266)\teta 0:00:11\tloss 0.9009 (0.8787)\tacc 68.7500 (67.1875)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.587 (0.587)\tdata 0.523 (0.523)\teta 0:00:20\tloss 0.8296 (0.8296)\tacc 65.6250 (65.6250)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.262)\teta 0:00:11\tloss 0.7163 (0.7729)\tacc 84.3750 (75.0000)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.617 (0.617)\tdata 0.554 (0.554)\teta 0:00:20\tloss 0.6426 (0.6426)\tacc 75.0000 (75.0000)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.065 (0.341)\tdata 0.000 (0.277)\teta 0:00:10\tloss 0.7949 (0.7188)\tacc 78.1250 (76.5625)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.597 (0.597)\tdata 0.535 (0.535)\teta 0:00:18\tloss 0.6675 (0.6675)\tacc 84.3750 (84.3750)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.065 (0.331)\tdata 0.000 (0.268)\teta 0:00:09\tloss 0.8262 (0.7468)\tacc 78.1250 (81.2500)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.581 (0.581)\tdata 0.516 (0.516)\teta 0:00:16\tloss 0.8911 (0.8911)\tacc 65.6250 (65.6250)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.258)\teta 0:00:09\tloss 0.9009 (0.8960)\tacc 75.0000 (70.3125)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.590 (0.590)\tdata 0.527 (0.527)\teta 0:00:15\tloss 0.5601 (0.5601)\tacc 84.3750 (84.3750)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.263)\teta 0:00:08\tloss 0.7495 (0.6548)\tacc 68.7500 (76.5625)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.617 (0.617)\tdata 0.555 (0.555)\teta 0:00:15\tloss 0.6626 (0.6626)\tacc 78.1250 (78.1250)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.064 (0.341)\tdata 0.000 (0.278)\teta 0:00:08\tloss 0.9819 (0.8223)\tacc 65.6250 (71.8750)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.596 (0.596)\tdata 0.533 (0.533)\teta 0:00:13\tloss 0.6909 (0.6909)\tacc 75.0000 (75.0000)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:07\tloss 0.9053 (0.7981)\tacc 71.8750 (73.4375)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.559 (0.559)\tdata 0.495 (0.495)\teta 0:00:11\tloss 0.8926 (0.8926)\tacc 65.6250 (65.6250)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.065 (0.312)\tdata 0.000 (0.248)\teta 0:00:06\tloss 0.6221 (0.7573)\tacc 81.2500 (73.4375)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.582 (0.582)\tdata 0.520 (0.520)\teta 0:00:11\tloss 0.8228 (0.8228)\tacc 65.6250 (65.6250)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.260)\teta 0:00:05\tloss 0.8052 (0.8140)\tacc 71.8750 (68.7500)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.621 (0.621)\tdata 0.546 (0.546)\teta 0:00:10\tloss 0.8076 (0.8076)\tacc 78.1250 (78.1250)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.074 (0.348)\tdata 0.000 (0.273)\teta 0:00:05\tloss 0.6997 (0.7537)\tacc 75.0000 (76.5625)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.592 (0.592)\tdata 0.530 (0.530)\teta 0:00:08\tloss 0.6367 (0.6367)\tacc 78.1250 (78.1250)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.065 (0.328)\tdata 0.000 (0.265)\teta 0:00:04\tloss 0.7549 (0.6958)\tacc 71.8750 (75.0000)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.592 (0.592)\tdata 0.530 (0.530)\teta 0:00:07\tloss 0.9224 (0.9224)\tacc 71.8750 (71.8750)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.065 (0.328)\tdata 0.000 (0.265)\teta 0:00:03\tloss 0.6318 (0.7771)\tacc 71.8750 (71.8750)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.576 (0.576)\tdata 0.512 (0.512)\teta 0:00:06\tloss 0.5601 (0.5601)\tacc 87.5000 (87.5000)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.065 (0.320)\tdata 0.000 (0.256)\teta 0:00:03\tloss 0.6626 (0.6113)\tacc 71.8750 (79.6875)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.597 (0.597)\tdata 0.534 (0.534)\teta 0:00:05\tloss 0.6865 (0.6865)\tacc 71.8750 (71.8750)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.065 (0.331)\tdata 0.000 (0.267)\teta 0:00:02\tloss 0.8179 (0.7522)\tacc 71.8750 (71.8750)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.603 (0.603)\tdata 0.539 (0.539)\teta 0:00:04\tloss 0.8511 (0.8511)\tacc 75.0000 (75.0000)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.270)\teta 0:00:02\tloss 0.6538 (0.7524)\tacc 75.0000 (75.0000)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.619 (0.619)\tdata 0.556 (0.556)\teta 0:00:03\tloss 0.5566 (0.5566)\tacc 87.5000 (87.5000)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.064 (0.342)\tdata 0.000 (0.278)\teta 0:00:01\tloss 0.7549 (0.6558)\tacc 78.1250 (82.8125)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.669 (0.669)\tdata 0.603 (0.603)\teta 0:00:02\tloss 0.7378 (0.7378)\tacc 78.1250 (78.1250)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.066 (0.367)\tdata 0.001 (0.302)\teta 0:00:00\tloss 0.8848 (0.8113)\tacc 78.1250 (78.1250)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.870 (0.870)\tdata 0.774 (0.774)\teta 0:00:00\tloss 0.8599 (0.8599)\tacc 68.7500 (68.7500)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.063 (0.467)\tdata 0.000 (0.387)\teta 0:00:00\tloss 0.5020 (0.6809)\tacc 84.3750 (76.5625)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed14/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 32\n",
            "* accuracy: 50.00%\n",
            "* error: 50.00%\n",
            "* macro_f1: 43.10%\n",
            "=> per-class result\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 7\tacc: 77.78%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 4\tacc: 44.44%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* average: 50.79%\n",
            "Elapsed: 0:00:50\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed15\n",
            "in jaffe\n",
            "Setting fixed seed: 15\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed15\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 15\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed15\n",
            "RESUME: \n",
            "SEED: 15\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 16284.04it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed15/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.825 (1.825)\tdata 0.572 (0.572)\teta 0:03:00\tloss 2.0918 (2.0918)\tacc 15.6250 (15.6250)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.066 (0.945)\tdata 0.000 (0.286)\teta 0:01:32\tloss 1.9658 (2.0288)\tacc 15.6250 (15.6250)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.587 (0.587)\tdata 0.522 (0.522)\teta 0:00:56\tloss 2.0996 (2.0996)\tacc 12.5000 (12.5000)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.261)\teta 0:00:31\tloss 1.7539 (1.9268)\tacc 46.8750 (29.6875)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.582 (0.582)\tdata 0.518 (0.518)\teta 0:00:55\tloss 1.8994 (1.8994)\tacc 28.1250 (28.1250)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.259)\teta 0:00:30\tloss 1.6846 (1.7920)\tacc 40.6250 (34.3750)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.595 (0.595)\tdata 0.531 (0.531)\teta 0:00:55\tloss 1.6865 (1.6865)\tacc 46.8750 (46.8750)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.064 (0.329)\tdata 0.000 (0.266)\teta 0:00:30\tloss 1.4795 (1.5830)\tacc 43.7500 (45.3125)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.604 (0.604)\tdata 0.542 (0.542)\teta 0:00:54\tloss 1.2803 (1.2803)\tacc 62.5000 (62.5000)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.063 (0.334)\tdata 0.000 (0.271)\teta 0:00:30\tloss 1.2246 (1.2524)\tacc 75.0000 (68.7500)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.610 (0.610)\tdata 0.538 (0.538)\teta 0:00:54\tloss 1.2793 (1.2793)\tacc 50.0000 (50.0000)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.077 (0.344)\tdata 0.000 (0.269)\teta 0:00:30\tloss 1.3887 (1.3340)\tacc 40.6250 (45.3125)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.593 (0.593)\tdata 0.531 (0.531)\teta 0:00:51\tloss 1.2275 (1.2275)\tacc 56.2500 (56.2500)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.063 (0.328)\tdata 0.000 (0.265)\teta 0:00:28\tloss 0.8940 (1.0608)\tacc 71.8750 (64.0625)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.572 (0.572)\tdata 0.509 (0.509)\teta 0:00:48\tloss 0.9233 (0.9233)\tacc 71.8750 (71.8750)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.064 (0.318)\tdata 0.000 (0.255)\teta 0:00:26\tloss 1.1377 (1.0305)\tacc 53.1250 (62.5000)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.593 (0.593)\tdata 0.529 (0.529)\teta 0:00:49\tloss 0.9722 (0.9722)\tacc 59.3750 (59.3750)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.064 (0.328)\tdata 0.000 (0.264)\teta 0:00:26\tloss 1.0801 (1.0261)\tacc 56.2500 (57.8125)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.612 (0.612)\tdata 0.549 (0.549)\teta 0:00:49\tloss 0.9146 (0.9146)\tacc 71.8750 (71.8750)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.064 (0.338)\tdata 0.000 (0.275)\teta 0:00:27\tloss 0.9722 (0.9434)\tacc 71.8750 (71.8750)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.598 (0.598)\tdata 0.535 (0.535)\teta 0:00:47\tloss 1.1650 (1.1650)\tacc 62.5000 (62.5000)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.268)\teta 0:00:25\tloss 1.0684 (1.1167)\tacc 53.1250 (57.8125)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.587 (0.587)\tdata 0.525 (0.525)\teta 0:00:45\tloss 1.1611 (1.1611)\tacc 56.2500 (56.2500)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.262)\teta 0:00:24\tloss 0.9854 (1.0732)\tacc 65.6250 (60.9375)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.605 (0.605)\tdata 0.542 (0.542)\teta 0:00:45\tloss 0.8306 (0.8306)\tacc 81.2500 (81.2500)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.271)\teta 0:00:24\tloss 0.9521 (0.8914)\tacc 71.8750 (76.5625)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.571 (0.571)\tdata 0.509 (0.509)\teta 0:00:41\tloss 0.6665 (0.6665)\tacc 90.6250 (90.6250)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.065 (0.318)\tdata 0.000 (0.255)\teta 0:00:22\tloss 0.7183 (0.6924)\tacc 75.0000 (82.8125)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.590 (0.590)\tdata 0.515 (0.515)\teta 0:00:41\tloss 0.8242 (0.8242)\tacc 71.8750 (71.8750)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.072 (0.331)\tdata 0.000 (0.258)\teta 0:00:23\tloss 1.0713 (0.9478)\tacc 65.6250 (68.7500)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.621 (0.621)\tdata 0.557 (0.557)\teta 0:00:42\tloss 1.0020 (1.0020)\tacc 65.6250 (65.6250)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.065 (0.343)\tdata 0.000 (0.279)\teta 0:00:23\tloss 0.8110 (0.9065)\tacc 65.6250 (65.6250)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.598 (0.598)\tdata 0.535 (0.535)\teta 0:00:40\tloss 0.9834 (0.9834)\tacc 62.5000 (62.5000)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.268)\teta 0:00:21\tloss 0.8853 (0.9343)\tacc 71.8750 (67.1875)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.586 (0.586)\tdata 0.515 (0.515)\teta 0:00:38\tloss 0.8452 (0.8452)\tacc 68.7500 (68.7500)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.065 (0.326)\tdata 0.000 (0.257)\teta 0:00:20\tloss 0.9561 (0.9006)\tacc 62.5000 (65.6250)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.582 (0.582)\tdata 0.520 (0.520)\teta 0:00:36\tloss 0.9995 (0.9995)\tacc 68.7500 (68.7500)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.065 (0.324)\tdata 0.000 (0.260)\teta 0:00:20\tloss 1.0967 (1.0481)\tacc 50.0000 (59.3750)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.599 (0.599)\tdata 0.536 (0.536)\teta 0:00:36\tloss 0.5796 (0.5796)\tacc 81.2500 (81.2500)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.065 (0.332)\tdata 0.000 (0.268)\teta 0:00:19\tloss 0.8862 (0.7329)\tacc 68.7500 (75.0000)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.576 (0.576)\tdata 0.512 (0.512)\teta 0:00:34\tloss 1.0039 (1.0039)\tacc 56.2500 (56.2500)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.064 (0.320)\tdata 0.000 (0.256)\teta 0:00:18\tloss 0.7188 (0.8613)\tacc 84.3750 (70.3125)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.587 (0.587)\tdata 0.524 (0.524)\teta 0:00:33\tloss 0.8813 (0.8813)\tacc 78.1250 (78.1250)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.065 (0.326)\tdata 0.000 (0.262)\teta 0:00:18\tloss 0.7456 (0.8135)\tacc 75.0000 (76.5625)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.577 (0.577)\tdata 0.513 (0.513)\teta 0:00:31\tloss 0.8198 (0.8198)\tacc 68.7500 (68.7500)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.068 (0.322)\tdata 0.000 (0.257)\teta 0:00:17\tloss 0.7896 (0.8047)\tacc 78.1250 (73.4375)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.588 (0.588)\tdata 0.524 (0.524)\teta 0:00:31\tloss 0.9268 (0.9268)\tacc 78.1250 (78.1250)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.063 (0.326)\tdata 0.000 (0.262)\teta 0:00:16\tloss 0.5405 (0.7336)\tacc 78.1250 (78.1250)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.597 (0.597)\tdata 0.535 (0.535)\teta 0:00:30\tloss 0.7632 (0.7632)\tacc 71.8750 (71.8750)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.267)\teta 0:00:16\tloss 1.0293 (0.8962)\tacc 71.8750 (71.8750)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.584 (0.584)\tdata 0.522 (0.522)\teta 0:00:28\tloss 0.6636 (0.6636)\tacc 81.2500 (81.2500)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.063 (0.324)\tdata 0.000 (0.261)\teta 0:00:15\tloss 0.8618 (0.7627)\tacc 56.2500 (68.7500)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.581 (0.581)\tdata 0.518 (0.518)\teta 0:00:27\tloss 0.8135 (0.8135)\tacc 68.7500 (68.7500)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.259)\teta 0:00:14\tloss 0.7305 (0.7720)\tacc 75.0000 (71.8750)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.587 (0.587)\tdata 0.524 (0.524)\teta 0:00:26\tloss 0.6572 (0.6572)\tacc 78.1250 (78.1250)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.067 (0.327)\tdata 0.000 (0.262)\teta 0:00:14\tloss 0.7598 (0.7085)\tacc 75.0000 (76.5625)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.573 (0.573)\tdata 0.510 (0.510)\teta 0:00:24\tloss 0.7324 (0.7324)\tacc 71.8750 (71.8750)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.065 (0.319)\tdata 0.000 (0.255)\teta 0:00:13\tloss 0.9688 (0.8506)\tacc 71.8750 (71.8750)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.584 (0.584)\tdata 0.521 (0.521)\teta 0:00:23\tloss 0.6567 (0.6567)\tacc 78.1250 (78.1250)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.261)\teta 0:00:12\tloss 0.6021 (0.6294)\tacc 81.2500 (79.6875)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.588 (0.588)\tdata 0.525 (0.525)\teta 0:00:22\tloss 0.4089 (0.4089)\tacc 87.5000 (87.5000)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.065 (0.327)\tdata 0.000 (0.262)\teta 0:00:12\tloss 0.7920 (0.6005)\tacc 71.8750 (79.6875)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.599 (0.599)\tdata 0.537 (0.537)\teta 0:00:22\tloss 1.0215 (1.0215)\tacc 56.2500 (56.2500)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.064 (0.332)\tdata 0.000 (0.269)\teta 0:00:11\tloss 0.9946 (1.0081)\tacc 62.5000 (59.3750)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.599 (0.599)\tdata 0.524 (0.524)\teta 0:00:20\tloss 0.6226 (0.6226)\tacc 71.8750 (71.8750)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.068 (0.333)\tdata 0.001 (0.263)\teta 0:00:11\tloss 0.8091 (0.7158)\tacc 71.8750 (71.8750)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.928 (0.928)\tdata 0.862 (0.862)\teta 0:00:30\tloss 0.6167 (0.6167)\tacc 81.2500 (81.2500)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.067 (0.497)\tdata 0.001 (0.431)\teta 0:00:15\tloss 0.8740 (0.7454)\tacc 65.6250 (73.4375)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.874 (0.874)\tdata 0.806 (0.806)\teta 0:00:27\tloss 0.9302 (0.9302)\tacc 65.6250 (65.6250)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.068 (0.471)\tdata 0.001 (0.404)\teta 0:00:14\tloss 0.7651 (0.8477)\tacc 71.8750 (68.7500)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.891 (0.891)\tdata 0.814 (0.814)\teta 0:00:25\tloss 0.7217 (0.7217)\tacc 68.7500 (68.7500)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.078 (0.485)\tdata 0.013 (0.413)\teta 0:00:13\tloss 0.8320 (0.7769)\tacc 75.0000 (71.8750)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.875 (0.875)\tdata 0.795 (0.795)\teta 0:00:23\tloss 0.6973 (0.6973)\tacc 78.1250 (78.1250)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.077 (0.476)\tdata 0.000 (0.398)\teta 0:00:12\tloss 0.7393 (0.7183)\tacc 75.0000 (76.5625)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.944 (0.944)\tdata 0.866 (0.866)\teta 0:00:23\tloss 0.9531 (0.9531)\tacc 68.7500 (68.7500)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.076 (0.510)\tdata 0.001 (0.433)\teta 0:00:12\tloss 0.7549 (0.8540)\tacc 78.1250 (73.4375)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.878 (0.878)\tdata 0.809 (0.809)\teta 0:00:20\tloss 0.8545 (0.8545)\tacc 65.6250 (65.6250)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.067 (0.472)\tdata 0.000 (0.405)\teta 0:00:10\tloss 0.6763 (0.7654)\tacc 78.1250 (71.8750)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.835 (0.835)\tdata 0.768 (0.768)\teta 0:00:17\tloss 0.7939 (0.7939)\tacc 71.8750 (71.8750)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.067 (0.451)\tdata 0.001 (0.384)\teta 0:00:09\tloss 0.6670 (0.7305)\tacc 75.0000 (73.4375)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.953 (0.953)\tdata 0.885 (0.885)\teta 0:00:18\tloss 0.8413 (0.8413)\tacc 75.0000 (75.0000)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.067 (0.510)\tdata 0.001 (0.443)\teta 0:00:09\tloss 0.6660 (0.7537)\tacc 78.1250 (76.5625)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.873 (0.873)\tdata 0.791 (0.791)\teta 0:00:14\tloss 0.9517 (0.9517)\tacc 56.2500 (56.2500)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.076 (0.474)\tdata 0.000 (0.396)\teta 0:00:07\tloss 0.7329 (0.8423)\tacc 71.8750 (64.0625)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.889 (0.889)\tdata 0.813 (0.813)\teta 0:00:13\tloss 0.7563 (0.7563)\tacc 75.0000 (75.0000)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.073 (0.481)\tdata 0.000 (0.407)\teta 0:00:06\tloss 0.5244 (0.6404)\tacc 90.6250 (82.8125)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.633 (0.633)\tdata 0.544 (0.544)\teta 0:00:08\tloss 0.8320 (0.8320)\tacc 62.5000 (62.5000)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.087 (0.360)\tdata 0.000 (0.272)\teta 0:00:04\tloss 0.6313 (0.7317)\tacc 78.1250 (70.3125)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.609 (0.609)\tdata 0.545 (0.545)\teta 0:00:06\tloss 0.6558 (0.6558)\tacc 78.1250 (78.1250)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.064 (0.337)\tdata 0.000 (0.272)\teta 0:00:03\tloss 0.9365 (0.7961)\tacc 71.8750 (75.0000)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.590 (0.590)\tdata 0.525 (0.525)\teta 0:00:05\tloss 0.7773 (0.7773)\tacc 68.7500 (68.7500)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.065 (0.327)\tdata 0.000 (0.263)\teta 0:00:02\tloss 0.5449 (0.6611)\tacc 87.5000 (78.1250)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.591 (0.591)\tdata 0.527 (0.527)\teta 0:00:04\tloss 0.8872 (0.8872)\tacc 68.7500 (68.7500)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.264)\teta 0:00:01\tloss 0.5283 (0.7078)\tacc 87.5000 (78.1250)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.612 (0.612)\tdata 0.549 (0.549)\teta 0:00:03\tloss 0.6357 (0.6357)\tacc 84.3750 (84.3750)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.065 (0.339)\tdata 0.000 (0.274)\teta 0:00:01\tloss 0.7310 (0.6833)\tacc 78.1250 (81.2500)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.594 (0.594)\tdata 0.531 (0.531)\teta 0:00:01\tloss 0.6802 (0.6802)\tacc 68.7500 (68.7500)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.065 (0.330)\tdata 0.000 (0.266)\teta 0:00:00\tloss 0.7085 (0.6943)\tacc 78.1250 (73.4375)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.588 (0.588)\tdata 0.525 (0.525)\teta 0:00:00\tloss 0.6855 (0.6855)\tacc 84.3750 (84.3750)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.263)\teta 0:00:00\tloss 1.0898 (0.8877)\tacc 56.2500 (70.3125)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed15/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 30\n",
            "* accuracy: 46.88%\n",
            "* error: 53.12%\n",
            "* macro_f1: 42.61%\n",
            "=> per-class result\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 1\tacc: 11.11%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 6\tacc: 66.67%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* average: 47.62%\n",
            "Elapsed: 0:00:50\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed16\n",
            "in jaffe\n",
            "Setting fixed seed: 16\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed16\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 16\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed16\n",
            "RESUME: \n",
            "SEED: 16\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 12644.33it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 81\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed16/tensorboard\n",
            "epoch [1/50][1/2]\ttime 2.299 (2.299)\tdata 0.944 (0.944)\teta 0:03:47\tloss 2.1094 (2.1094)\tacc 3.1250 (3.1250)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.066 (1.182)\tdata 0.000 (0.472)\teta 0:01:55\tloss 2.1855 (2.1475)\tacc 3.1250 (3.1250)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.910 (0.910)\tdata 0.838 (0.838)\teta 0:01:28\tloss 2.0723 (2.0723)\tacc 0.0000 (0.0000)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.067 (0.489)\tdata 0.001 (0.419)\teta 0:00:46\tloss 1.8975 (1.9849)\tacc 15.6250 (7.8125)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.850 (0.850)\tdata 0.748 (0.748)\teta 0:01:20\tloss 2.1074 (2.1074)\tacc 18.7500 (18.7500)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.089 (0.470)\tdata 0.014 (0.381)\teta 0:00:44\tloss 2.0430 (2.0752)\tacc 18.7500 (18.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.944 (0.944)\tdata 0.864 (0.864)\teta 0:01:27\tloss 1.9492 (1.9492)\tacc 18.7500 (18.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.074 (0.509)\tdata 0.001 (0.432)\teta 0:00:46\tloss 1.9297 (1.9395)\tacc 18.7500 (18.7500)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.892 (0.892)\tdata 0.807 (0.807)\teta 0:01:21\tloss 1.9053 (1.9053)\tacc 28.1250 (28.1250)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.069 (0.480)\tdata 0.000 (0.404)\teta 0:00:43\tloss 1.9102 (1.9077)\tacc 31.2500 (29.6875)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.925 (0.925)\tdata 0.857 (0.857)\teta 0:01:22\tloss 1.9004 (1.9004)\tacc 15.6250 (15.6250)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.067 (0.496)\tdata 0.000 (0.429)\teta 0:00:43\tloss 1.9463 (1.9233)\tacc 15.6250 (15.6250)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.853 (0.853)\tdata 0.785 (0.785)\teta 0:01:14\tloss 1.8916 (1.8916)\tacc 43.7500 (43.7500)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.067 (0.460)\tdata 0.000 (0.393)\teta 0:00:39\tloss 1.8555 (1.8735)\tacc 31.2500 (37.5000)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.947 (0.947)\tdata 0.880 (0.880)\teta 0:01:20\tloss 1.8877 (1.8877)\tacc 18.7500 (18.7500)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.069 (0.508)\tdata 0.000 (0.440)\teta 0:00:42\tloss 1.8428 (1.8652)\tacc 28.1250 (23.4375)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.579 (0.579)\tdata 0.501 (0.501)\teta 0:00:48\tloss 1.7900 (1.7900)\tacc 37.5000 (37.5000)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.072 (0.325)\tdata 0.001 (0.251)\teta 0:00:26\tloss 1.8809 (1.8354)\tacc 28.1250 (32.8125)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.580 (0.580)\tdata 0.517 (0.517)\teta 0:00:46\tloss 1.7480 (1.7480)\tacc 34.3750 (34.3750)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.063 (0.322)\tdata 0.000 (0.259)\teta 0:00:25\tloss 1.7900 (1.7690)\tacc 31.2500 (32.8125)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.586 (0.586)\tdata 0.522 (0.522)\teta 0:00:46\tloss 1.6338 (1.6338)\tacc 37.5000 (37.5000)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.064 (0.325)\tdata 0.000 (0.261)\teta 0:00:25\tloss 1.8613 (1.7476)\tacc 12.5000 (25.0000)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.967 (0.967)\tdata 0.901 (0.901)\teta 0:01:14\tloss 1.8145 (1.8145)\tacc 12.5000 (12.5000)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.065 (0.516)\tdata 0.000 (0.450)\teta 0:00:39\tloss 1.7607 (1.7876)\tacc 25.0000 (18.7500)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.968 (0.968)\tdata 0.881 (0.881)\teta 0:01:12\tloss 1.7148 (1.7148)\tacc 40.6250 (40.6250)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.079 (0.524)\tdata 0.001 (0.441)\teta 0:00:38\tloss 1.6787 (1.6968)\tacc 40.6250 (40.6250)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.905 (0.905)\tdata 0.838 (0.838)\teta 0:01:06\tloss 1.4795 (1.4795)\tacc 62.5000 (62.5000)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.066 (0.486)\tdata 0.000 (0.419)\teta 0:00:34\tloss 1.4912 (1.4854)\tacc 53.1250 (57.8125)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.910 (0.910)\tdata 0.842 (0.842)\teta 0:01:04\tloss 1.4863 (1.4863)\tacc 53.1250 (53.1250)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.067 (0.488)\tdata 0.000 (0.421)\teta 0:00:34\tloss 1.1025 (1.2944)\tacc 75.0000 (64.0625)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.967 (0.967)\tdata 0.886 (0.886)\teta 0:01:06\tloss 1.3066 (1.3066)\tacc 46.8750 (46.8750)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.079 (0.523)\tdata 0.001 (0.443)\teta 0:00:35\tloss 1.0205 (1.1636)\tacc 75.0000 (60.9375)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.936 (0.936)\tdata 0.868 (0.868)\teta 0:01:02\tloss 1.2012 (1.2012)\tacc 65.6250 (65.6250)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.069 (0.502)\tdata 0.000 (0.434)\teta 0:00:33\tloss 1.1650 (1.1831)\tacc 53.1250 (59.3750)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.881 (0.881)\tdata 0.815 (0.815)\teta 0:00:57\tloss 1.0400 (1.0400)\tacc 62.5000 (62.5000)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.068 (0.474)\tdata 0.000 (0.408)\teta 0:00:30\tloss 1.2070 (1.1235)\tacc 53.1250 (57.8125)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.893 (0.893)\tdata 0.808 (0.808)\teta 0:00:56\tloss 1.0986 (1.0986)\tacc 59.3750 (59.3750)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.083 (0.488)\tdata 0.001 (0.404)\teta 0:00:30\tloss 1.1807 (1.1396)\tacc 53.1250 (56.2500)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.961 (0.961)\tdata 0.886 (0.886)\teta 0:00:58\tloss 1.0391 (1.0391)\tacc 62.5000 (62.5000)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.069 (0.515)\tdata 0.001 (0.443)\teta 0:00:30\tloss 1.0498 (1.0444)\tacc 53.1250 (57.8125)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.896 (0.896)\tdata 0.832 (0.832)\teta 0:00:52\tloss 1.1455 (1.1455)\tacc 65.6250 (65.6250)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.063 (0.480)\tdata 0.000 (0.416)\teta 0:00:27\tloss 0.8960 (1.0208)\tacc 68.7500 (67.1875)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.615 (0.615)\tdata 0.542 (0.542)\teta 0:00:35\tloss 1.1172 (1.1172)\tacc 65.6250 (65.6250)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.070 (0.342)\tdata 0.000 (0.271)\teta 0:00:19\tloss 0.9214 (1.0193)\tacc 65.6250 (65.6250)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.580 (0.580)\tdata 0.516 (0.516)\teta 0:00:31\tloss 0.9785 (0.9785)\tacc 62.5000 (62.5000)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.258)\teta 0:00:17\tloss 1.1982 (1.0884)\tacc 56.2500 (59.3750)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.603 (0.603)\tdata 0.541 (0.541)\teta 0:00:31\tloss 0.9707 (0.9707)\tacc 65.6250 (65.6250)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.271)\teta 0:00:17\tloss 0.8608 (0.9158)\tacc 75.0000 (70.3125)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.588 (0.588)\tdata 0.523 (0.523)\teta 0:00:29\tloss 1.1523 (1.1523)\tacc 65.6250 (65.6250)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.262)\teta 0:00:16\tloss 0.8638 (1.0081)\tacc 62.5000 (64.0625)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.583 (0.583)\tdata 0.518 (0.518)\teta 0:00:28\tloss 0.8257 (0.8257)\tacc 78.1250 (78.1250)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.259)\teta 0:00:15\tloss 0.9282 (0.8770)\tacc 71.8750 (75.0000)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.582 (0.582)\tdata 0.518 (0.518)\teta 0:00:27\tloss 0.9229 (0.9229)\tacc 62.5000 (62.5000)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.064 (0.323)\tdata 0.000 (0.259)\teta 0:00:14\tloss 0.9355 (0.9292)\tacc 68.7500 (65.6250)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.589 (0.589)\tdata 0.526 (0.526)\teta 0:00:26\tloss 0.8433 (0.8433)\tacc 71.8750 (71.8750)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.064 (0.327)\tdata 0.000 (0.263)\teta 0:00:14\tloss 0.8833 (0.8633)\tacc 71.8750 (71.8750)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.603 (0.603)\tdata 0.539 (0.539)\teta 0:00:25\tloss 0.8740 (0.8740)\tacc 68.7500 (68.7500)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.064 (0.333)\tdata 0.000 (0.270)\teta 0:00:13\tloss 1.1182 (0.9961)\tacc 65.6250 (67.1875)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.620 (0.620)\tdata 0.557 (0.557)\teta 0:00:25\tloss 1.0420 (1.0420)\tacc 68.7500 (68.7500)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.064 (0.342)\tdata 0.000 (0.279)\teta 0:00:13\tloss 1.0527 (1.0474)\tacc 56.2500 (62.5000)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.588 (0.588)\tdata 0.523 (0.523)\teta 0:00:22\tloss 0.8960 (0.8960)\tacc 65.6250 (65.6250)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.065 (0.326)\tdata 0.000 (0.262)\teta 0:00:12\tloss 0.6426 (0.7693)\tacc 75.0000 (70.3125)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.589 (0.589)\tdata 0.526 (0.526)\teta 0:00:21\tloss 1.1855 (1.1855)\tacc 65.6250 (65.6250)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.263)\teta 0:00:11\tloss 1.0439 (1.1147)\tacc 65.6250 (65.6250)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.597 (0.597)\tdata 0.534 (0.534)\teta 0:00:20\tloss 0.8506 (0.8506)\tacc 71.8750 (71.8750)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.064 (0.330)\tdata 0.000 (0.267)\teta 0:00:11\tloss 1.0283 (0.9395)\tacc 78.1250 (75.0000)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.585 (0.585)\tdata 0.522 (0.522)\teta 0:00:19\tloss 0.6372 (0.6372)\tacc 78.1250 (78.1250)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.064 (0.324)\tdata 0.000 (0.261)\teta 0:00:10\tloss 0.8179 (0.7275)\tacc 75.0000 (76.5625)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.588 (0.588)\tdata 0.525 (0.525)\teta 0:00:18\tloss 0.7217 (0.7217)\tacc 68.7500 (68.7500)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.063 (0.326)\tdata 0.000 (0.263)\teta 0:00:09\tloss 0.9800 (0.8508)\tacc 62.5000 (65.6250)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.592 (0.592)\tdata 0.529 (0.529)\teta 0:00:17\tloss 1.0332 (1.0332)\tacc 62.5000 (62.5000)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.065 (0.328)\tdata 0.000 (0.265)\teta 0:00:09\tloss 0.6616 (0.8474)\tacc 75.0000 (68.7500)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.581 (0.581)\tdata 0.517 (0.517)\teta 0:00:15\tloss 0.6504 (0.6504)\tacc 78.1250 (78.1250)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.064 (0.322)\tdata 0.000 (0.259)\teta 0:00:08\tloss 0.9658 (0.8081)\tacc 65.6250 (71.8750)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.601 (0.601)\tdata 0.539 (0.539)\teta 0:00:15\tloss 0.6846 (0.6846)\tacc 75.0000 (75.0000)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.064 (0.333)\tdata 0.000 (0.270)\teta 0:00:07\tloss 0.9424 (0.8135)\tacc 68.7500 (71.8750)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.604 (0.604)\tdata 0.541 (0.541)\teta 0:00:13\tloss 0.6909 (0.6909)\tacc 78.1250 (78.1250)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.064 (0.334)\tdata 0.000 (0.271)\teta 0:00:07\tloss 0.7104 (0.7007)\tacc 68.7500 (73.4375)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.599 (0.599)\tdata 0.537 (0.537)\teta 0:00:12\tloss 0.8799 (0.8799)\tacc 62.5000 (62.5000)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.064 (0.332)\tdata 0.000 (0.268)\teta 0:00:06\tloss 0.7661 (0.8230)\tacc 78.1250 (70.3125)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.576 (0.576)\tdata 0.510 (0.510)\teta 0:00:10\tloss 0.8242 (0.8242)\tacc 78.1250 (78.1250)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.064 (0.320)\tdata 0.000 (0.255)\teta 0:00:05\tloss 0.6987 (0.7615)\tacc 81.2500 (79.6875)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.596 (0.596)\tdata 0.533 (0.533)\teta 0:00:10\tloss 0.7100 (0.7100)\tacc 78.1250 (78.1250)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.065 (0.331)\tdata 0.000 (0.267)\teta 0:00:05\tloss 1.1562 (0.9331)\tacc 65.6250 (71.8750)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.576 (0.576)\tdata 0.511 (0.511)\teta 0:00:08\tloss 0.8672 (0.8672)\tacc 65.6250 (65.6250)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.065 (0.320)\tdata 0.000 (0.256)\teta 0:00:04\tloss 0.7061 (0.7866)\tacc 84.3750 (75.0000)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.624 (0.624)\tdata 0.551 (0.551)\teta 0:00:08\tloss 0.6489 (0.6489)\tacc 84.3750 (84.3750)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.070 (0.347)\tdata 0.000 (0.276)\teta 0:00:04\tloss 0.6514 (0.6501)\tacc 71.8750 (78.1250)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.602 (0.602)\tdata 0.540 (0.540)\teta 0:00:06\tloss 0.8569 (0.8569)\tacc 68.7500 (68.7500)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.064 (0.333)\tdata 0.000 (0.270)\teta 0:00:03\tloss 0.9780 (0.9175)\tacc 78.1250 (73.4375)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.597 (0.597)\tdata 0.535 (0.535)\teta 0:00:05\tloss 0.8447 (0.8447)\tacc 65.6250 (65.6250)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.064 (0.331)\tdata 0.000 (0.268)\teta 0:00:02\tloss 0.7539 (0.7993)\tacc 71.8750 (68.7500)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.594 (0.594)\tdata 0.529 (0.529)\teta 0:00:04\tloss 0.9355 (0.9355)\tacc 68.7500 (68.7500)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.065 (0.329)\tdata 0.000 (0.265)\teta 0:00:01\tloss 0.9038 (0.9197)\tacc 65.6250 (67.1875)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.581 (0.581)\tdata 0.508 (0.508)\teta 0:00:02\tloss 0.9653 (0.9653)\tacc 65.6250 (65.6250)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.071 (0.326)\tdata 0.000 (0.254)\teta 0:00:01\tloss 0.9478 (0.9565)\tacc 75.0000 (70.3125)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.570 (0.570)\tdata 0.505 (0.505)\teta 0:00:01\tloss 0.6606 (0.6606)\tacc 84.3750 (84.3750)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.064 (0.317)\tdata 0.000 (0.253)\teta 0:00:00\tloss 0.8853 (0.7729)\tacc 71.8750 (78.1250)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.588 (0.588)\tdata 0.523 (0.523)\teta 0:00:00\tloss 1.0508 (1.0508)\tacc 65.6250 (65.6250)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.064 (0.326)\tdata 0.000 (0.262)\teta 0:00:00\tloss 0.4165 (0.7336)\tacc 93.7500 (79.6875)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed16/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 31\n",
            "* accuracy: 48.44%\n",
            "* error: 51.56%\n",
            "* macro_f1: 42.03%\n",
            "=> per-class result\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 6\tacc: 66.67%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* average: 49.21%\n",
            "Elapsed: 0:00:53\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 bash upl_train.sh ssjaffe rn50_ep50 end 16 16 False True multiple_models_random_init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XHjhQkwRrM3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a3e955-7c29-4a8c-d33e-66cd78b6f8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run this job and save the output to ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed1\n",
            "in jaffe\n",
            "Setting fixed seed: 1\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssoxford_pets.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'middle', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed1\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 1\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSOxfordPets\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed1\n",
            "RESUME: \n",
            "SEED: 1\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: middle\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSOxfordPets\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSOxfordPets\n",
            "  # classes: 37\n",
            "  # train_x: 2,944\n",
            "  # val: 736\n",
            "  # test: 3,669\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 37/37 [00:00<00:00, 17464.47it/s]\n",
            "SSOxfordPets\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "sstrain 592\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed1/tensorboard\n",
            "epoch [1/50][5/18]\ttime 0.116 (1.167)\tdata 0.000 (0.450)\teta 0:17:24\tloss 2.4609 (2.8176)\tacc 40.6250 (26.2500)\tlr 1.000000e-05\n",
            "epoch [1/50][10/18]\ttime 0.115 (0.641)\tdata 0.000 (0.225)\teta 0:09:30\tloss 3.0820 (2.7051)\tacc 18.7500 (30.6250)\tlr 1.000000e-05\n",
            "epoch [1/50][15/18]\ttime 0.116 (0.466)\tdata 0.000 (0.150)\teta 0:06:52\tloss 2.1309 (2.4715)\tacc 43.7500 (38.1250)\tlr 1.000000e-05\n",
            "epoch [2/50][5/18]\ttime 0.181 (0.652)\tdata 0.000 (0.472)\teta 0:09:31\tloss 0.4751 (0.8646)\tacc 90.6250 (73.7500)\tlr 2.000000e-03\n",
            "epoch [2/50][10/18]\ttime 0.137 (0.471)\tdata 0.006 (0.304)\teta 0:06:50\tloss 0.8682 (0.7665)\tacc 68.7500 (75.3125)\tlr 2.000000e-03\n",
            "epoch [2/50][15/18]\ttime 0.116 (0.353)\tdata 0.000 (0.203)\teta 0:05:06\tloss 0.5869 (0.7004)\tacc 81.2500 (78.5417)\tlr 2.000000e-03\n",
            "epoch [3/50][5/18]\ttime 0.159 (0.673)\tdata 0.000 (0.461)\teta 0:09:37\tloss 0.3816 (0.5514)\tacc 90.6250 (86.8750)\tlr 1.998027e-03\n",
            "epoch [3/50][10/18]\ttime 0.124 (0.472)\tdata 0.001 (0.278)\teta 0:06:42\tloss 0.4700 (0.5325)\tacc 90.6250 (87.5000)\tlr 1.998027e-03\n",
            "epoch [3/50][15/18]\ttime 0.116 (0.354)\tdata 0.000 (0.186)\teta 0:05:00\tloss 0.6045 (0.5571)\tacc 81.2500 (86.4583)\tlr 1.998027e-03\n",
            "epoch [4/50][5/18]\ttime 0.218 (0.676)\tdata 0.000 (0.451)\teta 0:09:28\tloss 0.5522 (0.5997)\tacc 84.3750 (83.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][10/18]\ttime 0.137 (0.474)\tdata 0.000 (0.269)\teta 0:06:35\tloss 0.4624 (0.5276)\tacc 93.7500 (86.8750)\tlr 1.992115e-03\n",
            "epoch [4/50][15/18]\ttime 0.117 (0.356)\tdata 0.000 (0.180)\teta 0:04:55\tloss 0.2593 (0.5336)\tacc 93.7500 (86.0417)\tlr 1.992115e-03\n",
            "epoch [5/50][5/18]\ttime 0.306 (0.733)\tdata 0.001 (0.499)\teta 0:10:03\tloss 0.3733 (0.4923)\tacc 87.5000 (85.0000)\tlr 1.982287e-03\n",
            "epoch [5/50][10/18]\ttime 0.232 (0.573)\tdata 0.000 (0.288)\teta 0:07:48\tloss 0.5845 (0.4699)\tacc 81.2500 (85.9375)\tlr 1.982287e-03\n",
            "epoch [5/50][15/18]\ttime 0.158 (0.428)\tdata 0.000 (0.192)\teta 0:05:47\tloss 0.3525 (0.4757)\tacc 93.7500 (86.4583)\tlr 1.982287e-03\n",
            "epoch [6/50][5/18]\ttime 0.365 (0.956)\tdata 0.001 (0.631)\teta 0:12:49\tloss 0.5205 (0.6808)\tacc 87.5000 (82.5000)\tlr 1.968583e-03\n",
            "epoch [6/50][10/18]\ttime 0.267 (0.659)\tdata 0.129 (0.365)\teta 0:08:47\tloss 0.6597 (0.5480)\tacc 81.2500 (85.9375)\tlr 1.968583e-03\n",
            "epoch [6/50][15/18]\ttime 0.147 (0.483)\tdata 0.001 (0.244)\teta 0:06:24\tloss 0.5859 (0.5166)\tacc 84.3750 (87.0833)\tlr 1.968583e-03\n",
            "epoch [7/50][5/18]\ttime 0.194 (0.731)\tdata 0.000 (0.522)\teta 0:09:35\tloss 0.6499 (0.5197)\tacc 84.3750 (85.0000)\tlr 1.951057e-03\n",
            "epoch [7/50][10/18]\ttime 0.305 (0.488)\tdata 0.184 (0.302)\teta 0:06:21\tloss 0.3193 (0.4862)\tacc 93.7500 (84.6875)\tlr 1.951057e-03\n",
            "epoch [7/50][15/18]\ttime 0.116 (0.365)\tdata 0.000 (0.202)\teta 0:04:43\tloss 0.2764 (0.4521)\tacc 90.6250 (85.8333)\tlr 1.951057e-03\n",
            "epoch [8/50][5/18]\ttime 0.218 (0.661)\tdata 0.000 (0.439)\teta 0:08:28\tloss 0.5376 (0.4066)\tacc 90.6250 (90.6250)\tlr 1.929776e-03\n",
            "epoch [8/50][10/18]\ttime 0.120 (0.467)\tdata 0.001 (0.276)\teta 0:05:56\tloss 0.4731 (0.4888)\tacc 90.6250 (87.8125)\tlr 1.929776e-03\n",
            "epoch [8/50][15/18]\ttime 0.116 (0.351)\tdata 0.000 (0.185)\teta 0:04:26\tloss 0.7480 (0.4906)\tacc 78.1250 (87.2917)\tlr 1.929776e-03\n",
            "epoch [9/50][5/18]\ttime 0.184 (0.624)\tdata 0.000 (0.435)\teta 0:07:48\tloss 0.3232 (0.4417)\tacc 90.6250 (90.0000)\tlr 1.904827e-03\n",
            "epoch [9/50][10/18]\ttime 0.180 (0.457)\tdata 0.001 (0.269)\teta 0:05:40\tloss 0.4763 (0.4336)\tacc 87.5000 (88.7500)\tlr 1.904827e-03\n",
            "epoch [9/50][15/18]\ttime 0.118 (0.352)\tdata 0.000 (0.187)\teta 0:04:20\tloss 0.4375 (0.4398)\tacc 87.5000 (87.9167)\tlr 1.904827e-03\n",
            "epoch [10/50][5/18]\ttime 0.181 (0.633)\tdata 0.000 (0.443)\teta 0:07:43\tloss 0.6763 (0.5594)\tacc 81.2500 (86.2500)\tlr 1.876307e-03\n",
            "epoch [10/50][10/18]\ttime 0.302 (0.459)\tdata 0.135 (0.269)\teta 0:05:33\tloss 0.4058 (0.5078)\tacc 93.7500 (87.5000)\tlr 1.876307e-03\n",
            "epoch [10/50][15/18]\ttime 0.124 (0.347)\tdata 0.000 (0.180)\teta 0:04:10\tloss 0.5386 (0.5311)\tacc 90.6250 (87.5000)\tlr 1.876307e-03\n",
            "epoch [11/50][5/18]\ttime 0.191 (0.663)\tdata 0.000 (0.439)\teta 0:07:54\tloss 0.4399 (0.4903)\tacc 84.3750 (85.0000)\tlr 1.844328e-03\n",
            "epoch [11/50][10/18]\ttime 0.134 (0.464)\tdata 0.000 (0.267)\teta 0:05:29\tloss 0.4119 (0.5176)\tacc 93.7500 (85.6250)\tlr 1.844328e-03\n",
            "epoch [11/50][15/18]\ttime 0.118 (0.350)\tdata 0.000 (0.178)\teta 0:04:06\tloss 0.3083 (0.4487)\tacc 84.3750 (87.0833)\tlr 1.844328e-03\n",
            "epoch [12/50][5/18]\ttime 0.180 (0.678)\tdata 0.000 (0.474)\teta 0:07:52\tloss 0.3176 (0.5391)\tacc 87.5000 (85.0000)\tlr 1.809017e-03\n",
            "epoch [12/50][10/18]\ttime 0.129 (0.480)\tdata 0.000 (0.296)\teta 0:05:32\tloss 0.4609 (0.5119)\tacc 90.6250 (85.9375)\tlr 1.809017e-03\n",
            "epoch [12/50][15/18]\ttime 0.120 (0.360)\tdata 0.001 (0.198)\teta 0:04:07\tloss 0.3542 (0.4945)\tacc 90.6250 (86.4583)\tlr 1.809017e-03\n",
            "epoch [13/50][5/18]\ttime 0.190 (1.019)\tdata 0.000 (0.679)\teta 0:11:32\tloss 0.7661 (0.4093)\tacc 78.1250 (90.6250)\tlr 1.770513e-03\n",
            "epoch [13/50][10/18]\ttime 0.161 (0.710)\tdata 0.001 (0.395)\teta 0:07:58\tloss 0.5630 (0.4029)\tacc 84.3750 (90.3125)\tlr 1.770513e-03\n",
            "epoch [13/50][15/18]\ttime 0.120 (0.516)\tdata 0.000 (0.263)\teta 0:05:45\tloss 0.2441 (0.4283)\tacc 93.7500 (89.5833)\tlr 1.770513e-03\n",
            "epoch [14/50][5/18]\ttime 0.178 (0.910)\tdata 0.000 (0.705)\teta 0:10:01\tloss 0.3440 (0.4466)\tacc 93.7500 (88.7500)\tlr 1.728969e-03\n",
            "epoch [14/50][10/18]\ttime 0.131 (0.581)\tdata 0.000 (0.387)\teta 0:06:21\tloss 0.5522 (0.4445)\tacc 84.3750 (88.4375)\tlr 1.728969e-03\n",
            "epoch [14/50][15/18]\ttime 0.118 (0.428)\tdata 0.000 (0.259)\teta 0:04:38\tloss 0.8149 (0.4684)\tacc 78.1250 (87.0833)\tlr 1.728969e-03\n",
            "epoch [15/50][5/18]\ttime 0.181 (0.707)\tdata 0.000 (0.504)\teta 0:07:34\tloss 0.5552 (0.3807)\tacc 78.1250 (86.8750)\tlr 1.684547e-03\n",
            "epoch [15/50][10/18]\ttime 0.129 (0.484)\tdata 0.000 (0.300)\teta 0:05:08\tloss 0.2830 (0.4358)\tacc 93.7500 (87.5000)\tlr 1.684547e-03\n",
            "epoch [15/50][15/18]\ttime 0.118 (0.362)\tdata 0.000 (0.201)\teta 0:03:49\tloss 0.2617 (0.3915)\tacc 93.7500 (89.5833)\tlr 1.684547e-03\n",
            "epoch [16/50][5/18]\ttime 0.170 (0.643)\tdata 0.000 (0.461)\teta 0:06:41\tloss 0.9468 (0.6408)\tacc 75.0000 (81.2500)\tlr 1.637424e-03\n",
            "epoch [16/50][10/18]\ttime 0.168 (0.467)\tdata 0.048 (0.300)\teta 0:04:49\tloss 0.4197 (0.5507)\tacc 93.7500 (84.6875)\tlr 1.637424e-03\n",
            "epoch [16/50][15/18]\ttime 0.117 (0.352)\tdata 0.000 (0.201)\teta 0:03:36\tloss 0.3235 (0.5028)\tacc 93.7500 (85.6250)\tlr 1.637424e-03\n",
            "epoch [17/50][5/18]\ttime 0.172 (0.664)\tdata 0.000 (0.482)\teta 0:06:43\tloss 0.4304 (0.5259)\tacc 84.3750 (85.0000)\tlr 1.587785e-03\n",
            "epoch [17/50][10/18]\ttime 0.116 (0.464)\tdata 0.000 (0.285)\teta 0:04:39\tloss 0.1951 (0.4985)\tacc 96.8750 (86.5625)\tlr 1.587785e-03\n",
            "epoch [17/50][15/18]\ttime 0.117 (0.349)\tdata 0.000 (0.190)\teta 0:03:28\tloss 0.5161 (0.4696)\tacc 87.5000 (86.6667)\tlr 1.587785e-03\n",
            "epoch [18/50][5/18]\ttime 0.172 (0.717)\tdata 0.000 (0.518)\teta 0:07:02\tloss 0.3843 (0.4720)\tacc 90.6250 (87.5000)\tlr 1.535827e-03\n",
            "epoch [18/50][10/18]\ttime 0.122 (0.485)\tdata 0.000 (0.299)\teta 0:04:43\tloss 0.3081 (0.4117)\tacc 87.5000 (88.1250)\tlr 1.535827e-03\n",
            "epoch [18/50][15/18]\ttime 0.116 (0.363)\tdata 0.000 (0.199)\teta 0:03:30\tloss 0.3911 (0.4176)\tacc 87.5000 (88.5417)\tlr 1.535827e-03\n",
            "epoch [19/50][5/18]\ttime 0.345 (0.868)\tdata 0.000 (0.515)\teta 0:08:15\tloss 0.3005 (0.3842)\tacc 90.6250 (88.1250)\tlr 1.481754e-03\n",
            "epoch [19/50][10/18]\ttime 0.394 (0.634)\tdata 0.238 (0.318)\teta 0:05:58\tloss 0.5767 (0.4396)\tacc 81.2500 (86.2500)\tlr 1.481754e-03\n",
            "epoch [19/50][15/18]\ttime 0.121 (0.469)\tdata 0.000 (0.212)\teta 0:04:22\tloss 0.3147 (0.4248)\tacc 90.6250 (87.5000)\tlr 1.481754e-03\n",
            "epoch [20/50][5/18]\ttime 0.351 (1.178)\tdata 0.000 (0.799)\teta 0:10:51\tloss 0.5835 (0.4099)\tacc 87.5000 (88.7500)\tlr 1.425779e-03\n",
            "epoch [20/50][10/18]\ttime 0.156 (0.775)\tdata 0.000 (0.444)\teta 0:07:04\tloss 0.3430 (0.4131)\tacc 87.5000 (89.3750)\tlr 1.425779e-03\n",
            "epoch [20/50][15/18]\ttime 0.146 (0.560)\tdata 0.000 (0.296)\teta 0:05:04\tloss 0.3674 (0.4230)\tacc 93.7500 (89.1667)\tlr 1.425779e-03\n",
            "epoch [21/50][5/18]\ttime 0.174 (0.878)\tdata 0.000 (0.676)\teta 0:07:49\tloss 0.3992 (0.5120)\tacc 90.6250 (87.5000)\tlr 1.368125e-03\n",
            "epoch [21/50][10/18]\ttime 0.123 (0.561)\tdata 0.000 (0.369)\teta 0:04:57\tloss 0.2440 (0.4225)\tacc 96.8750 (89.6875)\tlr 1.368125e-03\n",
            "epoch [21/50][15/18]\ttime 0.118 (0.415)\tdata 0.001 (0.247)\teta 0:03:37\tloss 0.2676 (0.4121)\tacc 93.7500 (89.5833)\tlr 1.368125e-03\n",
            "epoch [22/50][5/18]\ttime 0.189 (0.674)\tdata 0.000 (0.458)\teta 0:05:48\tloss 0.4612 (0.4484)\tacc 87.5000 (85.0000)\tlr 1.309017e-03\n",
            "epoch [22/50][10/18]\ttime 0.126 (0.476)\tdata 0.000 (0.295)\teta 0:04:03\tloss 0.3052 (0.4023)\tacc 90.6250 (86.8750)\tlr 1.309017e-03\n",
            "epoch [22/50][15/18]\ttime 0.118 (0.357)\tdata 0.000 (0.197)\teta 0:03:01\tloss 0.4297 (0.4063)\tacc 90.6250 (87.5000)\tlr 1.309017e-03\n",
            "epoch [23/50][5/18]\ttime 0.158 (0.676)\tdata 0.000 (0.471)\teta 0:05:37\tloss 0.4387 (0.5319)\tacc 90.6250 (83.7500)\tlr 1.248690e-03\n",
            "epoch [23/50][10/18]\ttime 0.127 (0.465)\tdata 0.000 (0.288)\teta 0:03:49\tloss 0.5254 (0.5051)\tacc 84.3750 (85.9375)\tlr 1.248690e-03\n",
            "epoch [23/50][15/18]\ttime 0.118 (0.349)\tdata 0.000 (0.192)\teta 0:02:50\tloss 0.1963 (0.4444)\tacc 96.8750 (87.7083)\tlr 1.248690e-03\n",
            "epoch [24/50][5/18]\ttime 0.204 (0.650)\tdata 0.000 (0.448)\teta 0:05:12\tloss 0.5591 (0.3634)\tacc 84.3750 (90.6250)\tlr 1.187381e-03\n",
            "epoch [24/50][10/18]\ttime 0.118 (0.469)\tdata 0.000 (0.281)\teta 0:03:43\tloss 0.3132 (0.3475)\tacc 93.7500 (91.8750)\tlr 1.187381e-03\n",
            "epoch [24/50][15/18]\ttime 0.119 (0.353)\tdata 0.001 (0.188)\teta 0:02:46\tloss 0.3391 (0.3649)\tacc 87.5000 (90.8333)\tlr 1.187381e-03\n",
            "epoch [25/50][5/18]\ttime 0.177 (0.704)\tdata 0.000 (0.489)\teta 0:05:26\tloss 0.4216 (0.3911)\tacc 90.6250 (90.0000)\tlr 1.125333e-03\n",
            "epoch [25/50][10/18]\ttime 0.126 (0.477)\tdata 0.001 (0.288)\teta 0:03:38\tloss 0.1023 (0.3328)\tacc 100.0000 (91.2500)\tlr 1.125333e-03\n",
            "epoch [25/50][15/18]\ttime 0.118 (0.359)\tdata 0.000 (0.193)\teta 0:02:42\tloss 0.4895 (0.3824)\tacc 81.2500 (89.5833)\tlr 1.125333e-03\n",
            "epoch [26/50][5/18]\ttime 0.189 (0.652)\tdata 0.000 (0.428)\teta 0:04:50\tloss 0.4824 (0.4093)\tacc 84.3750 (86.8750)\tlr 1.062791e-03\n",
            "epoch [26/50][10/18]\ttime 0.142 (0.466)\tdata 0.018 (0.262)\teta 0:03:25\tloss 0.4426 (0.4453)\tacc 84.3750 (86.8750)\tlr 1.062791e-03\n",
            "epoch [26/50][15/18]\ttime 0.118 (0.352)\tdata 0.001 (0.176)\teta 0:02:33\tloss 0.4116 (0.4541)\tacc 87.5000 (86.6667)\tlr 1.062791e-03\n",
            "epoch [27/50][5/18]\ttime 0.318 (1.109)\tdata 0.000 (0.809)\teta 0:07:53\tloss 0.6743 (0.5110)\tacc 84.3750 (84.3750)\tlr 1.000000e-03\n",
            "epoch [27/50][10/18]\ttime 0.159 (0.709)\tdata 0.000 (0.418)\teta 0:04:59\tloss 0.1703 (0.4953)\tacc 96.8750 (85.6250)\tlr 1.000000e-03\n",
            "epoch [27/50][15/18]\ttime 0.135 (0.518)\tdata 0.003 (0.279)\teta 0:03:35\tloss 0.8208 (0.4915)\tacc 78.1250 (86.2500)\tlr 1.000000e-03\n",
            "epoch [28/50][5/18]\ttime 0.205 (0.894)\tdata 0.000 (0.699)\teta 0:06:05\tloss 0.4397 (0.5041)\tacc 93.7500 (86.8750)\tlr 9.372095e-04\n",
            "epoch [28/50][10/18]\ttime 0.117 (0.576)\tdata 0.000 (0.399)\teta 0:03:52\tloss 0.6411 (0.4687)\tacc 81.2500 (86.8750)\tlr 9.372095e-04\n",
            "epoch [28/50][15/18]\ttime 0.118 (0.424)\tdata 0.001 (0.266)\teta 0:02:49\tloss 0.4138 (0.4705)\tacc 96.8750 (87.5000)\tlr 9.372095e-04\n",
            "epoch [29/50][5/18]\ttime 0.168 (0.624)\tdata 0.000 (0.411)\teta 0:04:04\tloss 0.5444 (0.4947)\tacc 90.6250 (88.1250)\tlr 8.746668e-04\n",
            "epoch [29/50][10/18]\ttime 0.163 (0.456)\tdata 0.000 (0.253)\teta 0:02:56\tloss 0.4983 (0.4593)\tacc 81.2500 (88.1250)\tlr 8.746668e-04\n",
            "epoch [29/50][15/18]\ttime 0.119 (0.345)\tdata 0.000 (0.169)\teta 0:02:11\tloss 0.4265 (0.4996)\tacc 90.6250 (87.7083)\tlr 8.746668e-04\n",
            "epoch [30/50][5/18]\ttime 0.180 (0.640)\tdata 0.000 (0.442)\teta 0:03:58\tloss 0.1759 (0.2708)\tacc 93.7500 (92.5000)\tlr 8.126187e-04\n",
            "epoch [30/50][10/18]\ttime 0.128 (0.464)\tdata 0.000 (0.282)\teta 0:02:50\tloss 0.3264 (0.2915)\tacc 90.6250 (92.5000)\tlr 8.126187e-04\n",
            "epoch [30/50][15/18]\ttime 0.117 (0.349)\tdata 0.000 (0.188)\teta 0:02:06\tloss 0.7710 (0.3324)\tacc 71.8750 (91.0417)\tlr 8.126187e-04\n",
            "epoch [31/50][5/18]\ttime 0.188 (0.681)\tdata 0.000 (0.482)\teta 0:04:01\tloss 0.3652 (0.3894)\tacc 90.6250 (92.5000)\tlr 7.513101e-04\n",
            "epoch [31/50][10/18]\ttime 0.122 (0.485)\tdata 0.000 (0.304)\teta 0:02:49\tloss 0.5645 (0.4061)\tacc 87.5000 (90.0000)\tlr 7.513101e-04\n",
            "epoch [31/50][15/18]\ttime 0.118 (0.364)\tdata 0.000 (0.203)\teta 0:02:05\tloss 0.2852 (0.4076)\tacc 93.7500 (88.9583)\tlr 7.513101e-04\n",
            "epoch [32/50][5/18]\ttime 0.172 (0.618)\tdata 0.000 (0.426)\teta 0:03:28\tloss 0.6255 (0.4799)\tacc 84.3750 (86.8750)\tlr 6.909830e-04\n",
            "epoch [32/50][10/18]\ttime 0.227 (0.450)\tdata 0.098 (0.271)\teta 0:02:29\tloss 0.5205 (0.4457)\tacc 87.5000 (88.1250)\tlr 6.909830e-04\n",
            "epoch [32/50][15/18]\ttime 0.118 (0.344)\tdata 0.000 (0.183)\teta 0:01:52\tloss 0.3484 (0.4500)\tacc 93.7500 (88.3333)\tlr 6.909830e-04\n",
            "epoch [33/50][5/18]\ttime 0.158 (0.657)\tdata 0.000 (0.458)\teta 0:03:29\tloss 0.4197 (0.4603)\tacc 87.5000 (88.1250)\tlr 6.318754e-04\n",
            "epoch [33/50][10/18]\ttime 0.791 (0.482)\tdata 0.673 (0.296)\teta 0:02:31\tloss 0.3523 (0.3879)\tacc 90.6250 (90.0000)\tlr 6.318754e-04\n",
            "epoch [33/50][15/18]\ttime 0.117 (0.361)\tdata 0.000 (0.198)\teta 0:01:51\tloss 0.2418 (0.3728)\tacc 96.8750 (90.6250)\tlr 6.318754e-04\n",
            "epoch [34/50][5/18]\ttime 0.324 (0.933)\tdata 0.000 (0.576)\teta 0:04:40\tloss 0.4841 (0.3829)\tacc 84.3750 (88.7500)\tlr 5.742207e-04\n",
            "epoch [34/50][10/18]\ttime 0.187 (0.668)\tdata 0.000 (0.354)\teta 0:03:17\tloss 0.1808 (0.3519)\tacc 96.8750 (89.0625)\tlr 5.742207e-04\n",
            "epoch [34/50][15/18]\ttime 0.122 (0.489)\tdata 0.001 (0.236)\teta 0:02:22\tloss 0.1763 (0.3656)\tacc 100.0000 (89.5833)\tlr 5.742207e-04\n",
            "epoch [35/50][5/18]\ttime 0.342 (1.067)\tdata 0.000 (0.715)\teta 0:05:01\tloss 0.3845 (0.4078)\tacc 84.3750 (87.5000)\tlr 5.182463e-04\n",
            "epoch [35/50][10/18]\ttime 0.118 (0.672)\tdata 0.000 (0.373)\teta 0:03:06\tloss 0.2100 (0.4301)\tacc 93.7500 (86.8750)\tlr 5.182463e-04\n",
            "epoch [35/50][15/18]\ttime 0.119 (0.491)\tdata 0.000 (0.251)\teta 0:02:14\tloss 0.4700 (0.4247)\tacc 87.5000 (87.7083)\tlr 5.182463e-04\n",
            "epoch [36/50][5/18]\ttime 0.165 (0.643)\tdata 0.000 (0.437)\teta 0:02:50\tloss 0.4514 (0.4062)\tacc 84.3750 (89.3750)\tlr 4.641732e-04\n",
            "epoch [36/50][10/18]\ttime 0.143 (0.477)\tdata 0.000 (0.284)\teta 0:02:04\tloss 0.5127 (0.4326)\tacc 84.3750 (87.5000)\tlr 4.641732e-04\n",
            "epoch [36/50][15/18]\ttime 0.119 (0.357)\tdata 0.000 (0.189)\teta 0:01:31\tloss 0.2454 (0.4313)\tacc 90.6250 (86.8750)\tlr 4.641732e-04\n",
            "epoch [37/50][5/18]\ttime 0.136 (0.690)\tdata 0.000 (0.489)\teta 0:02:50\tloss 0.1970 (0.2740)\tacc 93.7500 (93.1250)\tlr 4.122147e-04\n",
            "epoch [37/50][10/18]\ttime 0.186 (0.470)\tdata 0.067 (0.298)\teta 0:01:53\tloss 0.3765 (0.3051)\tacc 93.7500 (91.8750)\tlr 4.122147e-04\n",
            "epoch [37/50][15/18]\ttime 0.119 (0.355)\tdata 0.000 (0.199)\teta 0:01:24\tloss 0.4468 (0.3582)\tacc 93.7500 (90.4167)\tlr 4.122147e-04\n",
            "epoch [38/50][5/18]\ttime 0.189 (0.723)\tdata 0.000 (0.502)\teta 0:02:45\tloss 0.3979 (0.4940)\tacc 84.3750 (83.1250)\tlr 3.625760e-04\n",
            "epoch [38/50][10/18]\ttime 0.241 (0.474)\tdata 0.124 (0.265)\teta 0:01:46\tloss 0.4084 (0.4733)\tacc 90.6250 (85.6250)\tlr 3.625760e-04\n",
            "epoch [38/50][15/18]\ttime 0.118 (0.357)\tdata 0.000 (0.177)\teta 0:01:18\tloss 0.5278 (0.4529)\tacc 84.3750 (87.0833)\tlr 3.625760e-04\n",
            "epoch [39/50][5/18]\ttime 0.204 (0.653)\tdata 0.000 (0.434)\teta 0:02:17\tloss 0.6460 (0.4298)\tacc 87.5000 (88.7500)\tlr 3.154529e-04\n",
            "epoch [39/50][10/18]\ttime 0.621 (0.472)\tdata 0.503 (0.273)\teta 0:01:37\tloss 0.3201 (0.4537)\tacc 93.7500 (87.8125)\tlr 3.154529e-04\n",
            "epoch [39/50][15/18]\ttime 0.119 (0.355)\tdata 0.000 (0.182)\teta 0:01:11\tloss 0.2705 (0.3933)\tacc 93.7500 (89.3750)\tlr 3.154529e-04\n",
            "epoch [40/50][5/18]\ttime 0.166 (0.684)\tdata 0.000 (0.457)\teta 0:02:12\tloss 0.3000 (0.3939)\tacc 93.7500 (91.2500)\tlr 2.710314e-04\n",
            "epoch [40/50][10/18]\ttime 0.219 (0.459)\tdata 0.089 (0.261)\teta 0:01:26\tloss 0.7759 (0.4477)\tacc 78.1250 (88.4375)\tlr 2.710314e-04\n",
            "epoch [40/50][15/18]\ttime 0.121 (0.347)\tdata 0.000 (0.174)\teta 0:01:03\tloss 0.2703 (0.4000)\tacc 93.7500 (89.1667)\tlr 2.710314e-04\n",
            "epoch [41/50][5/18]\ttime 0.344 (1.045)\tdata 0.000 (0.712)\teta 0:03:02\tloss 0.3611 (0.4623)\tacc 90.6250 (85.6250)\tlr 2.294868e-04\n",
            "epoch [41/50][10/18]\ttime 0.123 (0.695)\tdata 0.000 (0.414)\teta 0:01:58\tloss 0.1033 (0.3764)\tacc 100.0000 (88.7500)\tlr 2.294868e-04\n",
            "epoch [41/50][15/18]\ttime 0.124 (0.507)\tdata 0.000 (0.276)\teta 0:01:23\tloss 0.1793 (0.4079)\tacc 93.7500 (87.5000)\tlr 2.294868e-04\n",
            "epoch [42/50][5/18]\ttime 0.345 (0.985)\tdata 0.000 (0.643)\teta 0:02:34\tloss 0.4436 (0.4065)\tacc 87.5000 (90.6250)\tlr 1.909830e-04\n",
            "epoch [42/50][10/18]\ttime 0.175 (0.623)\tdata 0.000 (0.335)\teta 0:01:34\tloss 0.4473 (0.3822)\tacc 90.6250 (90.3125)\tlr 1.909830e-04\n",
            "epoch [42/50][15/18]\ttime 0.132 (0.456)\tdata 0.000 (0.224)\teta 0:01:07\tloss 0.7783 (0.4553)\tacc 78.1250 (88.1250)\tlr 1.909830e-04\n",
            "epoch [43/50][5/18]\ttime 0.182 (0.694)\tdata 0.000 (0.493)\teta 0:01:36\tloss 0.6465 (0.3282)\tacc 71.8750 (88.7500)\tlr 1.556721e-04\n",
            "epoch [43/50][10/18]\ttime 0.127 (0.468)\tdata 0.010 (0.284)\teta 0:01:02\tloss 0.3767 (0.3716)\tacc 93.7500 (88.7500)\tlr 1.556721e-04\n",
            "epoch [43/50][15/18]\ttime 0.120 (0.353)\tdata 0.001 (0.190)\teta 0:00:45\tloss 0.5913 (0.3989)\tacc 84.3750 (88.9583)\tlr 1.556721e-04\n",
            "epoch [44/50][5/18]\ttime 0.164 (0.614)\tdata 0.000 (0.415)\teta 0:01:14\tloss 0.2430 (0.3482)\tacc 96.8750 (93.1250)\tlr 1.236933e-04\n",
            "epoch [44/50][10/18]\ttime 0.173 (0.449)\tdata 0.005 (0.259)\teta 0:00:52\tloss 0.3477 (0.3672)\tacc 90.6250 (91.5625)\tlr 1.236933e-04\n",
            "epoch [44/50][15/18]\ttime 0.117 (0.340)\tdata 0.001 (0.173)\teta 0:00:37\tloss 0.6587 (0.3828)\tacc 84.3750 (90.6250)\tlr 1.236933e-04\n",
            "epoch [45/50][5/18]\ttime 0.212 (0.637)\tdata 0.000 (0.445)\teta 0:01:05\tloss 0.3787 (0.4071)\tacc 87.5000 (86.2500)\tlr 9.517295e-05\n",
            "epoch [45/50][10/18]\ttime 0.123 (0.464)\tdata 0.000 (0.297)\teta 0:00:45\tloss 0.3020 (0.3817)\tacc 93.7500 (88.1250)\tlr 9.517295e-05\n",
            "epoch [45/50][15/18]\ttime 0.118 (0.349)\tdata 0.000 (0.198)\teta 0:00:32\tloss 0.2114 (0.3975)\tacc 96.8750 (88.7500)\tlr 9.517295e-05\n",
            "epoch [46/50][5/18]\ttime 0.165 (0.671)\tdata 0.000 (0.443)\teta 0:00:57\tloss 0.1580 (0.3893)\tacc 93.7500 (88.1250)\tlr 7.022351e-05\n",
            "epoch [46/50][10/18]\ttime 0.118 (0.482)\tdata 0.000 (0.288)\teta 0:00:38\tloss 0.4294 (0.4204)\tacc 87.5000 (87.5000)\tlr 7.022351e-05\n",
            "epoch [46/50][15/18]\ttime 0.118 (0.362)\tdata 0.000 (0.193)\teta 0:00:27\tloss 0.6685 (0.4242)\tacc 84.3750 (88.1250)\tlr 7.022351e-05\n",
            "epoch [47/50][5/18]\ttime 0.211 (0.719)\tdata 0.000 (0.515)\teta 0:00:48\tloss 0.5576 (0.3584)\tacc 84.3750 (90.6250)\tlr 4.894348e-05\n",
            "epoch [47/50][10/18]\ttime 0.127 (0.482)\tdata 0.002 (0.299)\teta 0:00:29\tloss 0.3643 (0.3731)\tacc 93.7500 (90.9375)\tlr 4.894348e-05\n",
            "epoch [47/50][15/18]\ttime 0.118 (0.362)\tdata 0.000 (0.199)\teta 0:00:20\tloss 0.3389 (0.3822)\tacc 90.6250 (90.0000)\tlr 4.894348e-05\n",
            "epoch [48/50][5/18]\ttime 0.311 (0.974)\tdata 0.000 (0.602)\teta 0:00:47\tloss 0.3889 (0.3180)\tacc 90.6250 (91.8750)\tlr 3.141684e-05\n",
            "epoch [48/50][10/18]\ttime 0.153 (0.676)\tdata 0.000 (0.363)\teta 0:00:29\tloss 0.6206 (0.3602)\tacc 75.0000 (89.3750)\tlr 3.141684e-05\n",
            "epoch [48/50][15/18]\ttime 0.121 (0.495)\tdata 0.000 (0.242)\teta 0:00:19\tloss 0.3940 (0.3962)\tacc 93.7500 (89.3750)\tlr 3.141684e-05\n",
            "epoch [49/50][5/18]\ttime 0.380 (1.214)\tdata 0.000 (0.834)\teta 0:00:37\tloss 0.6411 (0.4536)\tacc 75.0000 (85.0000)\tlr 1.771275e-05\n",
            "epoch [49/50][10/18]\ttime 0.137 (0.783)\tdata 0.000 (0.455)\teta 0:00:20\tloss 0.3994 (0.4134)\tacc 84.3750 (86.5625)\tlr 1.771275e-05\n",
            "epoch [49/50][15/18]\ttime 0.155 (0.565)\tdata 0.005 (0.304)\teta 0:00:11\tloss 0.5420 (0.3958)\tacc 84.3750 (87.9167)\tlr 1.771275e-05\n",
            "epoch [50/50][5/18]\ttime 0.313 (1.092)\tdata 0.000 (0.773)\teta 0:00:14\tloss 0.7065 (0.4683)\tacc 81.2500 (87.5000)\tlr 7.885299e-06\n",
            "epoch [50/50][10/18]\ttime 0.124 (0.666)\tdata 0.000 (0.413)\teta 0:00:05\tloss 0.1082 (0.3920)\tacc 96.8750 (89.3750)\tlr 7.885299e-06\n",
            "epoch [50/50][15/18]\ttime 0.117 (0.485)\tdata 0.000 (0.276)\teta 0:00:01\tloss 0.2064 (0.3917)\tacc 96.8750 (88.7500)\tlr 7.885299e-06\n",
            "Checkpoint saved to \"./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed1/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 3,669\n",
            "* correct: 3,029\n",
            "* accuracy: 82.56%\n",
            "* error: 17.44%\n",
            "* macro_f1: 82.48%\n",
            "=> per-class result\n",
            "* class: 1 (american_bulldog)\ttotal: 100\tcorrect: 73\tacc: 73.00%\n",
            "* class: 34 (staffordshire_bull_terrier)\ttotal: 89\tcorrect: 41\tacc: 46.07%\n",
            "* class: 18 (keeshond)\ttotal: 99\tcorrect: 95\tacc: 95.96%\n",
            "* class: 12 (english_cocker_spaniel)\ttotal: 100\tcorrect: 72\tacc: 72.00%\n",
            "* class: 14 (german_shorthaired)\ttotal: 100\tcorrect: 92\tacc: 92.00%\n",
            "* class: 10 (chihuahua)\ttotal: 100\tcorrect: 81\tacc: 81.00%\n",
            "* class: 28 (saint_bernard)\ttotal: 100\tcorrect: 78\tacc: 78.00%\n",
            "* class: 4 (beagle)\ttotal: 100\tcorrect: 55\tacc: 55.00%\n",
            "* class: 6 (birman)\ttotal: 100\tcorrect: 60\tacc: 60.00%\n",
            "* class: 26 (ragdoll)\ttotal: 100\tcorrect: 68\tacc: 68.00%\n",
            "* class: 8 (boxer)\ttotal: 99\tcorrect: 90\tacc: 90.91%\n",
            "* class: 31 (shiba_inu)\ttotal: 100\tcorrect: 96\tacc: 96.00%\n",
            "* class: 17 (japanese_chin)\ttotal: 100\tcorrect: 90\tacc: 90.00%\n",
            "* class: 7 (bombay)\ttotal: 88\tcorrect: 84\tacc: 95.45%\n",
            "* class: 20 (maine_coon)\ttotal: 100\tcorrect: 86\tacc: 86.00%\n",
            "* class: 5 (bengal)\ttotal: 100\tcorrect: 87\tacc: 87.00%\n",
            "* class: 29 (samoyed)\ttotal: 100\tcorrect: 100\tacc: 100.00%\n",
            "* class: 35 (wheaten_terrier)\ttotal: 100\tcorrect: 94\tacc: 94.00%\n",
            "* class: 2 (american_pit_bull_terrier)\ttotal: 100\tcorrect: 67\tacc: 67.00%\n",
            "* class: 23 (persian)\ttotal: 100\tcorrect: 71\tacc: 71.00%\n",
            "* class: 32 (siamese)\ttotal: 100\tcorrect: 80\tacc: 80.00%\n",
            "* class: 33 (sphynx)\ttotal: 100\tcorrect: 94\tacc: 94.00%\n",
            "* class: 16 (havanese)\ttotal: 100\tcorrect: 79\tacc: 79.00%\n",
            "* class: 24 (pomeranian)\ttotal: 100\tcorrect: 96\tacc: 96.00%\n",
            "* class: 30 (scottish_terrier)\ttotal: 99\tcorrect: 93\tacc: 93.94%\n",
            "* class: 27 (russian_blue)\ttotal: 100\tcorrect: 79\tacc: 79.00%\n",
            "* class: 36 (yorkshire_terrier)\ttotal: 100\tcorrect: 89\tacc: 89.00%\n",
            "* class: 22 (newfoundland)\ttotal: 100\tcorrect: 88\tacc: 88.00%\n",
            "* class: 3 (basset_hound)\ttotal: 100\tcorrect: 85\tacc: 85.00%\n",
            "* class: 11 (egyptian_mau)\ttotal: 97\tcorrect: 77\tacc: 79.38%\n",
            "* class: 15 (great_pyrenees)\ttotal: 100\tcorrect: 89\tacc: 89.00%\n",
            "* class: 9 (british_shorthair)\ttotal: 100\tcorrect: 64\tacc: 64.00%\n",
            "* class: 21 (miniature_pinscher)\ttotal: 100\tcorrect: 93\tacc: 93.00%\n",
            "* class: 19 (leonberger)\ttotal: 100\tcorrect: 86\tacc: 86.00%\n",
            "* class: 0 (abyssinian)\ttotal: 98\tcorrect: 80\tacc: 81.63%\n",
            "* class: 13 (english_setter)\ttotal: 100\tcorrect: 87\tacc: 87.00%\n",
            "* class: 25 (pug)\ttotal: 100\tcorrect: 90\tacc: 90.00%\n",
            "* average: 82.50%\n",
            "Elapsed: 0:05:58\n",
            "Run this job and save the output to ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed2\n",
            "in jaffe\n",
            "Setting fixed seed: 2\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssoxford_pets.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'middle', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed2\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 2\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSOxfordPets\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed2\n",
            "RESUME: \n",
            "SEED: 2\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: middle\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSOxfordPets\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSOxfordPets\n",
            "  # classes: 37\n",
            "  # train_x: 2,944\n",
            "  # val: 736\n",
            "  # test: 3,669\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 37/37 [00:00<00:00, 13565.49it/s]\n",
            "SSOxfordPets\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "sstrain 592\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed2/tensorboard\n",
            "epoch [1/50][5/18]\ttime 0.119 (1.205)\tdata 0.000 (0.547)\teta 0:17:58\tloss 2.3906 (2.5105)\tacc 40.6250 (40.6250)\tlr 1.000000e-05\n",
            "epoch [1/50][10/18]\ttime 0.118 (0.662)\tdata 0.000 (0.273)\teta 0:09:48\tloss 2.1738 (2.3561)\tacc 40.6250 (42.1875)\tlr 1.000000e-05\n",
            "epoch [1/50][15/18]\ttime 0.118 (0.480)\tdata 0.000 (0.182)\teta 0:07:05\tloss 1.5283 (2.2092)\tacc 53.1250 (44.3750)\tlr 1.000000e-05\n",
            "epoch [2/50][5/18]\ttime 0.206 (0.671)\tdata 0.000 (0.458)\teta 0:09:48\tloss 0.9292 (0.9559)\tacc 81.2500 (77.5000)\tlr 2.000000e-03\n",
            "epoch [2/50][10/18]\ttime 0.143 (0.473)\tdata 0.000 (0.279)\teta 0:06:52\tloss 0.6318 (0.7765)\tacc 78.1250 (80.0000)\tlr 2.000000e-03\n",
            "epoch [2/50][15/18]\ttime 0.118 (0.355)\tdata 0.000 (0.186)\teta 0:05:07\tloss 0.8833 (0.7583)\tacc 81.2500 (80.4167)\tlr 2.000000e-03\n",
            "epoch [3/50][5/18]\ttime 0.155 (0.626)\tdata 0.000 (0.418)\teta 0:08:57\tloss 1.1650 (0.7981)\tacc 65.6250 (78.7500)\tlr 1.998027e-03\n",
            "epoch [3/50][10/18]\ttime 0.271 (0.455)\tdata 0.146 (0.259)\teta 0:06:28\tloss 0.4429 (0.7112)\tacc 93.7500 (81.5625)\tlr 1.998027e-03\n",
            "epoch [3/50][15/18]\ttime 0.118 (0.344)\tdata 0.000 (0.173)\teta 0:04:51\tloss 0.2502 (0.6280)\tacc 93.7500 (83.3333)\tlr 1.998027e-03\n",
            "epoch [4/50][5/18]\ttime 0.194 (0.644)\tdata 0.000 (0.440)\teta 0:09:01\tloss 0.4282 (0.4579)\tacc 87.5000 (89.3750)\tlr 1.992115e-03\n",
            "epoch [4/50][10/18]\ttime 0.169 (0.460)\tdata 0.000 (0.272)\teta 0:06:24\tloss 0.4556 (0.4846)\tacc 90.6250 (87.8125)\tlr 1.992115e-03\n",
            "epoch [4/50][15/18]\ttime 0.121 (0.350)\tdata 0.000 (0.184)\teta 0:04:50\tloss 0.8462 (0.5351)\tacc 78.1250 (86.0417)\tlr 1.992115e-03\n",
            "epoch [5/50][5/18]\ttime 0.329 (1.042)\tdata 0.001 (0.722)\teta 0:14:17\tloss 0.9414 (0.5392)\tacc 87.5000 (87.5000)\tlr 1.982287e-03\n",
            "epoch [5/50][10/18]\ttime 0.392 (0.715)\tdata 0.246 (0.430)\teta 0:09:45\tloss 0.4666 (0.5026)\tacc 84.3750 (87.5000)\tlr 1.982287e-03\n",
            "epoch [5/50][15/18]\ttime 0.131 (0.520)\tdata 0.000 (0.287)\teta 0:07:02\tloss 0.7437 (0.5377)\tacc 78.1250 (85.6250)\tlr 1.982287e-03\n",
            "epoch [6/50][5/18]\ttime 0.193 (0.989)\tdata 0.000 (0.706)\teta 0:13:15\tloss 0.4546 (0.5496)\tacc 87.5000 (86.2500)\tlr 1.968583e-03\n",
            "epoch [6/50][10/18]\ttime 0.124 (0.596)\tdata 0.000 (0.371)\teta 0:07:56\tloss 0.8203 (0.5904)\tacc 75.0000 (84.3750)\tlr 1.968583e-03\n",
            "epoch [6/50][15/18]\ttime 0.119 (0.438)\tdata 0.000 (0.247)\teta 0:05:48\tloss 0.5737 (0.5316)\tacc 87.5000 (85.8333)\tlr 1.968583e-03\n",
            "epoch [7/50][5/18]\ttime 0.132 (0.639)\tdata 0.000 (0.471)\teta 0:08:22\tloss 0.4387 (0.4036)\tacc 87.5000 (91.2500)\tlr 1.951057e-03\n",
            "epoch [7/50][10/18]\ttime 0.579 (0.463)\tdata 0.464 (0.302)\teta 0:06:02\tloss 0.8242 (0.4993)\tacc 78.1250 (86.8750)\tlr 1.951057e-03\n",
            "epoch [7/50][15/18]\ttime 0.119 (0.349)\tdata 0.001 (0.201)\teta 0:04:31\tloss 0.5249 (0.4938)\tacc 81.2500 (85.8333)\tlr 1.951057e-03\n",
            "epoch [8/50][5/18]\ttime 0.143 (0.612)\tdata 0.000 (0.430)\teta 0:07:50\tloss 0.3740 (0.5298)\tacc 90.6250 (83.7500)\tlr 1.929776e-03\n",
            "epoch [8/50][10/18]\ttime 0.216 (0.457)\tdata 0.000 (0.275)\teta 0:05:48\tloss 0.3926 (0.4870)\tacc 87.5000 (86.2500)\tlr 1.929776e-03\n",
            "epoch [8/50][15/18]\ttime 0.118 (0.346)\tdata 0.000 (0.184)\teta 0:04:22\tloss 0.2637 (0.5023)\tacc 93.7500 (86.2500)\tlr 1.929776e-03\n",
            "epoch [9/50][5/18]\ttime 0.140 (0.613)\tdata 0.000 (0.445)\teta 0:07:40\tloss 0.4626 (0.5837)\tacc 87.5000 (84.3750)\tlr 1.904827e-03\n",
            "epoch [9/50][10/18]\ttime 0.120 (0.464)\tdata 0.000 (0.300)\teta 0:05:45\tloss 0.3164 (0.6215)\tacc 96.8750 (84.6875)\tlr 1.904827e-03\n",
            "epoch [9/50][15/18]\ttime 0.120 (0.350)\tdata 0.000 (0.200)\teta 0:04:19\tloss 0.3345 (0.5732)\tacc 90.6250 (86.2500)\tlr 1.904827e-03\n",
            "epoch [10/50][5/18]\ttime 0.207 (0.661)\tdata 0.000 (0.453)\teta 0:08:04\tloss 0.4084 (0.5409)\tacc 90.6250 (88.7500)\tlr 1.876307e-03\n",
            "epoch [10/50][10/18]\ttime 0.155 (0.460)\tdata 0.000 (0.263)\teta 0:05:34\tloss 0.3125 (0.4941)\tacc 93.7500 (88.7500)\tlr 1.876307e-03\n",
            "epoch [10/50][15/18]\ttime 0.120 (0.347)\tdata 0.000 (0.175)\teta 0:04:11\tloss 0.3359 (0.4324)\tacc 87.5000 (89.7917)\tlr 1.876307e-03\n",
            "epoch [11/50][5/18]\ttime 0.179 (0.651)\tdata 0.000 (0.445)\teta 0:07:45\tloss 0.4429 (0.4832)\tacc 84.3750 (85.6250)\tlr 1.844328e-03\n",
            "epoch [11/50][10/18]\ttime 0.123 (0.465)\tdata 0.000 (0.284)\teta 0:05:30\tloss 0.5684 (0.4596)\tacc 87.5000 (88.1250)\tlr 1.844328e-03\n",
            "epoch [11/50][15/18]\ttime 0.118 (0.350)\tdata 0.000 (0.190)\teta 0:04:06\tloss 0.6152 (0.4575)\tacc 84.3750 (88.1250)\tlr 1.844328e-03\n",
            "epoch [12/50][5/18]\ttime 0.328 (1.052)\tdata 0.000 (0.714)\teta 0:12:13\tloss 0.4844 (0.5450)\tacc 81.2500 (83.1250)\tlr 1.809017e-03\n",
            "epoch [12/50][10/18]\ttime 0.182 (0.677)\tdata 0.000 (0.375)\teta 0:07:48\tloss 0.4299 (0.4858)\tacc 90.6250 (85.9375)\tlr 1.809017e-03\n",
            "epoch [12/50][15/18]\ttime 0.158 (0.500)\tdata 0.000 (0.250)\teta 0:05:43\tloss 0.3179 (0.4574)\tacc 93.7500 (86.8750)\tlr 1.809017e-03\n",
            "epoch [13/50][5/18]\ttime 0.226 (0.938)\tdata 0.000 (0.608)\teta 0:10:37\tloss 0.3591 (0.4041)\tacc 93.7500 (89.3750)\tlr 1.770513e-03\n",
            "epoch [13/50][10/18]\ttime 0.194 (0.644)\tdata 0.000 (0.341)\teta 0:07:14\tloss 0.5601 (0.4628)\tacc 84.3750 (87.5000)\tlr 1.770513e-03\n",
            "epoch [13/50][15/18]\ttime 0.130 (0.470)\tdata 0.000 (0.227)\teta 0:05:14\tloss 0.8042 (0.4599)\tacc 81.2500 (87.9167)\tlr 1.770513e-03\n",
            "epoch [14/50][5/18]\ttime 0.176 (0.658)\tdata 0.000 (0.459)\teta 0:07:14\tloss 0.5273 (0.4159)\tacc 84.3750 (88.7500)\tlr 1.728969e-03\n",
            "epoch [14/50][10/18]\ttime 0.129 (0.473)\tdata 0.001 (0.294)\teta 0:05:10\tloss 0.7173 (0.4874)\tacc 78.1250 (85.6250)\tlr 1.728969e-03\n",
            "epoch [14/50][15/18]\ttime 0.118 (0.355)\tdata 0.000 (0.196)\teta 0:03:51\tloss 0.3848 (0.4781)\tacc 90.6250 (85.6250)\tlr 1.728969e-03\n",
            "epoch [15/50][5/18]\ttime 0.139 (0.691)\tdata 0.000 (0.498)\teta 0:07:24\tloss 0.3391 (0.4944)\tacc 93.7500 (86.2500)\tlr 1.684547e-03\n",
            "epoch [15/50][10/18]\ttime 0.121 (0.468)\tdata 0.000 (0.298)\teta 0:04:58\tloss 0.7661 (0.5500)\tacc 84.3750 (86.8750)\tlr 1.684547e-03\n",
            "epoch [15/50][15/18]\ttime 0.118 (0.352)\tdata 0.000 (0.199)\teta 0:03:42\tloss 0.8091 (0.5092)\tacc 78.1250 (87.5000)\tlr 1.684547e-03\n",
            "epoch [16/50][5/18]\ttime 0.170 (0.649)\tdata 0.000 (0.446)\teta 0:06:45\tloss 0.4072 (0.2853)\tacc 90.6250 (94.3750)\tlr 1.637424e-03\n",
            "epoch [16/50][10/18]\ttime 0.224 (0.469)\tdata 0.073 (0.281)\teta 0:04:50\tloss 0.9004 (0.4117)\tacc 78.1250 (90.9375)\tlr 1.637424e-03\n",
            "epoch [16/50][15/18]\ttime 0.118 (0.353)\tdata 0.000 (0.187)\teta 0:03:36\tloss 0.5771 (0.4616)\tacc 78.1250 (87.5000)\tlr 1.637424e-03\n",
            "epoch [17/50][5/18]\ttime 0.175 (0.686)\tdata 0.000 (0.470)\teta 0:06:56\tloss 0.7417 (0.4441)\tacc 84.3750 (87.5000)\tlr 1.587785e-03\n",
            "epoch [17/50][10/18]\ttime 0.120 (0.464)\tdata 0.000 (0.270)\teta 0:04:39\tloss 0.1896 (0.4149)\tacc 93.7500 (87.5000)\tlr 1.587785e-03\n",
            "epoch [17/50][15/18]\ttime 0.119 (0.351)\tdata 0.000 (0.181)\teta 0:03:29\tloss 0.3647 (0.4205)\tacc 87.5000 (87.2917)\tlr 1.587785e-03\n",
            "epoch [18/50][5/18]\ttime 0.203 (0.658)\tdata 0.000 (0.461)\teta 0:06:27\tloss 0.6738 (0.5918)\tacc 81.2500 (83.7500)\tlr 1.535827e-03\n",
            "epoch [18/50][10/18]\ttime 0.162 (0.457)\tdata 0.039 (0.270)\teta 0:04:26\tloss 0.4863 (0.4702)\tacc 84.3750 (87.1875)\tlr 1.535827e-03\n",
            "epoch [18/50][15/18]\ttime 0.124 (0.346)\tdata 0.007 (0.181)\teta 0:03:20\tloss 0.2644 (0.4520)\tacc 93.7500 (87.2917)\tlr 1.535827e-03\n",
            "epoch [19/50][5/18]\ttime 0.377 (0.798)\tdata 0.000 (0.482)\teta 0:07:35\tloss 0.4634 (0.3245)\tacc 84.3750 (91.2500)\tlr 1.481754e-03\n",
            "epoch [19/50][10/18]\ttime 0.200 (0.634)\tdata 0.000 (0.325)\teta 0:05:58\tloss 0.2859 (0.3641)\tacc 90.6250 (89.6875)\tlr 1.481754e-03\n",
            "epoch [19/50][15/18]\ttime 0.119 (0.467)\tdata 0.000 (0.217)\teta 0:04:21\tloss 0.2747 (0.3694)\tacc 96.8750 (89.7917)\tlr 1.481754e-03\n",
            "epoch [20/50][5/18]\ttime 0.325 (0.961)\tdata 0.003 (0.656)\teta 0:08:51\tloss 0.5933 (0.4880)\tacc 84.3750 (86.2500)\tlr 1.425779e-03\n",
            "epoch [20/50][10/18]\ttime 0.171 (0.662)\tdata 0.000 (0.386)\teta 0:06:02\tloss 0.3958 (0.4447)\tacc 87.5000 (86.8750)\tlr 1.425779e-03\n",
            "epoch [20/50][15/18]\ttime 0.149 (0.483)\tdata 0.009 (0.258)\teta 0:04:22\tloss 0.3669 (0.4045)\tacc 93.7500 (89.3750)\tlr 1.425779e-03\n",
            "epoch [21/50][5/18]\ttime 0.169 (0.749)\tdata 0.000 (0.544)\teta 0:06:40\tloss 0.6797 (0.4979)\tacc 84.3750 (87.5000)\tlr 1.368125e-03\n",
            "epoch [21/50][10/18]\ttime 0.139 (0.502)\tdata 0.000 (0.324)\teta 0:04:26\tloss 0.1035 (0.4705)\tacc 96.8750 (87.1875)\tlr 1.368125e-03\n",
            "epoch [21/50][15/18]\ttime 0.154 (0.382)\tdata 0.000 (0.216)\teta 0:03:20\tloss 0.5762 (0.4615)\tacc 87.5000 (87.5000)\tlr 1.368125e-03\n",
            "epoch [22/50][5/18]\ttime 0.285 (1.059)\tdata 0.001 (0.761)\teta 0:09:07\tloss 0.2244 (0.3919)\tacc 93.7500 (88.7500)\tlr 1.309017e-03\n",
            "epoch [22/50][10/18]\ttime 0.124 (0.693)\tdata 0.000 (0.425)\teta 0:05:54\tloss 0.1981 (0.3359)\tacc 96.8750 (90.9375)\tlr 1.309017e-03\n",
            "epoch [22/50][15/18]\ttime 0.122 (0.503)\tdata 0.000 (0.284)\teta 0:04:14\tloss 0.4521 (0.3648)\tacc 90.6250 (90.8333)\tlr 1.309017e-03\n",
            "epoch [23/50][5/18]\ttime 0.191 (0.880)\tdata 0.000 (0.658)\teta 0:07:19\tloss 0.2693 (0.3484)\tacc 87.5000 (90.0000)\tlr 1.248690e-03\n",
            "epoch [23/50][10/18]\ttime 0.119 (0.566)\tdata 0.000 (0.370)\teta 0:04:39\tloss 0.5352 (0.4031)\tacc 87.5000 (87.5000)\tlr 1.248690e-03\n",
            "epoch [23/50][15/18]\ttime 0.119 (0.418)\tdata 0.000 (0.247)\teta 0:03:24\tloss 0.4019 (0.3810)\tacc 90.6250 (89.3750)\tlr 1.248690e-03\n",
            "epoch [24/50][5/18]\ttime 0.202 (0.678)\tdata 0.000 (0.484)\teta 0:05:26\tloss 0.3252 (0.4957)\tacc 90.6250 (85.0000)\tlr 1.187381e-03\n",
            "epoch [24/50][10/18]\ttime 0.118 (0.463)\tdata 0.000 (0.292)\teta 0:03:40\tloss 0.5273 (0.4598)\tacc 78.1250 (87.1875)\tlr 1.187381e-03\n",
            "epoch [24/50][15/18]\ttime 0.117 (0.349)\tdata 0.000 (0.195)\teta 0:02:44\tloss 0.3188 (0.4483)\tacc 93.7500 (87.2917)\tlr 1.187381e-03\n",
            "epoch [25/50][5/18]\ttime 0.180 (0.682)\tdata 0.000 (0.480)\teta 0:05:15\tloss 0.3855 (0.4810)\tacc 87.5000 (85.6250)\tlr 1.125333e-03\n",
            "epoch [25/50][10/18]\ttime 0.130 (0.472)\tdata 0.001 (0.284)\teta 0:03:36\tloss 0.4841 (0.4170)\tacc 90.6250 (89.0625)\tlr 1.125333e-03\n",
            "epoch [25/50][15/18]\ttime 0.118 (0.355)\tdata 0.000 (0.189)\teta 0:02:40\tloss 0.4390 (0.4256)\tacc 84.3750 (88.3333)\tlr 1.125333e-03\n",
            "epoch [26/50][5/18]\ttime 0.306 (1.123)\tdata 0.001 (0.826)\teta 0:08:19\tloss 0.5508 (0.3418)\tacc 87.5000 (91.8750)\tlr 1.062791e-03\n",
            "epoch [26/50][10/18]\ttime 0.122 (0.695)\tdata 0.000 (0.428)\teta 0:05:05\tloss 0.3313 (0.3871)\tacc 93.7500 (90.6250)\tlr 1.062791e-03\n",
            "epoch [26/50][15/18]\ttime 0.124 (0.504)\tdata 0.006 (0.286)\teta 0:03:39\tloss 0.3647 (0.4070)\tacc 87.5000 (89.1667)\tlr 1.062791e-03\n",
            "epoch [27/50][5/18]\ttime 0.249 (0.974)\tdata 0.000 (0.660)\teta 0:06:55\tloss 0.4360 (0.4598)\tacc 93.7500 (87.5000)\tlr 1.000000e-03\n",
            "epoch [27/50][10/18]\ttime 0.125 (0.633)\tdata 0.000 (0.367)\teta 0:04:26\tloss 0.3799 (0.3999)\tacc 87.5000 (89.3750)\tlr 1.000000e-03\n",
            "epoch [27/50][15/18]\ttime 0.116 (0.462)\tdata 0.000 (0.244)\teta 0:03:12\tloss 0.4407 (0.4125)\tacc 90.6250 (89.3750)\tlr 1.000000e-03\n",
            "epoch [28/50][5/18]\ttime 0.195 (0.657)\tdata 0.000 (0.441)\teta 0:04:28\tloss 0.4922 (0.4043)\tacc 87.5000 (90.0000)\tlr 9.372095e-04\n",
            "epoch [28/50][10/18]\ttime 0.375 (0.461)\tdata 0.211 (0.260)\teta 0:03:06\tloss 0.2263 (0.4410)\tacc 93.7500 (88.1250)\tlr 9.372095e-04\n",
            "epoch [28/50][15/18]\ttime 0.118 (0.347)\tdata 0.000 (0.173)\teta 0:02:18\tloss 0.3662 (0.4057)\tacc 84.3750 (89.1667)\tlr 9.372095e-04\n",
            "epoch [29/50][5/18]\ttime 0.250 (0.693)\tdata 0.000 (0.485)\teta 0:04:30\tloss 0.1553 (0.4563)\tacc 96.8750 (88.7500)\tlr 8.746668e-04\n",
            "epoch [29/50][10/18]\ttime 0.119 (0.473)\tdata 0.000 (0.283)\teta 0:03:02\tloss 0.4800 (0.4270)\tacc 81.2500 (87.8125)\tlr 8.746668e-04\n",
            "epoch [29/50][15/18]\ttime 0.119 (0.355)\tdata 0.000 (0.189)\teta 0:02:15\tloss 0.5859 (0.4387)\tacc 87.5000 (87.9167)\tlr 8.746668e-04\n",
            "epoch [30/50][5/18]\ttime 0.174 (0.684)\tdata 0.000 (0.475)\teta 0:04:15\tloss 0.5176 (0.4201)\tacc 90.6250 (89.3750)\tlr 8.126187e-04\n",
            "epoch [30/50][10/18]\ttime 0.308 (0.477)\tdata 0.162 (0.288)\teta 0:02:55\tloss 0.3250 (0.4339)\tacc 87.5000 (88.7500)\tlr 8.126187e-04\n",
            "epoch [30/50][15/18]\ttime 0.117 (0.358)\tdata 0.000 (0.192)\teta 0:02:09\tloss 0.3252 (0.3935)\tacc 90.6250 (89.7917)\tlr 8.126187e-04\n",
            "epoch [31/50][5/18]\ttime 0.194 (0.695)\tdata 0.000 (0.494)\teta 0:04:06\tloss 0.3594 (0.3424)\tacc 90.6250 (91.2500)\tlr 7.513101e-04\n",
            "epoch [31/50][10/18]\ttime 0.121 (0.467)\tdata 0.000 (0.291)\teta 0:02:43\tloss 0.2903 (0.3711)\tacc 87.5000 (90.9375)\tlr 7.513101e-04\n",
            "epoch [31/50][15/18]\ttime 0.118 (0.352)\tdata 0.000 (0.194)\teta 0:02:01\tloss 0.4641 (0.3816)\tacc 87.5000 (90.0000)\tlr 7.513101e-04\n",
            "epoch [32/50][5/18]\ttime 0.174 (0.614)\tdata 0.000 (0.421)\teta 0:03:26\tloss 0.2212 (0.3681)\tacc 100.0000 (93.1250)\tlr 6.909830e-04\n",
            "epoch [32/50][10/18]\ttime 0.430 (0.453)\tdata 0.293 (0.272)\teta 0:02:30\tloss 0.1980 (0.3059)\tacc 96.8750 (93.7500)\tlr 6.909830e-04\n",
            "epoch [32/50][15/18]\ttime 0.119 (0.344)\tdata 0.000 (0.181)\teta 0:01:52\tloss 0.2286 (0.3456)\tacc 93.7500 (92.0833)\tlr 6.909830e-04\n",
            "epoch [33/50][5/18]\ttime 0.335 (1.028)\tdata 0.000 (0.688)\teta 0:05:28\tloss 0.3989 (0.3860)\tacc 90.6250 (89.3750)\tlr 6.318754e-04\n",
            "epoch [33/50][10/18]\ttime 0.152 (0.687)\tdata 0.000 (0.374)\teta 0:03:35\tloss 0.5112 (0.3865)\tacc 78.1250 (87.5000)\tlr 6.318754e-04\n",
            "epoch [33/50][15/18]\ttime 0.130 (0.501)\tdata 0.000 (0.250)\teta 0:02:34\tloss 0.4160 (0.4202)\tacc 87.5000 (87.0833)\tlr 6.318754e-04\n",
            "epoch [34/50][5/18]\ttime 0.316 (1.057)\tdata 0.000 (0.730)\teta 0:05:18\tloss 0.4114 (0.3937)\tacc 93.7500 (90.0000)\tlr 5.742207e-04\n",
            "epoch [34/50][10/18]\ttime 0.124 (0.663)\tdata 0.000 (0.378)\teta 0:03:16\tloss 0.5576 (0.3846)\tacc 87.5000 (90.0000)\tlr 5.742207e-04\n",
            "epoch [34/50][15/18]\ttime 0.120 (0.482)\tdata 0.000 (0.252)\teta 0:02:20\tloss 0.3435 (0.3856)\tacc 87.5000 (90.2083)\tlr 5.742207e-04\n",
            "epoch [35/50][5/18]\ttime 0.135 (0.641)\tdata 0.000 (0.462)\teta 0:03:01\tloss 0.1053 (0.3093)\tacc 93.7500 (89.3750)\tlr 5.182463e-04\n",
            "epoch [35/50][10/18]\ttime 0.291 (0.452)\tdata 0.128 (0.271)\teta 0:02:05\tloss 0.4509 (0.3683)\tacc 81.2500 (87.1875)\tlr 5.182463e-04\n",
            "epoch [35/50][15/18]\ttime 0.121 (0.357)\tdata 0.000 (0.195)\teta 0:01:37\tloss 0.4429 (0.4066)\tacc 87.5000 (87.5000)\tlr 5.182463e-04\n",
            "epoch [36/50][5/18]\ttime 0.174 (0.711)\tdata 0.000 (0.511)\teta 0:03:08\tloss 0.4104 (0.3272)\tacc 90.6250 (90.6250)\tlr 4.641732e-04\n",
            "epoch [36/50][10/18]\ttime 0.122 (0.457)\tdata 0.000 (0.277)\teta 0:01:58\tloss 0.2490 (0.3865)\tacc 96.8750 (90.0000)\tlr 4.641732e-04\n",
            "epoch [36/50][15/18]\ttime 0.121 (0.345)\tdata 0.000 (0.185)\teta 0:01:28\tloss 0.4324 (0.3645)\tacc 90.6250 (90.6250)\tlr 4.641732e-04\n",
            "epoch [37/50][5/18]\ttime 0.188 (0.610)\tdata 0.000 (0.411)\teta 0:02:30\tloss 0.4590 (0.4473)\tacc 84.3750 (87.5000)\tlr 4.122147e-04\n",
            "epoch [37/50][10/18]\ttime 0.174 (0.455)\tdata 0.000 (0.270)\teta 0:01:49\tloss 0.4536 (0.3886)\tacc 84.3750 (89.3750)\tlr 4.122147e-04\n",
            "epoch [37/50][15/18]\ttime 0.120 (0.345)\tdata 0.001 (0.180)\teta 0:01:21\tloss 0.3760 (0.3824)\tacc 93.7500 (90.2083)\tlr 4.122147e-04\n",
            "epoch [38/50][5/18]\ttime 0.152 (0.590)\tdata 0.000 (0.409)\teta 0:02:15\tloss 0.5854 (0.4918)\tacc 84.3750 (87.5000)\tlr 3.625760e-04\n",
            "epoch [38/50][10/18]\ttime 0.173 (0.438)\tdata 0.000 (0.250)\teta 0:01:38\tloss 0.2019 (0.4172)\tacc 93.7500 (89.0625)\tlr 3.625760e-04\n",
            "epoch [38/50][15/18]\ttime 0.125 (0.343)\tdata 0.007 (0.174)\teta 0:01:15\tloss 0.6396 (0.4534)\tacc 87.5000 (88.3333)\tlr 3.625760e-04\n",
            "epoch [39/50][5/18]\ttime 0.157 (0.644)\tdata 0.000 (0.436)\teta 0:02:15\tloss 0.2162 (0.3202)\tacc 93.7500 (92.5000)\tlr 3.154529e-04\n",
            "epoch [39/50][10/18]\ttime 0.127 (0.460)\tdata 0.000 (0.267)\teta 0:01:34\tloss 0.3845 (0.4101)\tacc 90.6250 (89.0625)\tlr 3.154529e-04\n",
            "epoch [39/50][15/18]\ttime 0.120 (0.349)\tdata 0.000 (0.178)\teta 0:01:10\tloss 0.7437 (0.4264)\tacc 81.2500 (88.5417)\tlr 3.154529e-04\n",
            "epoch [40/50][5/18]\ttime 0.196 (0.656)\tdata 0.000 (0.457)\teta 0:02:06\tloss 0.5781 (0.3977)\tacc 78.1250 (86.8750)\tlr 2.710314e-04\n",
            "epoch [40/50][10/18]\ttime 0.136 (0.572)\tdata 0.000 (0.360)\teta 0:01:47\tloss 0.1890 (0.4298)\tacc 93.7500 (88.1250)\tlr 2.710314e-04\n",
            "epoch [40/50][15/18]\ttime 0.121 (0.423)\tdata 0.004 (0.240)\teta 0:01:17\tloss 0.1539 (0.3950)\tacc 100.0000 (89.5833)\tlr 2.710314e-04\n",
            "epoch [41/50][5/18]\ttime 0.288 (0.971)\tdata 0.000 (0.648)\teta 0:02:50\tloss 0.5488 (0.4768)\tacc 81.2500 (88.1250)\tlr 2.294868e-04\n",
            "epoch [41/50][10/18]\ttime 0.229 (0.664)\tdata 0.000 (0.350)\teta 0:01:52\tloss 0.2903 (0.3741)\tacc 90.6250 (90.3125)\tlr 2.294868e-04\n",
            "epoch [41/50][15/18]\ttime 0.147 (0.493)\tdata 0.000 (0.234)\teta 0:01:21\tloss 0.3518 (0.4234)\tacc 90.6250 (88.5417)\tlr 2.294868e-04\n",
            "epoch [42/50][5/18]\ttime 0.215 (0.791)\tdata 0.000 (0.580)\teta 0:02:04\tloss 0.4636 (0.3788)\tacc 81.2500 (88.7500)\tlr 1.909830e-04\n",
            "epoch [42/50][10/18]\ttime 0.127 (0.525)\tdata 0.000 (0.336)\teta 0:01:19\tloss 0.6528 (0.4147)\tacc 81.2500 (88.4375)\tlr 1.909830e-04\n",
            "epoch [42/50][15/18]\ttime 0.117 (0.390)\tdata 0.000 (0.224)\teta 0:00:57\tloss 0.2354 (0.3959)\tacc 93.7500 (89.1667)\tlr 1.909830e-04\n",
            "epoch [43/50][5/18]\ttime 0.159 (0.616)\tdata 0.000 (0.424)\teta 0:01:25\tloss 0.5415 (0.6160)\tacc 90.6250 (86.2500)\tlr 1.556721e-04\n",
            "epoch [43/50][10/18]\ttime 0.685 (0.464)\tdata 0.569 (0.291)\teta 0:01:02\tloss 0.5605 (0.5350)\tacc 78.1250 (85.6250)\tlr 1.556721e-04\n",
            "epoch [43/50][15/18]\ttime 0.117 (0.349)\tdata 0.000 (0.194)\teta 0:00:44\tloss 0.4585 (0.5189)\tacc 84.3750 (85.8333)\tlr 1.556721e-04\n",
            "epoch [44/50][5/18]\ttime 0.190 (0.643)\tdata 0.000 (0.437)\teta 0:01:17\tloss 0.7349 (0.4183)\tacc 78.1250 (87.5000)\tlr 1.236933e-04\n",
            "epoch [44/50][10/18]\ttime 0.162 (0.463)\tdata 0.000 (0.274)\teta 0:00:53\tloss 0.1682 (0.4016)\tacc 96.8750 (88.1250)\tlr 1.236933e-04\n",
            "epoch [44/50][15/18]\ttime 0.125 (0.350)\tdata 0.000 (0.183)\teta 0:00:38\tloss 0.3838 (0.3912)\tacc 87.5000 (88.1250)\tlr 1.236933e-04\n",
            "epoch [45/50][5/18]\ttime 0.170 (0.670)\tdata 0.000 (0.482)\teta 0:01:09\tloss 0.5747 (0.5227)\tacc 81.2500 (87.5000)\tlr 9.517295e-05\n",
            "epoch [45/50][10/18]\ttime 0.123 (0.459)\tdata 0.000 (0.291)\teta 0:00:45\tloss 0.4741 (0.4865)\tacc 78.1250 (86.8750)\tlr 9.517295e-05\n",
            "epoch [45/50][15/18]\ttime 0.118 (0.348)\tdata 0.000 (0.195)\teta 0:00:32\tloss 0.3591 (0.4649)\tacc 93.7500 (88.3333)\tlr 9.517295e-05\n",
            "epoch [46/50][5/18]\ttime 0.158 (0.658)\tdata 0.000 (0.451)\teta 0:00:55\tloss 0.2396 (0.4176)\tacc 96.8750 (90.6250)\tlr 7.022351e-05\n",
            "epoch [46/50][10/18]\ttime 0.398 (0.470)\tdata 0.278 (0.279)\teta 0:00:37\tloss 0.3730 (0.3965)\tacc 87.5000 (90.0000)\tlr 7.022351e-05\n",
            "epoch [46/50][15/18]\ttime 0.118 (0.354)\tdata 0.000 (0.186)\teta 0:00:26\tloss 0.3640 (0.3648)\tacc 87.5000 (90.2083)\tlr 7.022351e-05\n",
            "epoch [47/50][5/18]\ttime 0.137 (0.653)\tdata 0.000 (0.482)\teta 0:00:43\tloss 0.6206 (0.3531)\tacc 84.3750 (90.0000)\tlr 4.894348e-05\n",
            "epoch [47/50][10/18]\ttime 0.236 (0.463)\tdata 0.113 (0.284)\teta 0:00:28\tloss 0.2104 (0.3483)\tacc 93.7500 (90.6250)\tlr 4.894348e-05\n",
            "epoch [47/50][15/18]\ttime 0.119 (0.349)\tdata 0.000 (0.190)\teta 0:00:19\tloss 0.5054 (0.3562)\tacc 87.5000 (90.6250)\tlr 4.894348e-05\n",
            "epoch [48/50][5/18]\ttime 0.309 (1.076)\tdata 0.000 (0.764)\teta 0:00:52\tloss 0.4797 (0.4851)\tacc 87.5000 (85.6250)\tlr 3.141684e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"upl_train.py\", line 226, in <module>\n",
            "    main(args)\n",
            "  File \"upl_train.py\", line 148, in main\n",
            "    trainer.sstrain_with_id(model_id=i)\n",
            "  File \"/content/UPL/trainers/upltrainer.py\", line 739, in sstrain_with_id\n",
            "    self.sstrain(self.start_epoch, self.max_epoch, model_id)\n",
            "  File \"/content/UPL/trainers/upltrainer.py\", line 749, in sstrain\n",
            "    self.run_epoch_with_sstrain()\n",
            "  File \"/content/UPL/trainers/upltrainer.py\", line 763, in run_epoch_with_sstrain\n",
            "    loss_summary = self.forward_backward(batch)\n",
            "  File \"/content/UPL/trainers/upltrainer.py\", line 347, in forward_backward\n",
            "    output, image_features, text_features = self.model(image)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/UPL/trainers/upltrainer.py\", line 256, in forward\n",
            "    prompts = self.prompt_learner()\n",
            "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/UPL/trainers/upltrainer.py\", line 199, in forward\n",
            "    ctx_i_half1 = ctx[i : i + 1, :half_n_ctx, :]\n",
            "KeyboardInterrupt\n",
            "Run this job and save the output to ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed3\n",
            "in jaffe\n",
            "Setting fixed seed: 3\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssoxford_pets.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'middle', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed3\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 3\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSOxfordPets\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpmiddle/seed3\n",
            "RESUME: \n",
            "SEED: 3\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: middle\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSOxfordPets\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSOxfordPets\n",
            "  # classes: 37\n",
            "  # train_x: 2,944\n",
            "  # val: 736\n",
            "  # test: 3,669\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Traceback (most recent call last):\n",
            "  File \"upl_train.py\", line 226, in <module>\n",
            "    main(args)\n",
            "  File \"upl_train.py\", line 138, in main\n",
            "    trainer = build_trainer(cfg)\n",
            "  File \"/content/Dassl.pytorch/dassl/engine/build.py\", line 11, in build_trainer\n",
            "    return TRAINER_REGISTRY.get(cfg.TRAINER.NAME)(cfg)\n",
            "  File \"/content/UPL/trainers/upltrainer.py\", line 292, in __init__\n",
            "    super().__init__(cfg)\n",
            "  File \"/content/Dassl.pytorch/dassl/engine/trainer.py\", line 326, in __init__\n",
            "    self.build_model()\n",
            "  File \"/content/UPL/trainers/upltrainer.py\", line 302, in build_model\n",
            "    clip_model = load_clip_to_cpu(cfg)\n",
            "  File \"/content/UPL/trainers/upltrainer.py\", line 86, in load_clip_to_cpu\n",
            "    model = clip.build_model(state_dict or model.state_dict())\n",
            "  File \"/content/UPL/clip/model.py\", line 423, in build_model\n",
            "    context_length, vocab_size, transformer_width, transformer_heads, transformer_layers\n",
            "  File \"/content/UPL/clip/model.py\", line 293, in __init__\n",
            "    self.initialize_parameters()\n",
            "  File \"/content/UPL/clip/model.py\", line 296, in initialize_parameters\n",
            "    nn.init.normal_(self.token_embedding.weight, std=0.02)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/init.py\", line 141, in normal_\n",
            "    return _no_grad_normal_(tensor, mean, std)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/init.py\", line 19, in _no_grad_normal_\n",
            "    return tensor.normal_(mean, std)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 bash upl_train.sh ssoxford_pets rn50_ep50 middle 16 16 False True multiple_models_random_init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "xvVt5kfQvDmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ed6831-5834-4d34-ab03-d51907059c47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in jaffe\n",
            "Setting fixed seed: 1\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True_CONF_THRESHOLD__RN50_temp/nctx16_cscFalse_ctpend/seed\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 1\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True_CONF_THRESHOLD__RN50_temp/nctx16_cscFalse_ctpend/seed\n",
            "RESUME: \n",
            "SEED: 1\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "SHOTS: 16 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "16  shots ensemble\n",
            "Do evaluation on test set\n",
            "torch.Size([64])\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 29\n",
            "* accuracy: 45.31%\n",
            "* error: 54.69%\n",
            "* macro_f1: 38.87%\n",
            "=> per-class result\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 0\tacc: 0.00%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 9\tacc: 100.00%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 4\tacc: 44.44%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* average: 46.03%\n",
            "ensemble: 45.31\n"
          ]
        }
      ],
      "source": [
        "!bash upl_test_existing_logits.sh ssjaffe rn50_ep50 end 16 16 False True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Faw6ldAarIRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9eecab-1fa1-47fd-b669-36486da39dab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in jaffe\n",
            "Setting fixed seed: 1\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssoxford_pets.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'middle', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True_CONF_THRESHOLD__RN50_temp/nctx16_cscFalse_ctpmiddle/seed\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 1\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSOxfordPets\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssoxford_pets/UPLTrainer/rn50_ep50_16shots_EQULE_True_CONF_THRESHOLD__RN50_temp/nctx16_cscFalse_ctpmiddle/seed\n",
            "RESUME: \n",
            "SEED: 1\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: middle\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSOxfordPets\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Reading split from /content/UPL/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSOxfordPets\n",
            "  # classes: 37\n",
            "  # train_x: 2,944\n",
            "  # val: 736\n",
            "  # test: 3,669\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "SHOTS: 16 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "0  shots ensemble\n",
            "Traceback (most recent call last):\n",
            "  File \"upl_test.py\", line 242, in <module>\n",
            "    main(args)\n",
            "  File \"upl_test.py\", line 158, in main\n",
            "    prob_test = sum(prob_end) / len(prob_end)\n",
            "ZeroDivisionError: division by zero\n"
          ]
        }
      ],
      "source": [
        "!bash upl_test_existing_logits.sh ssoxford_pets rn50_ep50 middle 16 16 False True"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}