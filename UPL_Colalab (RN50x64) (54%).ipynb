{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammad-shahid0749/UPL/blob/main/UPL_Colalab%20(RN50x64)%20(54%25).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bervRVwHp1Ga",
        "outputId": "7d71ab7a-924c-4a02-b7e9-d82e92ddc36e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dassl.pytorch'...\n",
            "remote: Enumerating objects: 2477, done.\u001b[K\n",
            "remote: Counting objects: 100% (993/993), done.\u001b[K\n",
            "remote: Compressing objects: 100% (326/326), done.\u001b[K\n",
            "remote: Total 2477 (delta 769), reused 830 (delta 667), pack-reused 1484\u001b[K\n",
            "Receiving objects: 100% (2477/2477), 435.37 KiB | 1.84 MiB/s, done.\n",
            "Resolving deltas: 100% (1650/1650), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/KaiyangZhou/Dassl.pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOKRMs-vvcqN",
        "outputId": "89f4bb94-ac43-4dc9-b024-b154f45a0403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dassl.pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Dassl.pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0jmafCWxJJ6",
        "outputId": "a750c1ee-41ce-4c2b-e52b-3467183934c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dassl.pytorch\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXnuOnMHvnGb",
        "outputId": "c8d84800-b3fb-45d9-b695-5c8b76b448a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEAD is now at ac6e441 leave 2 spaces for comment\n"
          ]
        }
      ],
      "source": [
        "!git reset --hard ac6e44194b2f90e325f477aadd6d9bc3a92ce255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj8kFZCvqTBD",
        "outputId": "ffdff963-9d88-44e3-9554-c654d440aae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:37\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRpdZNrDqYUH",
        "outputId": "6b984984-b925-4754-dbbf-f57b91fb727a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.14.0\n",
            "  latest version: 22.9.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/dassl\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.7\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2022.9.24  |       ha878542_0         150 KB  conda-forge\n",
            "    ld_impl_linux-64-2.39      |       hc81fddc_0         759 KB  conda-forge\n",
            "    libgcc-ng-12.2.0           |      h65d4601_19         931 KB  conda-forge\n",
            "    libgomp-12.2.0             |      h65d4601_19         455 KB  conda-forge\n",
            "    libsqlite-3.39.4           |       h753d276_0         803 KB  conda-forge\n",
            "    libstdcxx-ng-12.2.0        |      h46fd767_19         4.3 MB  conda-forge\n",
            "    libzlib-1.2.13             |       h166bdaf_4          64 KB  conda-forge\n",
            "    openssl-3.0.7              |       h166bdaf_0         2.8 MB  conda-forge\n",
            "    pip-22.3.1                 |     pyhd8ed1ab_0         1.5 MB  conda-forge\n",
            "    python-3.7.12              |hf930737_100_cpython        57.3 MB  conda-forge\n",
            "    setuptools-65.5.1          |     pyhd8ed1ab_0         731 KB  conda-forge\n",
            "    sqlite-3.39.4              |       h4ff8645_0         789 KB  conda-forge\n",
            "    wheel-0.38.4               |     pyhd8ed1ab_0          32 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        70.5 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge\n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2022.9.24-ha878542_0\n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.39-hc81fddc_0\n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5\n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-12.2.0-h65d4601_19\n",
            "  libgomp            conda-forge/linux-64::libgomp-12.2.0-h65d4601_19\n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.39.4-h753d276_0\n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-12.2.0-h46fd767_19\n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4\n",
            "  ncurses            conda-forge/linux-64::ncurses-6.3-h27087fc_1\n",
            "  openssl            conda-forge/linux-64::openssl-3.0.7-h166bdaf_0\n",
            "  pip                conda-forge/noarch::pip-22.3.1-pyhd8ed1ab_0\n",
            "  python             conda-forge/linux-64::python-3.7.12-hf930737_100_cpython\n",
            "  readline           conda-forge/linux-64::readline-8.1.2-h0f457ee_0\n",
            "  setuptools         conda-forge/noarch::setuptools-65.5.1-pyhd8ed1ab_0\n",
            "  sqlite             conda-forge/linux-64::sqlite-3.39.4-h4ff8645_0\n",
            "  tk                 conda-forge/linux-64::tk-8.6.12-h27826a3_0\n",
            "  wheel              conda-forge/noarch::wheel-0.38.4-pyhd8ed1ab_0\n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "pip-22.3.1           | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.67it/s]\n",
            "libzlib-1.2.13       | 64 KB     | : 100% 1.0/1 [00:00<00:00, 17.17it/s]\n",
            "ld_impl_linux-64-2.3 | 759 KB    | : 100% 1.0/1 [00:00<00:00,  6.61it/s]\n",
            "wheel-0.38.4         | 32 KB     | : 100% 1.0/1 [00:00<00:00, 20.99it/s]\n",
            "libgomp-12.2.0       | 455 KB    | : 100% 1.0/1 [00:00<00:00, 11.88it/s]\n",
            "libstdcxx-ng-12.2.0  | 4.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.55it/s]\n",
            "libgcc-ng-12.2.0     | 931 KB    | : 100% 1.0/1 [00:00<00:00,  6.49it/s]\n",
            "openssl-3.0.7        | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.22it/s]               \n",
            "libsqlite-3.39.4     | 803 KB    | : 100% 1.0/1 [00:00<00:00,  7.14it/s]\n",
            "sqlite-3.39.4        | 789 KB    | : 100% 1.0/1 [00:00<00:00,  7.83it/s]\n",
            "setuptools-65.5.1    | 731 KB    | : 100% 1.0/1 [00:00<00:00,  5.69it/s]\n",
            "ca-certificates-2022 | 150 KB    | : 100% 1.0/1 [00:00<00:00, 20.73it/s]\n",
            "python-3.7.12        | 57.3 MB   | : 100% 1.0/1 [00:06<00:00,  6.17s/it]\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate dassl\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "!conda create -n dassl python=3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxXwdGiItH4H",
        "outputId": "44082137-cf3d-4594-8e79-73beb072e98f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKCEI-Kmp_L0",
        "outputId": "f434e932-4f46-485d-96ed-da9635df53e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda activate dassl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNdjcMlUtxM6",
        "outputId": "32cf621c-5e09-4001-bf7a-9c2c9f1a178f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ WARNING conda.core.solve:_add_specs(649): pinned spec cudatoolkit=11.2 conflicts with explicit specs.  Overriding pinned spec.\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=10.1\n",
            "    - pytorch==1.8.1\n",
            "    - torchvision==0.9.1\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-4.5          |       2_kmp_llvm           6 KB  conda-forge\n",
            "    blas-2.116                 |              mkl          13 KB  conda-forge\n",
            "    blas-devel-3.9.0           |   16_linux64_mkl          12 KB  conda-forge\n",
            "    certifi-2022.9.24          |     pyhd8ed1ab_0         155 KB  conda-forge\n",
            "    conda-22.9.0               |   py37h89c1867_1         960 KB  conda-forge\n",
            "    cudatoolkit-10.1.243       |      h8cb64d8_10       427.6 MB  conda-forge\n",
            "    freetype-2.12.1            |       hca18f0e_0         884 KB  conda-forge\n",
            "    jpeg-9e                    |       h166bdaf_2         269 KB  conda-forge\n",
            "    lcms2-2.12                 |       hddcbb42_0         443 KB  conda-forge\n",
            "    lerc-3.0                   |       h9c3ff4c_0         216 KB  conda-forge\n",
            "    libblas-3.9.0              |   16_linux64_mkl          13 KB  conda-forge\n",
            "    libcblas-3.9.0             |   16_linux64_mkl          12 KB  conda-forge\n",
            "    libdeflate-1.10            |       h7f98852_0          77 KB  conda-forge\n",
            "    libgfortran-ng-12.2.0      |      h69a702a_19          22 KB  conda-forge\n",
            "    libgfortran5-12.2.0        |      h337968e_19         1.8 MB  conda-forge\n",
            "    liblapack-3.9.0            |   16_linux64_mkl          12 KB  conda-forge\n",
            "    liblapacke-3.9.0           |   16_linux64_mkl          12 KB  conda-forge\n",
            "    libpng-1.6.38              |       h753d276_0         371 KB  conda-forge\n",
            "    libtiff-4.3.0              |       h0fcbabc_4         635 KB  conda-forge\n",
            "    libuv-1.44.2               |       h166bdaf_0         1.0 MB  conda-forge\n",
            "    libwebp-base-1.2.4         |       h166bdaf_0         404 KB  conda-forge\n",
            "    llvm-openmp-15.0.4         |       he0ac6c6_0         5.7 MB  conda-forge\n",
            "    mkl-2022.1.0               |     h84fe81f_915       199.6 MB  conda-forge\n",
            "    mkl-devel-2022.1.0         |     ha770c72_916          25 KB  conda-forge\n",
            "    mkl-include-2022.1.0       |     h84fe81f_915         745 KB  conda-forge\n",
            "    ninja-1.11.0               |       h924138e_0         2.8 MB  conda-forge\n",
            "    numpy-1.21.6               |   py37h976b520_0         6.1 MB  conda-forge\n",
            "    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n",
            "    openssl-1.1.1s             |       h166bdaf_0         2.1 MB  conda-forge\n",
            "    pillow-7.2.0               |   py37h718be6c_2         671 KB  conda-forge\n",
            "    pytorch-1.8.1              |py3.7_cuda10.1_cudnn7.6.3_0       649.3 MB  pytorch\n",
            "    pytorch-cpu-1.1.0          |      py3.7_cpu_0        53.6 MB  pytorch\n",
            "    tbb-2021.6.0               |       h924138e_1         2.0 MB  conda-forge\n",
            "    torchvision-0.9.1          |py37h9e046cd_1_cpu         6.6 MB  conda-forge\n",
            "    typing_extensions-4.4.0    |     pyha770c72_0          29 KB  conda-forge\n",
            "    zlib-1.2.13                |       h166bdaf_4          92 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        1.33 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               conda-forge/linux-64::blas-2.116-mkl\n",
            "  blas-devel         conda-forge/linux-64::blas-devel-3.9.0-16_linux64_mkl\n",
            "  cudatoolkit        conda-forge/linux-64::cudatoolkit-10.1.243-h8cb64d8_10\n",
            "  freetype           conda-forge/linux-64::freetype-2.12.1-hca18f0e_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9e-h166bdaf_2\n",
            "  lcms2              conda-forge/linux-64::lcms2-2.12-hddcbb42_0\n",
            "  lerc               conda-forge/linux-64::lerc-3.0-h9c3ff4c_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-16_linux64_mkl\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-16_linux64_mkl\n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.10-h7f98852_0\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-12.2.0-h69a702a_19\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-12.2.0-h337968e_19\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-16_linux64_mkl\n",
            "  liblapacke         conda-forge/linux-64::liblapacke-3.9.0-16_linux64_mkl\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.38-h753d276_0\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.3.0-h0fcbabc_4\n",
            "  libuv              conda-forge/linux-64::libuv-1.44.2-h166bdaf_0\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.2.4-h166bdaf_0\n",
            "  llvm-openmp        conda-forge/linux-64::llvm-openmp-15.0.4-he0ac6c6_0\n",
            "  mkl                conda-forge/linux-64::mkl-2022.1.0-h84fe81f_915\n",
            "  mkl-devel          conda-forge/linux-64::mkl-devel-2022.1.0-ha770c72_916\n",
            "  mkl-include        conda-forge/linux-64::mkl-include-2022.1.0-h84fe81f_915\n",
            "  ninja              conda-forge/linux-64::ninja-1.11.0-h924138e_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.21.6-py37h976b520_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n",
            "  pillow             conda-forge/linux-64::pillow-7.2.0-py37h718be6c_2\n",
            "  pytorch            pytorch/linux-64::pytorch-1.8.1-py3.7_cuda10.1_cudnn7.6.3_0\n",
            "  pytorch-cpu        pytorch/linux-64::pytorch-cpu-1.1.0-py3.7_cpu_0\n",
            "  tbb                conda-forge/linux-64::tbb-2021.6.0-h924138e_1\n",
            "  torchvision        conda-forge/linux-64::torchvision-0.9.1-py37h9e046cd_1_cpu\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.4.0-pyha770c72_0\n",
            "  zlib               conda-forge/linux-64::zlib-1.2.13-h166bdaf_4\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                      2022.6.15-ha878542_0 --> 2022.9.24-ha878542_0\n",
            "  certifi            conda-forge/linux-64::certifi-2022.6.~ --> conda-forge/noarch::certifi-2022.9.24-pyhd8ed1ab_0\n",
            "  conda                               4.14.0-py37h89c1867_0 --> 22.9.0-py37h89c1867_1\n",
            "  libzlib                                 1.2.12-h166bdaf_2 --> 1.2.13-h166bdaf_4\n",
            "  openssl                                 1.1.1q-h166bdaf_0 --> 1.1.1s-h166bdaf_0\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-2_kmp_llvm\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "jpeg-9e              | 269 KB    | : 100% 1.0/1 [00:00<00:00, 10.05it/s]\n",
            "conda-22.9.0         | 960 KB    | : 100% 1.0/1 [00:00<00:00,  4.92it/s]\n",
            "blas-2.116           | 13 KB     | : 100% 1.0/1 [00:00<00:00, 26.81it/s]\n",
            "libblas-3.9.0        | 13 KB     | : 100% 1.0/1 [00:00<00:00, 36.70it/s]\n",
            "cudatoolkit-10.1.243 | 427.6 MB  | : 100% 1.0/1 [00:45<00:00, 45.77s/it]               \n",
            "torchvision-0.9.1    | 6.6 MB    | : 100% 1.0/1 [00:00<00:00,  1.45it/s]\n",
            "openssl-1.1.1s       | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.32it/s]\n",
            "mkl-include-2022.1.0 | 745 KB    | : 100% 1.0/1 [00:00<00:00,  3.03it/s]\n",
            "liblapacke-3.9.0     | 12 KB     | : 100% 1.0/1 [00:00<00:00, 28.03it/s]\n",
            "libuv-1.44.2         | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  6.46it/s]\n",
            "libgfortran5-12.2.0  | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.65it/s]\n",
            "libdeflate-1.10      | 77 KB     | : 100% 1.0/1 [00:00<00:00, 21.34it/s]\n",
            "lerc-3.0             | 216 KB    | : 100% 1.0/1 [00:00<00:00, 13.73it/s]\n",
            "mkl-2022.1.0         | 199.6 MB  | : 100% 1.0/1 [00:30<00:00, 30.64s/it]               \n",
            "certifi-2022.9.24    | 155 KB    | : 100% 1.0/1 [00:00<00:00, 19.39it/s]\n",
            "zlib-1.2.13          | 92 KB     | : 100% 1.0/1 [00:00<00:00, 28.71it/s]\n",
            "mkl-devel-2022.1.0   | 25 KB     | : 100% 1.0/1 [00:00<00:00, 29.49it/s]\n",
            "freetype-2.12.1      | 884 KB    | : 100% 1.0/1 [00:00<00:00,  6.32it/s]\n",
            "pillow-7.2.0         | 671 KB    | : 100% 1.0/1 [00:00<00:00,  2.14it/s]\n",
            "tbb-2021.6.0         | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.63it/s]\n",
            "olefile-0.46         | 32 KB     | : 100% 1.0/1 [00:00<00:00, 34.37it/s]\n",
            "libwebp-base-1.2.4   | 404 KB    | : 100% 1.0/1 [00:00<00:00, 12.13it/s]\n",
            "libpng-1.6.38        | 371 KB    | : 100% 1.0/1 [00:00<00:00, 12.84it/s]\n",
            "libcblas-3.9.0       | 12 KB     | : 100% 1.0/1 [00:00<00:00, 31.41it/s]\n",
            "blas-devel-3.9.0     | 12 KB     | : 100% 1.0/1 [00:00<00:00, 34.29it/s]\n",
            "pytorch-1.8.1        | 649.3 MB  | : 100% 1.0/1 [01:29<00:00, 89.81s/it]               \n",
            "_openmp_mutex-4.5    | 6 KB      | : 100% 1.0/1 [00:00<00:00, 24.79it/s]\n",
            "numpy-1.21.6         | 6.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.04s/it]\n",
            "libtiff-4.3.0        | 635 KB    | : 100% 1.0/1 [00:00<00:00,  8.24it/s]\n",
            "libgfortran-ng-12.2. | 22 KB     | : 100% 1.0/1 [00:00<00:00, 29.43it/s]\n",
            "typing_extensions-4. | 29 KB     | : 100% 1.0/1 [00:00<00:00, 27.09it/s]\n",
            "liblapack-3.9.0      | 12 KB     | : 100% 1.0/1 [00:00<00:00, 36.07it/s]\n",
            "llvm-openmp-15.0.4   | 5.7 MB    | : 100% 1.0/1 [00:00<00:00,  1.37it/s]\n",
            "ninja-1.11.0         | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.63it/s]\n",
            "pytorch-cpu-1.1.0    | 53.6 MB   | : 100% 1.0/1 [00:09<00:00,  9.78s/it]               \n",
            "lcms2-2.12           | 443 KB    | : 100% 1.0/1 [00:00<00:00, 10.40it/s]\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "!conda install pytorch==1.8.1 torchvision==0.9.1 cudatoolkit=10.1 -c pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70-SE7HVrrYV",
        "outputId": "69b3a78c-1563-4fd5-a1bb-b0ae942c4c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dassl.pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Dassl.pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amKERbdMtGRi",
        "outputId": "787387ac-cf84-497a-bd88-3714e3737642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dassl.pytorch\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwRIH_BHt3Hj",
        "outputId": "c5aedbb6-970d-4fb2-e187-1db72b35964b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running develop\n",
            "/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py:147: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "  EasyInstallDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "  setuptools.SetuptoolsDeprecationWarning,\n",
            "running egg_info\n",
            "creating dassl.egg-info\n",
            "writing dassl.egg-info/PKG-INFO\n",
            "writing dependency_links to dassl.egg-info/dependency_links.txt\n",
            "writing requirements to dassl.egg-info/requires.txt\n",
            "writing top-level names to dassl.egg-info/top_level.txt\n",
            "writing manifest file 'dassl.egg-info/SOURCES.txt'\n",
            "reading manifest file 'dassl.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'dassl.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.7/site-packages/dassl.egg-link (link to .)\n",
            "Adding dassl 0.4.3 to easy-install.pth file\n",
            "\n",
            "Installed /content/Dassl.pytorch\n",
            "Processing dependencies for dassl==0.4.3\n",
            "Searching for scikit-learn\n",
            "Reading https://pypi.org/simple/scikit-learn/\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.9 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning:  is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.10 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.11 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.12 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.12.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.13 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.13.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.14 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.14.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.15.0b1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.15.0b2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.15.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.15.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.15.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.16b1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.16.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.16.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.17b1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.17 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.17.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.18rc2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.18 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.18.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.18.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.19b2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.19.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.19.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.19.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20rc1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20.3 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.20.4 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.21rc2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.21.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.21.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.21.3 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.22rc2.post1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.22rc3 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.22 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.22.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.22.2.post1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.23.0rc1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.23.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.23.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.23.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.24.dev0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.24.0rc1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.24.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.24.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-0.24.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.0rc1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.0rc2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.0.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.0.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.1.0rc1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.1.0 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.1.1 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.1.2 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: learn-1.1.3 is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "Downloading https://files.pythonhosted.org/packages/38/bc/319f789ce0988d9bf1379d6e40498dc119b30bec133bf76cd82ca549b69a/scikit-learn-1.1.3.tar.gz#sha256=bef51978a51ec19977700fe7b86aecea49c825884f3811756b74a3b152bb4e35\n",
            "Best match: scikit-learn 1.1.3\n",
            "Processing scikit-learn-1.1.3.tar.gz\n",
            "Writing /tmp/easy_install-y4d3j8fi/scikit-learn-1.1.3/setup.cfg\n",
            "Running scikit-learn-1.1.3/setup.py -q bdist_egg --dist-dir /tmp/easy_install-y4d3j8fi/scikit-learn-1.1.3/egg-dist-tmp-xm_dxvan\n",
            "Partial import of sklearn during the build process.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 156, in save_modules\n",
            "    yield saved\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 198, in setup_context\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 259, in run_setup\n",
            "    _execfile(setup_script, ns)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 46, in _execfile\n",
            "    exec(code, globals, locals)\n",
            "  File \"/tmp/easy_install-y4d3j8fi/scikit-learn-1.1.3/setup.py\", line 330, in <module>\n",
            "  File \"/tmp/easy_install-y4d3j8fi/scikit-learn-1.1.3/setup.py\", line 301, in setup_package\n",
            "RuntimeError: Scikit-learn requires Python 3.8 or later. The current Python version is 3.7.12 installed in /usr/local/bin/python.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"setup.py\", line 46, in <module>\n",
            "    'Semi-Supervised Learning', 'Pytorch'\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
            "    return distutils.core.setup(**attrs)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
            "    return run_commands(dist)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
            "    dist.run_commands()\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 973, in run_commands\n",
            "    self.run_command(cmd)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
            "    super().run_command(command)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 992, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/develop.py\", line 34, in run\n",
            "    self.install_for_development()\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/develop.py\", line 129, in install_for_development\n",
            "    self.process_distribution(None, self.dist, not self.no_deps)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 755, in process_distribution\n",
            "    [requirement], self.local_index, self.easy_install\n",
            "  File \"/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 791, in resolve\n",
            "    replace_conflicting=replace_conflicting\n",
            "  File \"/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 1075, in best_match\n",
            "    return self.obtain(req, installer)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 1087, in obtain\n",
            "    return installer(requirement)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 681, in easy_install\n",
            "    return self.install_item(spec, dist.location, tmpdir, deps)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 707, in install_item\n",
            "    dists = self.install_eggs(spec, download, tmpdir)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 900, in install_eggs\n",
            "    return self.build_and_install(setup_script, setup_base)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 1174, in build_and_install\n",
            "    self.run_setup(setup_script, setup_base, args)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 1158, in run_setup\n",
            "    run_setup(setup_script, args)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 262, in run_setup\n",
            "    raise\n",
            "  File \"/usr/local/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 198, in setup_context\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 169, in save_modules\n",
            "    saved_exc.resume()\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 143, in resume\n",
            "    raise exc.with_traceback(self._tb)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 156, in save_modules\n",
            "    yield saved\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 198, in setup_context\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 259, in run_setup\n",
            "    _execfile(setup_script, ns)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/setuptools/sandbox.py\", line 46, in _execfile\n",
            "    exec(code, globals, locals)\n",
            "  File \"/tmp/easy_install-y4d3j8fi/scikit-learn-1.1.3/setup.py\", line 330, in <module>\n",
            "  File \"/tmp/easy_install-y4d3j8fi/scikit-learn-1.1.3/setup.py\", line 301, in setup_package\n",
            "RuntimeError: Scikit-learn requires Python 3.8 or later. The current Python version is 3.7.12 installed in /usr/local/bin/python.\n"
          ]
        }
      ],
      "source": [
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJIhk7HmzU9r",
        "outputId": "77252cf2-ec76-40e1-fd83-09ac0902c6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duedm9M5zYBU",
        "outputId": "8c014f49-f643-451d-b27d-90e6654e72a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COiXmqyRT7tZ",
        "outputId": "1dc074e9-c3b9-484e-e508-1b6456c9087a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'content'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4I6OP0D8pgFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb87a40d-af83-40c2-d33c-dc3c4066c004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UPL'...\n",
            "remote: Enumerating objects: 45609, done.\u001b[K\n",
            "remote: Counting objects: 100% (9009/9009), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8979/8979), done.\u001b[K\n",
            "remote: Total 45609 (delta 31), reused 9002 (delta 25), pack-reused 36600\u001b[K\n",
            "Receiving objects: 100% (45609/45609), 1.29 GiB | 17.04 MiB/s, done.\n",
            "Resolving deltas: 100% (3749/3749), done.\n",
            "Checking out files: 100% (52711/52711), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/muhammad-shahid0749/UPL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AjygzxZt-zs",
        "outputId": "585eb1b9-d7bd-4ba3-8f09-ff2f95288e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL\n"
          ]
        }
      ],
      "source": [
        "%cd UPL/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XlD9z1iL3icu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9d83e7-1b6d-49da-a2ae-c2f6ea8764c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "dwzZY852uA7l",
        "outputId": "447f960f-06aa-405f-c910-58d92de2d134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex\n",
            "  Downloading regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m757.1/757.1 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (4.64.0)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wcwidth>=0.2.5\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (7.2.0)\n",
            "Collecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.21.6)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->-r requirements.txt (line 4)) (4.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 4)) (1.16.0)\n",
            "Installing collected packages: wcwidth, regex, python-dateutil, pyparsing, kiwisolver, ftfy, fonttools, cycler, packaging, matplotlib\n",
            "Successfully installed cycler-0.11.0 fonttools-4.38.0 ftfy-6.1.1 kiwisolver-1.4.4 matplotlib-3.5.3 packaging-21.3 pyparsing-3.0.9 python-dateutil-2.8.2 regex-2022.10.31 wcwidth-0.2.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "kiwisolver",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU7YLTuTuFFo",
        "outputId": "abe7fed3-db96-4f36-f1bd-715104af3fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSEPoeV7Am0S",
        "outputId": "7eacec0e-cdbf-4f17-921d-5cc170141914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyYAML, yacs\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dassl 0.4.3 requires flake8==3.7.9, which is not installed.\n",
            "dassl 0.4.3 requires future, which is not installed.\n",
            "dassl 0.4.3 requires gdown, which is not installed.\n",
            "dassl 0.4.3 requires isort==4.3.21, which is not installed.\n",
            "dassl 0.4.3 requires scikit-learn, which is not installed.\n",
            "dassl 0.4.3 requires scipy, which is not installed.\n",
            "dassl 0.4.3 requires tb-nightly, which is not installed.\n",
            "dassl 0.4.3 requires yapf==0.29.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0 yacs-0.1.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install yacs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf4L0TugARWU",
        "outputId": "c05a3696-951a-4dc4-f525-c6d726fb78af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDz0DuYvuYcr",
        "outputId": "cc2e9a6b-e717-453c-df66-6832966845c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL/scripts\n"
          ]
        }
      ],
      "source": [
        "%cd /content/UPL/scripts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i2RwHBeJA2rS",
        "outputId": "0bd2945e-fed7-4632-9ac8-c85ac474c58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboard\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/site-packages (from tensorboard) (1.21.6)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<4,>=3.9.2\n",
            "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/site-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard) (65.3.0)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard) (2.28.1)\n",
            "Collecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.50.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=0.4\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.4.0)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.10.0-py3-none-any.whl (6.2 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, zipp, tensorboard-data-server, rsa, pyasn1-modules, protobuf, oauthlib, MarkupSafe, grpcio, cachetools, absl-py, werkzeug, requests-oauthlib, importlib-metadata, google-auth, markdown, google-auth-oauthlib, tensorboard\n",
            "Successfully installed MarkupSafe-2.1.1 absl-py-1.3.0 cachetools-5.2.0 google-auth-2.14.1 google-auth-oauthlib-0.4.6 grpcio-1.50.0 importlib-metadata-5.0.0 markdown-3.4.1 oauthlib-3.2.2 protobuf-3.20.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.2.2 zipp-3.10.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saSnPtg9A6Zz",
        "outputId": "f595c529-0c85-43f4-bf93-9d6305c7614f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.5.3.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/site-packages (from gdown) (2.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from gdown) (1.16.0)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from gdown) (4.64.0)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.5.3-py3-none-any.whl size=14821 sha256=00ae8895107c6e4fb1b98c826444d86b769a36e35e8ef307b97b0efda896195e\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/8d/0b/bdcd83555c3555f91a33f6c2384428d9f163c7d75ab0d272b4\n",
            "Successfully built gdown\n",
            "Installing collected packages: soupsieve, filelock, beautifulsoup4, gdown\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dassl 0.4.3 requires flake8==3.7.9, which is not installed.\n",
            "dassl 0.4.3 requires future, which is not installed.\n",
            "dassl 0.4.3 requires isort==4.3.21, which is not installed.\n",
            "dassl 0.4.3 requires scikit-learn, which is not installed.\n",
            "dassl 0.4.3 requires scipy, which is not installed.\n",
            "dassl 0.4.3 requires tb-nightly, which is not installed.\n",
            "dassl 0.4.3 requires yapf==0.29.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beautifulsoup4-4.11.1 filelock-3.8.0 gdown-4.5.3 soupsieve-2.3.2.post1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htlY-GeoBJ5u",
        "outputId": "db5aa6b5-8b42-4634-bd37-dc685bd8ab7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2936 sha256=33c69f04e264d36ad2a91d206f56f3ecd9e335adfddd3dc7d1da10d93061b52e\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE_Oa_qpBKDh",
        "outputId": "7dba979b-cd18-4bd1-8c18-049d82b9f2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL/scripts\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX5Hds58Biqe",
        "outputId": "40cfc762-fe1b-4775-bee3-056ab09ea5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lANRo5sQBlYp",
        "outputId": "64aa9072-8c01-43c1-9f6b-cea241050555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/UPL\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLyRVwzqCPga",
        "outputId": "70993524-08c9-4b4d-a021-03eb813c9d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=0.11\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting scipy>=1.1.0\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.21.6)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dassl 0.4.3 requires flake8==3.7.9, which is not installed.\n",
            "dassl 0.4.3 requires future, which is not installed.\n",
            "dassl 0.4.3 requires isort==4.3.21, which is not installed.\n",
            "dassl 0.4.3 requires tb-nightly, which is not installed.\n",
            "dassl 0.4.3 requires yapf==0.29.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed joblib-1.2.0 scikit-learn-1.0.2 scipy-1.7.3 threadpoolctl-3.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psX_qMATB1AN",
        "outputId": "be46fd8a-762d-44df-93bc-5c9759f94bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UPL/scripts\n"
          ]
        }
      ],
      "source": [
        "%cd /content/UPL/scripts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpuMOZrMudS5",
        "outputId": "3eb8a7c1-1bc1-4e83-fa49-144f85f5d636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/anay_rn50x64_-1shots_random_init/nctx16_cscFalse_ctpmiddle/seed1\n",
            "in jaffe\n",
            "in jaffe\n",
            "Setting fixed seed: 1\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/anay_rn50x64.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'middle', 'DATASET.NUM_SHOTS', '-1']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/anay_rn50x64_-1shots_random_init/nctx16_cscFalse_ctpmiddle/seed1\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 1\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: -1\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (448, 448)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50x64\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: []\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/anay_rn50x64_-1shots_random_init/nctx16_cscFalse_ctpmiddle/seed1\n",
            "RESUME: \n",
            "SEED: 1\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: middle\n",
            "    CSC: False\n",
            "    CTX_INIT: a photo of a\n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Splitting into 50% train, 20% val, and 30% test\n",
            "Saved split to /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 448x448\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 448x448\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 448x448\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 448x448\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50x64)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.35G/1.35G [00:28<00:00, 48.1MiB/s]\n",
            "tcmalloc: large alloc 1353506816 bytes == 0x562dfd1f0000 @  0x7fb85c79d1e7 0x562df4fe6d19 0x562df50d75c8 0x562df4fea33b 0x562df4fea6e3 0x562df50eb99d 0x562df5006bc0 0x562df50071ad 0x562df50798f1 0x562df4fbdea2 0x562df5004370 0x562df50070d8 0x562df507dcba 0x562df50041d4 0x562df50070d8 0x562df507985b 0x562df50041d4 0x562df50070d8 0x562df50798f1 0x562df4fbdea2 0x562df5004370 0x562df50070d8 0x562df507dcba 0x562df4fbdea2 0x562df4fbf41f 0x562df5039fdc 0x562df500643c 0x562df5007269 0x562df507985b 0x562df50041d4 0x562df50070d8\n",
            "Building custom CLIP\n",
            "Initial context: \"a photo of a\"\n",
            "Number of context words (tokens): 4\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "4it [00:18,  4.56s/it]\n",
            "image_features torch.Size([107, 1024])\n",
            "text_features torch.Size([7, 1024])\n",
            "100% 7/7 [00:00<00:00, 736.17it/s]\n",
            "Acc Rate 0.5421\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 bash get_info.sh ssjaffe anay_rn50x64 middle 16 -1 False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj6QxMrPu5tS",
        "outputId": "cfed4db4-17d4-4592-9fd3-09b21dc70e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed1. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed2. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed3. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed4. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed5. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed6. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed7. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed8. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed9. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed10. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed11. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed12. Skip this job\n",
            "Results are available in ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed13. Skip this job\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed14\n",
            "in jaffe\n",
            "in jaffe\n",
            "Setting fixed seed: 14\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed14\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 14\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50x64']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed14\n",
            "RESUME: \n",
            "SEED: 14\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 18808.54it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 76\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed14/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.994 (1.994)\tdata 0.554 (0.554)\teta 0:03:17\tloss 1.8271 (1.8271)\tacc 40.6250 (40.6250)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.062 (1.028)\tdata 0.000 (0.277)\teta 0:01:40\tloss 1.8662 (1.8467)\tacc 25.0000 (32.8125)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.518 (0.518)\tdata 0.452 (0.452)\teta 0:00:50\tloss 1.8535 (1.8535)\tacc 34.3750 (34.3750)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.064 (0.291)\tdata 0.000 (0.226)\teta 0:00:27\tloss 1.7783 (1.8159)\tacc 21.8750 (28.1250)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.512 (0.512)\tdata 0.448 (0.448)\teta 0:00:48\tloss 1.7812 (1.7812)\tacc 37.5000 (37.5000)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.063 (0.287)\tdata 0.000 (0.224)\teta 0:00:26\tloss 1.7949 (1.7881)\tacc 37.5000 (37.5000)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.500 (0.500)\tdata 0.437 (0.437)\teta 0:00:46\tloss 1.7207 (1.7207)\tacc 43.7500 (43.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.064 (0.282)\tdata 0.000 (0.219)\teta 0:00:25\tloss 1.7598 (1.7402)\tacc 37.5000 (40.6250)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.512 (0.512)\tdata 0.450 (0.450)\teta 0:00:46\tloss 1.6396 (1.6396)\tacc 46.8750 (46.8750)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.064 (0.288)\tdata 0.000 (0.225)\teta 0:00:25\tloss 1.6641 (1.6519)\tacc 31.2500 (39.0625)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.505 (0.505)\tdata 0.443 (0.443)\teta 0:00:44\tloss 1.7559 (1.7559)\tacc 40.6250 (40.6250)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.064 (0.285)\tdata 0.000 (0.222)\teta 0:00:25\tloss 1.3984 (1.5771)\tacc 50.0000 (45.3125)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.518 (0.518)\tdata 0.456 (0.456)\teta 0:00:45\tloss 1.5244 (1.5244)\tacc 46.8750 (46.8750)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.064 (0.291)\tdata 0.000 (0.228)\teta 0:00:25\tloss 1.6543 (1.5894)\tacc 46.8750 (46.8750)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.510 (0.510)\tdata 0.448 (0.448)\teta 0:00:43\tloss 1.3857 (1.3857)\tacc 46.8750 (46.8750)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.064 (0.287)\tdata 0.000 (0.224)\teta 0:00:24\tloss 1.5322 (1.4590)\tacc 34.3750 (40.6250)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.524 (0.524)\tdata 0.452 (0.452)\teta 0:00:43\tloss 1.3262 (1.3262)\tacc 53.1250 (53.1250)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.065 (0.294)\tdata 0.000 (0.226)\teta 0:00:24\tloss 1.4678 (1.3970)\tacc 46.8750 (50.0000)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.505 (0.505)\tdata 0.442 (0.442)\teta 0:00:40\tloss 1.1904 (1.1904)\tacc 62.5000 (62.5000)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.065 (0.285)\tdata 0.000 (0.221)\teta 0:00:22\tloss 1.4043 (1.2974)\tacc 59.3750 (60.9375)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.497 (0.497)\tdata 0.433 (0.433)\teta 0:00:39\tloss 1.9102 (1.9102)\tacc 46.8750 (46.8750)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.065 (0.281)\tdata 0.000 (0.217)\teta 0:00:21\tloss 1.3789 (1.6445)\tacc 59.3750 (53.1250)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.529 (0.529)\tdata 0.465 (0.465)\teta 0:00:40\tloss 1.2744 (1.2744)\tacc 50.0000 (50.0000)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.064 (0.296)\tdata 0.000 (0.232)\teta 0:00:22\tloss 1.2021 (1.2383)\tacc 59.3750 (54.6875)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.499 (0.499)\tdata 0.436 (0.436)\teta 0:00:37\tloss 1.1963 (1.1963)\tacc 56.2500 (56.2500)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.067 (0.283)\tdata 0.000 (0.218)\teta 0:00:20\tloss 1.6562 (1.4263)\tacc 53.1250 (54.6875)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.498 (0.498)\tdata 0.434 (0.434)\teta 0:00:36\tloss 1.3154 (1.3154)\tacc 65.6250 (65.6250)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.064 (0.281)\tdata 0.000 (0.217)\teta 0:00:20\tloss 1.2910 (1.3032)\tacc 53.1250 (59.3750)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.524 (0.524)\tdata 0.462 (0.462)\teta 0:00:37\tloss 1.0156 (1.0156)\tacc 71.8750 (71.8750)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.065 (0.295)\tdata 0.000 (0.231)\teta 0:00:20\tloss 1.3291 (1.1724)\tacc 62.5000 (67.1875)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.502 (0.502)\tdata 0.439 (0.439)\teta 0:00:34\tloss 1.0137 (1.0137)\tacc 71.8750 (71.8750)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.063 (0.282)\tdata 0.000 (0.220)\teta 0:00:19\tloss 1.3945 (1.2041)\tacc 46.8750 (59.3750)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.503 (0.503)\tdata 0.441 (0.441)\teta 0:00:33\tloss 1.1113 (1.1113)\tacc 59.3750 (59.3750)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.065 (0.284)\tdata 0.000 (0.221)\teta 0:00:18\tloss 1.1943 (1.1528)\tacc 59.3750 (59.3750)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.520 (0.520)\tdata 0.453 (0.453)\teta 0:00:33\tloss 1.0732 (1.0732)\tacc 68.7500 (68.7500)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.064 (0.292)\tdata 0.000 (0.227)\teta 0:00:18\tloss 1.0176 (1.0454)\tacc 71.8750 (70.3125)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.539 (0.539)\tdata 0.476 (0.476)\teta 0:00:33\tloss 1.1328 (1.1328)\tacc 65.6250 (65.6250)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.064 (0.301)\tdata 0.000 (0.238)\teta 0:00:18\tloss 1.1328 (1.1328)\tacc 53.1250 (59.3750)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.497 (0.497)\tdata 0.433 (0.433)\teta 0:00:30\tloss 1.6875 (1.6875)\tacc 40.6250 (40.6250)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.064 (0.281)\tdata 0.000 (0.217)\teta 0:00:16\tloss 0.8931 (1.2903)\tacc 71.8750 (56.2500)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.497 (0.497)\tdata 0.433 (0.433)\teta 0:00:29\tloss 0.9141 (0.9141)\tacc 65.6250 (65.6250)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.065 (0.281)\tdata 0.000 (0.216)\teta 0:00:16\tloss 1.1797 (1.0469)\tacc 59.3750 (62.5000)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.500 (0.500)\tdata 0.436 (0.436)\teta 0:00:28\tloss 1.0498 (1.0498)\tacc 62.5000 (62.5000)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.066 (0.283)\tdata 0.000 (0.218)\teta 0:00:15\tloss 1.1611 (1.1055)\tacc 53.1250 (57.8125)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.515 (0.515)\tdata 0.452 (0.452)\teta 0:00:28\tloss 1.1494 (1.1494)\tacc 56.2500 (56.2500)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.064 (0.290)\tdata 0.000 (0.226)\teta 0:00:15\tloss 1.0293 (1.0894)\tacc 65.6250 (60.9375)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.501 (0.501)\tdata 0.437 (0.437)\teta 0:00:26\tloss 1.1992 (1.1992)\tacc 65.6250 (65.6250)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.064 (0.282)\tdata 0.000 (0.218)\teta 0:00:14\tloss 0.8936 (1.0464)\tacc 68.7500 (67.1875)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.502 (0.502)\tdata 0.437 (0.437)\teta 0:00:25\tloss 0.7788 (0.7788)\tacc 68.7500 (68.7500)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.064 (0.283)\tdata 0.000 (0.219)\teta 0:00:14\tloss 1.2764 (1.0276)\tacc 56.2500 (62.5000)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.511 (0.511)\tdata 0.448 (0.448)\teta 0:00:25\tloss 0.7212 (0.7212)\tacc 81.2500 (81.2500)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.064 (0.287)\tdata 0.000 (0.224)\teta 0:00:13\tloss 1.1133 (0.9172)\tacc 75.0000 (78.1250)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.514 (0.514)\tdata 0.451 (0.451)\teta 0:00:24\tloss 1.3340 (1.3340)\tacc 46.8750 (46.8750)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.066 (0.290)\tdata 0.000 (0.226)\teta 0:00:13\tloss 0.7817 (1.0579)\tacc 71.8750 (59.3750)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.510 (0.510)\tdata 0.445 (0.445)\teta 0:00:22\tloss 1.2910 (1.2910)\tacc 53.1250 (53.1250)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.063 (0.287)\tdata 0.000 (0.223)\teta 0:00:12\tloss 0.9810 (1.1360)\tacc 75.0000 (64.0625)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.531 (0.531)\tdata 0.467 (0.467)\teta 0:00:22\tloss 1.1533 (1.1533)\tacc 62.5000 (62.5000)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.064 (0.297)\tdata 0.000 (0.234)\teta 0:00:12\tloss 1.1680 (1.1606)\tacc 65.6250 (64.0625)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.522 (0.522)\tdata 0.459 (0.459)\teta 0:00:21\tloss 0.6157 (0.6157)\tacc 90.6250 (90.6250)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.064 (0.293)\tdata 0.000 (0.230)\teta 0:00:11\tloss 1.1777 (0.8967)\tacc 56.2500 (73.4375)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.501 (0.501)\tdata 0.436 (0.436)\teta 0:00:19\tloss 1.1416 (1.1416)\tacc 56.2500 (56.2500)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.064 (0.283)\tdata 0.000 (0.218)\teta 0:00:10\tloss 0.9668 (1.0542)\tacc 71.8750 (64.0625)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.508 (0.508)\tdata 0.444 (0.444)\teta 0:00:18\tloss 1.0195 (1.0195)\tacc 71.8750 (71.8750)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.064 (0.286)\tdata 0.000 (0.222)\teta 0:00:10\tloss 0.9761 (0.9978)\tacc 75.0000 (73.4375)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.508 (0.508)\tdata 0.445 (0.445)\teta 0:00:17\tloss 1.0205 (1.0205)\tacc 65.6250 (65.6250)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.063 (0.286)\tdata 0.000 (0.223)\teta 0:00:09\tloss 1.1221 (1.0713)\tacc 56.2500 (60.9375)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.555 (0.555)\tdata 0.493 (0.493)\teta 0:00:18\tloss 1.0732 (1.0732)\tacc 62.5000 (62.5000)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.065 (0.310)\tdata 0.000 (0.246)\teta 0:00:09\tloss 1.0391 (1.0562)\tacc 71.8750 (67.1875)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.564 (0.564)\tdata 0.501 (0.501)\teta 0:00:17\tloss 1.0352 (1.0352)\tacc 68.7500 (68.7500)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.065 (0.315)\tdata 0.000 (0.251)\teta 0:00:09\tloss 1.0342 (1.0347)\tacc 65.6250 (67.1875)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.515 (0.515)\tdata 0.451 (0.451)\teta 0:00:14\tloss 1.2695 (1.2695)\tacc 59.3750 (59.3750)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.066 (0.290)\tdata 0.000 (0.225)\teta 0:00:08\tloss 0.7939 (1.0317)\tacc 84.3750 (71.8750)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.513 (0.513)\tdata 0.449 (0.449)\teta 0:00:13\tloss 0.9097 (0.9097)\tacc 71.8750 (71.8750)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.065 (0.289)\tdata 0.000 (0.224)\teta 0:00:07\tloss 1.0156 (0.9626)\tacc 65.6250 (68.7500)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.505 (0.505)\tdata 0.441 (0.441)\teta 0:00:12\tloss 0.7979 (0.7979)\tacc 75.0000 (75.0000)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.065 (0.285)\tdata 0.000 (0.221)\teta 0:00:06\tloss 0.9458 (0.8718)\tacc 71.8750 (73.4375)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.512 (0.512)\tdata 0.449 (0.449)\teta 0:00:11\tloss 0.6016 (0.6016)\tacc 78.1250 (78.1250)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.064 (0.288)\tdata 0.000 (0.224)\teta 0:00:06\tloss 0.9507 (0.7761)\tacc 75.0000 (76.5625)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.515 (0.515)\tdata 0.452 (0.452)\teta 0:00:10\tloss 1.1436 (1.1436)\tacc 62.5000 (62.5000)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.065 (0.290)\tdata 0.000 (0.226)\teta 0:00:05\tloss 0.8389 (0.9912)\tacc 71.8750 (67.1875)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.510 (0.510)\tdata 0.447 (0.447)\teta 0:00:09\tloss 0.7822 (0.7822)\tacc 68.7500 (68.7500)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.064 (0.287)\tdata 0.000 (0.224)\teta 0:00:05\tloss 1.0752 (0.9287)\tacc 59.3750 (64.0625)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.508 (0.508)\tdata 0.445 (0.445)\teta 0:00:08\tloss 0.9590 (0.9590)\tacc 65.6250 (65.6250)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.064 (0.286)\tdata 0.000 (0.222)\teta 0:00:04\tloss 0.9155 (0.9373)\tacc 65.6250 (65.6250)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.520 (0.520)\tdata 0.456 (0.456)\teta 0:00:07\tloss 0.9004 (0.9004)\tacc 71.8750 (71.8750)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.065 (0.292)\tdata 0.000 (0.228)\teta 0:00:04\tloss 1.0127 (0.9565)\tacc 71.8750 (71.8750)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.526 (0.526)\tdata 0.464 (0.464)\teta 0:00:06\tloss 0.8740 (0.8740)\tacc 71.8750 (71.8750)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.064 (0.295)\tdata 0.000 (0.232)\teta 0:00:03\tloss 0.7539 (0.8140)\tacc 78.1250 (75.0000)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.498 (0.498)\tdata 0.434 (0.434)\teta 0:00:05\tloss 0.8784 (0.8784)\tacc 75.0000 (75.0000)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.065 (0.282)\tdata 0.000 (0.217)\teta 0:00:02\tloss 0.8496 (0.8640)\tacc 78.1250 (76.5625)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.515 (0.515)\tdata 0.449 (0.449)\teta 0:00:04\tloss 0.8491 (0.8491)\tacc 75.0000 (75.0000)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.064 (0.290)\tdata 0.001 (0.225)\teta 0:00:02\tloss 0.7607 (0.8049)\tacc 81.2500 (78.1250)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.506 (0.506)\tdata 0.443 (0.443)\teta 0:00:03\tloss 0.8740 (0.8740)\tacc 68.7500 (68.7500)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.066 (0.286)\tdata 0.000 (0.222)\teta 0:00:01\tloss 1.1348 (1.0044)\tacc 65.6250 (67.1875)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.503 (0.503)\tdata 0.438 (0.438)\teta 0:00:02\tloss 0.6079 (0.6079)\tacc 90.6250 (90.6250)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.066 (0.284)\tdata 0.000 (0.219)\teta 0:00:01\tloss 1.0781 (0.8430)\tacc 62.5000 (76.5625)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.497 (0.497)\tdata 0.432 (0.432)\teta 0:00:01\tloss 1.2236 (1.2236)\tacc 59.3750 (59.3750)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.064 (0.281)\tdata 0.000 (0.216)\teta 0:00:00\tloss 0.6167 (0.9202)\tacc 75.0000 (67.1875)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.514 (0.514)\tdata 0.452 (0.452)\teta 0:00:00\tloss 1.1582 (1.1582)\tacc 62.5000 (62.5000)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.064 (0.289)\tdata 0.000 (0.226)\teta 0:00:00\tloss 0.7642 (0.9612)\tacc 78.1250 (70.3125)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed14/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 33\n",
            "* accuracy: 51.56%\n",
            "* error: 48.44%\n",
            "* macro_f1: 49.48%\n",
            "=> per-class result\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 4\tacc: 40.00%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 7\tacc: 77.78%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 5\tacc: 55.56%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 6\tacc: 66.67%\n",
            "* average: 51.75%\n",
            "Elapsed: 0:00:40\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed15\n",
            "in jaffe\n",
            "in jaffe\n",
            "Setting fixed seed: 15\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed15\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 15\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50x64']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed15\n",
            "RESUME: \n",
            "SEED: 15\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 17260.51it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 76\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed15/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.704 (1.704)\tdata 0.498 (0.498)\teta 0:02:48\tloss 2.0020 (2.0020)\tacc 12.5000 (12.5000)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.064 (0.884)\tdata 0.000 (0.249)\teta 0:01:26\tloss 2.0723 (2.0371)\tacc 12.5000 (12.5000)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.519 (0.519)\tdata 0.455 (0.455)\teta 0:00:50\tloss 2.1699 (2.1699)\tacc 3.1250 (3.1250)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.067 (0.293)\tdata 0.000 (0.227)\teta 0:00:28\tloss 1.8682 (2.0190)\tacc 40.6250 (21.8750)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.507 (0.507)\tdata 0.444 (0.444)\teta 0:00:48\tloss 1.8320 (1.8320)\tacc 37.5000 (37.5000)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.065 (0.286)\tdata 0.000 (0.222)\teta 0:00:26\tloss 1.8848 (1.8584)\tacc 21.8750 (29.6875)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.513 (0.513)\tdata 0.450 (0.450)\teta 0:00:47\tloss 1.7725 (1.7725)\tacc 31.2500 (31.2500)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.066 (0.289)\tdata 0.000 (0.225)\teta 0:00:26\tloss 1.8115 (1.7920)\tacc 37.5000 (34.3750)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.512 (0.512)\tdata 0.449 (0.449)\teta 0:00:46\tloss 1.6924 (1.6924)\tacc 31.2500 (31.2500)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.064 (0.288)\tdata 0.000 (0.224)\teta 0:00:25\tloss 1.7168 (1.7046)\tacc 43.7500 (37.5000)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.514 (0.514)\tdata 0.452 (0.452)\teta 0:00:45\tloss 1.6104 (1.6104)\tacc 43.7500 (43.7500)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.066 (0.290)\tdata 0.000 (0.226)\teta 0:00:25\tloss 1.6475 (1.6289)\tacc 40.6250 (42.1875)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.501 (0.501)\tdata 0.436 (0.436)\teta 0:00:43\tloss 1.4609 (1.4609)\tacc 46.8750 (46.8750)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.065 (0.283)\tdata 0.000 (0.218)\teta 0:00:24\tloss 1.5547 (1.5078)\tacc 40.6250 (43.7500)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.516 (0.516)\tdata 0.452 (0.452)\teta 0:00:43\tloss 1.4668 (1.4668)\tacc 56.2500 (56.2500)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.065 (0.291)\tdata 0.000 (0.226)\teta 0:00:24\tloss 1.5723 (1.5195)\tacc 34.3750 (45.3125)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.510 (0.510)\tdata 0.447 (0.447)\teta 0:00:42\tloss 1.1250 (1.1250)\tacc 59.3750 (59.3750)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.065 (0.288)\tdata 0.000 (0.224)\teta 0:00:23\tloss 1.8135 (1.4692)\tacc 31.2500 (45.3125)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.507 (0.507)\tdata 0.444 (0.444)\teta 0:00:41\tloss 1.2432 (1.2432)\tacc 56.2500 (56.2500)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.064 (0.286)\tdata 0.000 (0.222)\teta 0:00:22\tloss 1.1992 (1.2212)\tacc 59.3750 (57.8125)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.506 (0.506)\tdata 0.443 (0.443)\teta 0:00:39\tloss 1.2354 (1.2354)\tacc 56.2500 (56.2500)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.066 (0.286)\tdata 0.000 (0.222)\teta 0:00:22\tloss 1.3184 (1.2769)\tacc 56.2500 (56.2500)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.557 (0.557)\tdata 0.494 (0.494)\teta 0:00:42\tloss 1.3359 (1.3359)\tacc 46.8750 (46.8750)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.065 (0.311)\tdata 0.000 (0.247)\teta 0:00:23\tloss 1.0811 (1.2085)\tacc 68.7500 (57.8125)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.500 (0.500)\tdata 0.437 (0.437)\teta 0:00:37\tloss 1.3721 (1.3721)\tacc 43.7500 (43.7500)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.065 (0.282)\tdata 0.000 (0.219)\teta 0:00:20\tloss 1.0547 (1.2134)\tacc 62.5000 (53.1250)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.506 (0.506)\tdata 0.443 (0.443)\teta 0:00:36\tloss 1.4189 (1.4189)\tacc 50.0000 (50.0000)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.065 (0.286)\tdata 0.000 (0.222)\teta 0:00:20\tloss 1.1943 (1.3066)\tacc 56.2500 (53.1250)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.509 (0.509)\tdata 0.445 (0.445)\teta 0:00:36\tloss 1.2549 (1.2549)\tacc 56.2500 (56.2500)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.065 (0.287)\tdata 0.000 (0.222)\teta 0:00:20\tloss 1.2402 (1.2476)\tacc 59.3750 (57.8125)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.507 (0.507)\tdata 0.442 (0.442)\teta 0:00:34\tloss 1.1836 (1.1836)\tacc 59.3750 (59.3750)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.065 (0.286)\tdata 0.000 (0.221)\teta 0:00:19\tloss 0.9951 (1.0894)\tacc 78.1250 (68.7500)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.511 (0.511)\tdata 0.448 (0.448)\teta 0:00:34\tloss 0.9282 (0.9282)\tacc 78.1250 (78.1250)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.067 (0.289)\tdata 0.000 (0.224)\teta 0:00:19\tloss 1.3271 (1.1277)\tacc 50.0000 (64.0625)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.517 (0.517)\tdata 0.451 (0.451)\teta 0:00:33\tloss 1.4961 (1.4961)\tacc 50.0000 (50.0000)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.068 (0.293)\tdata 0.000 (0.226)\teta 0:00:18\tloss 1.1523 (1.3242)\tacc 59.3750 (54.6875)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.516 (0.516)\tdata 0.452 (0.452)\teta 0:00:32\tloss 1.0566 (1.0566)\tacc 65.6250 (65.6250)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.066 (0.291)\tdata 0.000 (0.226)\teta 0:00:18\tloss 0.9526 (1.0046)\tacc 71.8750 (68.7500)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.511 (0.511)\tdata 0.449 (0.449)\teta 0:00:31\tloss 0.9214 (0.9214)\tacc 71.8750 (71.8750)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.065 (0.288)\tdata 0.000 (0.224)\teta 0:00:17\tloss 0.9771 (0.9492)\tacc 65.6250 (68.7500)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.516 (0.516)\tdata 0.453 (0.453)\teta 0:00:30\tloss 1.0420 (1.0420)\tacc 71.8750 (71.8750)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.066 (0.291)\tdata 0.000 (0.227)\teta 0:00:16\tloss 1.1553 (1.0986)\tacc 53.1250 (62.5000)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.518 (0.518)\tdata 0.454 (0.454)\teta 0:00:29\tloss 1.0977 (1.0977)\tacc 65.6250 (65.6250)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.065 (0.291)\tdata 0.000 (0.227)\teta 0:00:16\tloss 1.0801 (1.0889)\tacc 59.3750 (62.5000)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.509 (0.509)\tdata 0.443 (0.443)\teta 0:00:27\tloss 1.0791 (1.0791)\tacc 62.5000 (62.5000)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.065 (0.287)\tdata 0.000 (0.222)\teta 0:00:15\tloss 0.9619 (1.0205)\tacc 68.7500 (65.6250)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.515 (0.515)\tdata 0.450 (0.450)\teta 0:00:27\tloss 1.0117 (1.0117)\tacc 62.5000 (62.5000)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.066 (0.290)\tdata 0.000 (0.225)\teta 0:00:15\tloss 1.0059 (1.0088)\tacc 78.1250 (70.3125)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.534 (0.534)\tdata 0.471 (0.471)\teta 0:00:27\tloss 0.9146 (0.9146)\tacc 65.6250 (65.6250)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.066 (0.300)\tdata 0.000 (0.236)\teta 0:00:14\tloss 1.2861 (1.1003)\tacc 59.3750 (62.5000)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.527 (0.527)\tdata 0.464 (0.464)\teta 0:00:25\tloss 0.8501 (0.8501)\tacc 71.8750 (71.8750)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.067 (0.297)\tdata 0.000 (0.232)\teta 0:00:14\tloss 1.1348 (0.9924)\tacc 68.7500 (70.3125)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.519 (0.519)\tdata 0.454 (0.454)\teta 0:00:24\tloss 1.2451 (1.2451)\tacc 53.1250 (53.1250)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.068 (0.294)\tdata 0.000 (0.227)\teta 0:00:13\tloss 1.0010 (1.1230)\tacc 65.6250 (59.3750)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.507 (0.507)\tdata 0.442 (0.442)\teta 0:00:22\tloss 1.0576 (1.0576)\tacc 62.5000 (62.5000)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.066 (0.287)\tdata 0.000 (0.221)\teta 0:00:12\tloss 1.0020 (1.0298)\tacc 68.7500 (65.6250)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.527 (0.527)\tdata 0.463 (0.463)\teta 0:00:22\tloss 1.1504 (1.1504)\tacc 65.6250 (65.6250)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.066 (0.296)\tdata 0.000 (0.232)\teta 0:00:12\tloss 0.7935 (0.9719)\tacc 68.7500 (67.1875)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.525 (0.525)\tdata 0.459 (0.459)\teta 0:00:21\tloss 1.0312 (1.0312)\tacc 65.6250 (65.6250)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.067 (0.296)\tdata 0.000 (0.230)\teta 0:00:11\tloss 0.8477 (0.9395)\tacc 78.1250 (71.8750)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.510 (0.510)\tdata 0.445 (0.445)\teta 0:00:19\tloss 0.9980 (0.9980)\tacc 65.6250 (65.6250)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.065 (0.288)\tdata 0.000 (0.223)\teta 0:00:10\tloss 0.9727 (0.9854)\tacc 68.7500 (67.1875)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.545 (0.545)\tdata 0.482 (0.482)\teta 0:00:20\tloss 1.4932 (1.4932)\tacc 46.8750 (46.8750)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.065 (0.305)\tdata 0.000 (0.241)\teta 0:00:10\tloss 0.7588 (1.1260)\tacc 75.0000 (60.9375)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.503 (0.503)\tdata 0.439 (0.439)\teta 0:00:17\tloss 0.9570 (0.9570)\tacc 65.6250 (65.6250)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.066 (0.284)\tdata 0.000 (0.220)\teta 0:00:09\tloss 0.9233 (0.9402)\tacc 71.8750 (68.7500)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.507 (0.507)\tdata 0.444 (0.444)\teta 0:00:16\tloss 0.9443 (0.9443)\tacc 65.6250 (65.6250)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.066 (0.286)\tdata 0.000 (0.222)\teta 0:00:09\tloss 1.0117 (0.9780)\tacc 62.5000 (64.0625)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.510 (0.510)\tdata 0.448 (0.448)\teta 0:00:15\tloss 0.9243 (0.9243)\tacc 62.5000 (62.5000)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.061 (0.285)\tdata 0.000 (0.224)\teta 0:00:08\tloss 0.9473 (0.9358)\tacc 65.6250 (64.0625)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.509 (0.509)\tdata 0.444 (0.444)\teta 0:00:14\tloss 0.8188 (0.8188)\tacc 78.1250 (78.1250)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.066 (0.288)\tdata 0.000 (0.222)\teta 0:00:08\tloss 0.9307 (0.8748)\tacc 62.5000 (70.3125)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.516 (0.516)\tdata 0.453 (0.453)\teta 0:00:13\tloss 1.0293 (1.0293)\tacc 75.0000 (75.0000)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.065 (0.291)\tdata 0.000 (0.227)\teta 0:00:07\tloss 0.7554 (0.8923)\tacc 75.0000 (75.0000)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.507 (0.507)\tdata 0.442 (0.442)\teta 0:00:12\tloss 1.0293 (1.0293)\tacc 62.5000 (62.5000)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.066 (0.286)\tdata 0.000 (0.221)\teta 0:00:06\tloss 0.8862 (0.9578)\tacc 68.7500 (65.6250)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.503 (0.503)\tdata 0.439 (0.439)\teta 0:00:11\tloss 0.8481 (0.8481)\tacc 71.8750 (71.8750)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.065 (0.284)\tdata 0.000 (0.220)\teta 0:00:06\tloss 0.7632 (0.8057)\tacc 78.1250 (75.0000)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.513 (0.513)\tdata 0.448 (0.448)\teta 0:00:10\tloss 0.8887 (0.8887)\tacc 68.7500 (68.7500)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.066 (0.290)\tdata 0.000 (0.224)\teta 0:00:05\tloss 1.1475 (1.0181)\tacc 59.3750 (64.0625)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.509 (0.509)\tdata 0.440 (0.440)\teta 0:00:09\tloss 1.1074 (1.1074)\tacc 56.2500 (56.2500)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.064 (0.287)\tdata 0.000 (0.220)\teta 0:00:05\tloss 0.7891 (0.9482)\tacc 71.8750 (64.0625)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.502 (0.502)\tdata 0.437 (0.437)\teta 0:00:08\tloss 1.1230 (1.1230)\tacc 62.5000 (62.5000)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.066 (0.284)\tdata 0.000 (0.219)\teta 0:00:04\tloss 0.7256 (0.9243)\tacc 75.0000 (68.7500)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.551 (0.551)\tdata 0.485 (0.485)\teta 0:00:08\tloss 1.0010 (1.0010)\tacc 59.3750 (59.3750)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.066 (0.309)\tdata 0.000 (0.243)\teta 0:00:04\tloss 1.0723 (1.0366)\tacc 65.6250 (62.5000)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.515 (0.515)\tdata 0.450 (0.450)\teta 0:00:06\tloss 0.8662 (0.8662)\tacc 75.0000 (75.0000)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.066 (0.290)\tdata 0.000 (0.225)\teta 0:00:03\tloss 0.8384 (0.8523)\tacc 75.0000 (75.0000)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.511 (0.511)\tdata 0.448 (0.448)\teta 0:00:05\tloss 0.8320 (0.8320)\tacc 68.7500 (68.7500)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.069 (0.290)\tdata 0.000 (0.224)\teta 0:00:02\tloss 0.7275 (0.7798)\tacc 65.6250 (67.1875)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.513 (0.513)\tdata 0.450 (0.450)\teta 0:00:04\tloss 0.9097 (0.9097)\tacc 75.0000 (75.0000)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.067 (0.290)\tdata 0.000 (0.225)\teta 0:00:02\tloss 0.8013 (0.8555)\tacc 71.8750 (73.4375)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.518 (0.518)\tdata 0.454 (0.454)\teta 0:00:03\tloss 0.9053 (0.9053)\tacc 75.0000 (75.0000)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.066 (0.292)\tdata 0.000 (0.227)\teta 0:00:01\tloss 0.8071 (0.8562)\tacc 71.8750 (73.4375)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.514 (0.514)\tdata 0.451 (0.451)\teta 0:00:02\tloss 0.9248 (0.9248)\tacc 65.6250 (65.6250)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.066 (0.290)\tdata 0.000 (0.226)\teta 0:00:01\tloss 0.8389 (0.8818)\tacc 78.1250 (71.8750)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.512 (0.512)\tdata 0.441 (0.441)\teta 0:00:01\tloss 0.9658 (0.9658)\tacc 62.5000 (62.5000)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.067 (0.289)\tdata 0.000 (0.220)\teta 0:00:00\tloss 0.9644 (0.9651)\tacc 65.6250 (64.0625)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.505 (0.505)\tdata 0.439 (0.439)\teta 0:00:00\tloss 0.8672 (0.8672)\tacc 68.7500 (68.7500)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.066 (0.286)\tdata 0.000 (0.220)\teta 0:00:00\tloss 0.8120 (0.8396)\tacc 81.2500 (75.0000)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed15/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 37\n",
            "* accuracy: 57.81%\n",
            "* error: 42.19%\n",
            "* macro_f1: 54.22%\n",
            "=> per-class result\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 6\tacc: 60.00%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 4\tacc: 44.44%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 4\tacc: 44.44%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 7\tacc: 77.78%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* average: 57.78%\n",
            "Elapsed: 0:00:40\n",
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed16\n",
            "in jaffe\n",
            "in jaffe\n",
            "Setting fixed seed: 16\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed16\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 16\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50x64']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed16\n",
            "RESUME: \n",
            "SEED: 16\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "100% 7/7 [00:00<00:00, 19547.36it/s]\n",
            "SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "sstrain 76\n",
            "No checkpoint found, train from scratch\n",
            "Initializing summary writer for tensorboard with log_dir=./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed16/tensorboard\n",
            "epoch [1/50][1/2]\ttime 1.728 (1.728)\tdata 0.474 (0.474)\teta 0:02:51\tloss 2.0566 (2.0566)\tacc 3.1250 (3.1250)\tlr 1.000000e-05\n",
            "epoch [1/50][2/2]\ttime 0.066 (0.897)\tdata 0.000 (0.237)\teta 0:01:27\tloss 2.0684 (2.0625)\tacc 3.1250 (3.1250)\tlr 2.000000e-03\n",
            "epoch [2/50][1/2]\ttime 0.538 (0.538)\tdata 0.474 (0.474)\teta 0:00:52\tloss 2.1484 (2.1484)\tacc 6.2500 (6.2500)\tlr 2.000000e-03\n",
            "epoch [2/50][2/2]\ttime 0.067 (0.303)\tdata 0.000 (0.237)\teta 0:00:29\tloss 1.9297 (2.0391)\tacc 12.5000 (9.3750)\tlr 1.998027e-03\n",
            "epoch [3/50][1/2]\ttime 0.507 (0.507)\tdata 0.441 (0.441)\teta 0:00:48\tloss 1.8574 (1.8574)\tacc 9.3750 (9.3750)\tlr 1.998027e-03\n",
            "epoch [3/50][2/2]\ttime 0.067 (0.287)\tdata 0.000 (0.221)\teta 0:00:26\tloss 1.8965 (1.8770)\tacc 28.1250 (18.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][1/2]\ttime 0.518 (0.518)\tdata 0.453 (0.453)\teta 0:00:48\tloss 1.8203 (1.8203)\tacc 43.7500 (43.7500)\tlr 1.992115e-03\n",
            "epoch [4/50][2/2]\ttime 0.067 (0.292)\tdata 0.000 (0.227)\teta 0:00:26\tloss 1.8389 (1.8296)\tacc 34.3750 (39.0625)\tlr 1.982287e-03\n",
            "epoch [5/50][1/2]\ttime 0.509 (0.509)\tdata 0.443 (0.443)\teta 0:00:46\tloss 1.8213 (1.8213)\tacc 34.3750 (34.3750)\tlr 1.982287e-03\n",
            "epoch [5/50][2/2]\ttime 0.067 (0.288)\tdata 0.000 (0.222)\teta 0:00:25\tloss 1.7949 (1.8081)\tacc 31.2500 (32.8125)\tlr 1.968583e-03\n",
            "epoch [6/50][1/2]\ttime 0.508 (0.508)\tdata 0.444 (0.444)\teta 0:00:45\tloss 1.7803 (1.7803)\tacc 37.5000 (37.5000)\tlr 1.968583e-03\n",
            "epoch [6/50][2/2]\ttime 0.068 (0.288)\tdata 0.000 (0.222)\teta 0:00:25\tloss 1.6338 (1.7070)\tacc 40.6250 (39.0625)\tlr 1.951057e-03\n",
            "epoch [7/50][1/2]\ttime 0.508 (0.508)\tdata 0.442 (0.442)\teta 0:00:44\tloss 1.6582 (1.6582)\tacc 40.6250 (40.6250)\tlr 1.951057e-03\n",
            "epoch [7/50][2/2]\ttime 0.067 (0.287)\tdata 0.000 (0.221)\teta 0:00:24\tloss 1.5566 (1.6074)\tacc 40.6250 (40.6250)\tlr 1.929776e-03\n",
            "epoch [8/50][1/2]\ttime 0.531 (0.531)\tdata 0.466 (0.466)\teta 0:00:45\tloss 1.4883 (1.4883)\tacc 59.3750 (59.3750)\tlr 1.929776e-03\n",
            "epoch [8/50][2/2]\ttime 0.066 (0.299)\tdata 0.000 (0.233)\teta 0:00:25\tloss 1.6162 (1.5522)\tacc 50.0000 (54.6875)\tlr 1.904827e-03\n",
            "epoch [9/50][1/2]\ttime 0.543 (0.543)\tdata 0.474 (0.474)\teta 0:00:45\tloss 1.6055 (1.6055)\tacc 40.6250 (40.6250)\tlr 1.904827e-03\n",
            "epoch [9/50][2/2]\ttime 0.067 (0.305)\tdata 0.000 (0.237)\teta 0:00:25\tloss 1.5176 (1.5615)\tacc 43.7500 (42.1875)\tlr 1.876307e-03\n",
            "epoch [10/50][1/2]\ttime 0.544 (0.544)\tdata 0.480 (0.480)\teta 0:00:44\tloss 1.4375 (1.4375)\tacc 50.0000 (50.0000)\tlr 1.876307e-03\n",
            "epoch [10/50][2/2]\ttime 0.068 (0.306)\tdata 0.000 (0.240)\teta 0:00:24\tloss 1.7266 (1.5820)\tacc 50.0000 (50.0000)\tlr 1.844328e-03\n",
            "epoch [11/50][1/2]\ttime 0.518 (0.518)\tdata 0.455 (0.455)\teta 0:00:40\tloss 1.3066 (1.3066)\tacc 59.3750 (59.3750)\tlr 1.844328e-03\n",
            "epoch [11/50][2/2]\ttime 0.066 (0.292)\tdata 0.000 (0.227)\teta 0:00:22\tloss 1.6475 (1.4771)\tacc 46.8750 (53.1250)\tlr 1.809017e-03\n",
            "epoch [12/50][1/2]\ttime 0.527 (0.527)\tdata 0.463 (0.463)\teta 0:00:40\tloss 1.3604 (1.3604)\tacc 50.0000 (50.0000)\tlr 1.809017e-03\n",
            "epoch [12/50][2/2]\ttime 0.068 (0.297)\tdata 0.000 (0.232)\teta 0:00:22\tloss 1.4238 (1.3921)\tacc 46.8750 (48.4375)\tlr 1.770513e-03\n",
            "epoch [13/50][1/2]\ttime 0.545 (0.545)\tdata 0.482 (0.482)\teta 0:00:40\tloss 1.3125 (1.3125)\tacc 50.0000 (50.0000)\tlr 1.770513e-03\n",
            "epoch [13/50][2/2]\ttime 0.067 (0.306)\tdata 0.000 (0.241)\teta 0:00:22\tloss 1.3779 (1.3452)\tacc 53.1250 (51.5625)\tlr 1.728969e-03\n",
            "epoch [14/50][1/2]\ttime 0.522 (0.522)\tdata 0.458 (0.458)\teta 0:00:38\tloss 1.4346 (1.4346)\tacc 43.7500 (43.7500)\tlr 1.728969e-03\n",
            "epoch [14/50][2/2]\ttime 0.067 (0.294)\tdata 0.000 (0.229)\teta 0:00:21\tloss 1.0254 (1.2300)\tacc 71.8750 (57.8125)\tlr 1.684547e-03\n",
            "epoch [15/50][1/2]\ttime 0.535 (0.535)\tdata 0.471 (0.471)\teta 0:00:37\tloss 1.1592 (1.1592)\tacc 71.8750 (71.8750)\tlr 1.684547e-03\n",
            "epoch [15/50][2/2]\ttime 0.068 (0.301)\tdata 0.000 (0.236)\teta 0:00:21\tloss 1.4248 (1.2920)\tacc 43.7500 (57.8125)\tlr 1.637424e-03\n",
            "epoch [16/50][1/2]\ttime 0.548 (0.548)\tdata 0.484 (0.484)\teta 0:00:37\tloss 1.2598 (1.2598)\tacc 56.2500 (56.2500)\tlr 1.637424e-03\n",
            "epoch [16/50][2/2]\ttime 0.068 (0.308)\tdata 0.000 (0.242)\teta 0:00:20\tloss 1.1260 (1.1929)\tacc 65.6250 (60.9375)\tlr 1.587785e-03\n",
            "epoch [17/50][1/2]\ttime 0.530 (0.530)\tdata 0.466 (0.466)\teta 0:00:35\tloss 1.1377 (1.1377)\tacc 68.7500 (68.7500)\tlr 1.587785e-03\n",
            "epoch [17/50][2/2]\ttime 0.067 (0.299)\tdata 0.000 (0.233)\teta 0:00:19\tloss 1.2529 (1.1953)\tacc 56.2500 (62.5000)\tlr 1.535827e-03\n",
            "epoch [18/50][1/2]\ttime 0.511 (0.511)\tdata 0.448 (0.448)\teta 0:00:33\tloss 1.3008 (1.3008)\tacc 53.1250 (53.1250)\tlr 1.535827e-03\n",
            "epoch [18/50][2/2]\ttime 0.067 (0.289)\tdata 0.000 (0.224)\teta 0:00:18\tloss 1.3408 (1.3208)\tacc 62.5000 (57.8125)\tlr 1.481754e-03\n",
            "epoch [19/50][1/2]\ttime 0.500 (0.500)\tdata 0.434 (0.434)\teta 0:00:31\tloss 1.4844 (1.4844)\tacc 40.6250 (40.6250)\tlr 1.481754e-03\n",
            "epoch [19/50][2/2]\ttime 0.066 (0.283)\tdata 0.000 (0.217)\teta 0:00:17\tloss 1.1406 (1.3125)\tacc 62.5000 (51.5625)\tlr 1.425779e-03\n",
            "epoch [20/50][1/2]\ttime 0.519 (0.519)\tdata 0.456 (0.456)\teta 0:00:31\tloss 1.2119 (1.2119)\tacc 56.2500 (56.2500)\tlr 1.425779e-03\n",
            "epoch [20/50][2/2]\ttime 0.068 (0.294)\tdata 0.000 (0.228)\teta 0:00:17\tloss 1.2021 (1.2070)\tacc 71.8750 (64.0625)\tlr 1.368125e-03\n",
            "epoch [21/50][1/2]\ttime 0.518 (0.518)\tdata 0.452 (0.452)\teta 0:00:30\tloss 1.2324 (1.2324)\tacc 65.6250 (65.6250)\tlr 1.368125e-03\n",
            "epoch [21/50][2/2]\ttime 0.068 (0.293)\tdata 0.000 (0.226)\teta 0:00:16\tloss 0.9458 (1.0891)\tacc 68.7500 (67.1875)\tlr 1.309017e-03\n",
            "epoch [22/50][1/2]\ttime 0.506 (0.506)\tdata 0.443 (0.443)\teta 0:00:28\tloss 0.9326 (0.9326)\tacc 65.6250 (65.6250)\tlr 1.309017e-03\n",
            "epoch [22/50][2/2]\ttime 0.067 (0.286)\tdata 0.000 (0.221)\teta 0:00:16\tloss 1.0293 (0.9810)\tacc 68.7500 (67.1875)\tlr 1.248690e-03\n",
            "epoch [23/50][1/2]\ttime 0.493 (0.493)\tdata 0.428 (0.428)\teta 0:00:27\tloss 1.0996 (1.0996)\tacc 62.5000 (62.5000)\tlr 1.248690e-03\n",
            "epoch [23/50][2/2]\ttime 0.067 (0.280)\tdata 0.000 (0.214)\teta 0:00:15\tloss 1.0352 (1.0674)\tacc 71.8750 (67.1875)\tlr 1.187381e-03\n",
            "epoch [24/50][1/2]\ttime 0.522 (0.522)\tdata 0.456 (0.456)\teta 0:00:27\tloss 0.9512 (0.9512)\tacc 65.6250 (65.6250)\tlr 1.187381e-03\n",
            "epoch [24/50][2/2]\ttime 0.067 (0.294)\tdata 0.000 (0.228)\teta 0:00:15\tloss 1.0576 (1.0044)\tacc 65.6250 (65.6250)\tlr 1.125333e-03\n",
            "epoch [25/50][1/2]\ttime 0.516 (0.516)\tdata 0.452 (0.452)\teta 0:00:26\tloss 1.3311 (1.3311)\tacc 59.3750 (59.3750)\tlr 1.125333e-03\n",
            "epoch [25/50][2/2]\ttime 0.067 (0.291)\tdata 0.000 (0.226)\teta 0:00:14\tloss 1.1172 (1.2241)\tacc 46.8750 (53.1250)\tlr 1.062791e-03\n",
            "epoch [26/50][1/2]\ttime 0.509 (0.509)\tdata 0.444 (0.444)\teta 0:00:24\tloss 0.9014 (0.9014)\tacc 62.5000 (62.5000)\tlr 1.062791e-03\n",
            "epoch [26/50][2/2]\ttime 0.067 (0.288)\tdata 0.000 (0.222)\teta 0:00:13\tloss 1.2461 (1.0737)\tacc 65.6250 (64.0625)\tlr 1.000000e-03\n",
            "epoch [27/50][1/2]\ttime 0.520 (0.520)\tdata 0.455 (0.455)\teta 0:00:24\tloss 1.0635 (1.0635)\tacc 68.7500 (68.7500)\tlr 1.000000e-03\n",
            "epoch [27/50][2/2]\ttime 0.066 (0.293)\tdata 0.000 (0.228)\teta 0:00:13\tloss 1.1338 (1.0986)\tacc 65.6250 (67.1875)\tlr 9.372095e-04\n",
            "epoch [28/50][1/2]\ttime 0.525 (0.525)\tdata 0.460 (0.460)\teta 0:00:23\tloss 1.1006 (1.1006)\tacc 59.3750 (59.3750)\tlr 9.372095e-04\n",
            "epoch [28/50][2/2]\ttime 0.067 (0.296)\tdata 0.000 (0.230)\teta 0:00:13\tloss 1.1230 (1.1118)\tacc 62.5000 (60.9375)\tlr 8.746668e-04\n",
            "epoch [29/50][1/2]\ttime 0.514 (0.514)\tdata 0.450 (0.450)\teta 0:00:22\tloss 1.1465 (1.1465)\tacc 56.2500 (56.2500)\tlr 8.746668e-04\n",
            "epoch [29/50][2/2]\ttime 0.068 (0.291)\tdata 0.000 (0.225)\teta 0:00:12\tloss 0.8691 (1.0078)\tacc 78.1250 (67.1875)\tlr 8.126187e-04\n",
            "epoch [30/50][1/2]\ttime 0.508 (0.508)\tdata 0.444 (0.444)\teta 0:00:20\tloss 0.8384 (0.8384)\tacc 78.1250 (78.1250)\tlr 8.126187e-04\n",
            "epoch [30/50][2/2]\ttime 0.068 (0.288)\tdata 0.000 (0.222)\teta 0:00:11\tloss 1.1035 (0.9709)\tacc 65.6250 (71.8750)\tlr 7.513101e-04\n",
            "epoch [31/50][1/2]\ttime 0.540 (0.540)\tdata 0.476 (0.476)\teta 0:00:21\tloss 1.2393 (1.2393)\tacc 53.1250 (53.1250)\tlr 7.513101e-04\n",
            "epoch [31/50][2/2]\ttime 0.067 (0.303)\tdata 0.000 (0.238)\teta 0:00:11\tloss 1.1367 (1.1880)\tacc 68.7500 (60.9375)\tlr 6.909830e-04\n",
            "epoch [32/50][1/2]\ttime 0.512 (0.512)\tdata 0.447 (0.447)\teta 0:00:18\tloss 1.0889 (1.0889)\tacc 65.6250 (65.6250)\tlr 6.909830e-04\n",
            "epoch [32/50][2/2]\ttime 0.068 (0.290)\tdata 0.000 (0.224)\teta 0:00:10\tloss 1.0508 (1.0698)\tacc 65.6250 (65.6250)\tlr 6.318754e-04\n",
            "epoch [33/50][1/2]\ttime 0.524 (0.524)\tdata 0.460 (0.460)\teta 0:00:18\tloss 0.8975 (0.8975)\tacc 75.0000 (75.0000)\tlr 6.318754e-04\n",
            "epoch [33/50][2/2]\ttime 0.069 (0.297)\tdata 0.000 (0.230)\teta 0:00:10\tloss 1.1025 (1.0000)\tacc 65.6250 (70.3125)\tlr 5.742207e-04\n",
            "epoch [34/50][1/2]\ttime 0.500 (0.500)\tdata 0.434 (0.434)\teta 0:00:16\tloss 0.9014 (0.9014)\tacc 75.0000 (75.0000)\tlr 5.742207e-04\n",
            "epoch [34/50][2/2]\ttime 0.067 (0.283)\tdata 0.000 (0.217)\teta 0:00:09\tloss 0.8784 (0.8899)\tacc 71.8750 (73.4375)\tlr 5.182463e-04\n",
            "epoch [35/50][1/2]\ttime 0.516 (0.516)\tdata 0.451 (0.451)\teta 0:00:15\tloss 1.2051 (1.2051)\tacc 62.5000 (62.5000)\tlr 5.182463e-04\n",
            "epoch [35/50][2/2]\ttime 0.067 (0.292)\tdata 0.000 (0.226)\teta 0:00:08\tloss 0.9844 (1.0947)\tacc 59.3750 (60.9375)\tlr 4.641732e-04\n",
            "epoch [36/50][1/2]\ttime 0.523 (0.523)\tdata 0.455 (0.455)\teta 0:00:15\tloss 0.7798 (0.7798)\tacc 75.0000 (75.0000)\tlr 4.641732e-04\n",
            "epoch [36/50][2/2]\ttime 0.067 (0.295)\tdata 0.001 (0.228)\teta 0:00:08\tloss 1.0889 (0.9343)\tacc 59.3750 (67.1875)\tlr 4.122147e-04\n",
            "epoch [37/50][1/2]\ttime 0.516 (0.516)\tdata 0.451 (0.451)\teta 0:00:13\tloss 1.2764 (1.2764)\tacc 56.2500 (56.2500)\tlr 4.122147e-04\n",
            "epoch [37/50][2/2]\ttime 0.068 (0.292)\tdata 0.000 (0.226)\teta 0:00:07\tloss 0.6372 (0.9568)\tacc 81.2500 (68.7500)\tlr 3.625760e-04\n",
            "epoch [38/50][1/2]\ttime 0.512 (0.512)\tdata 0.446 (0.446)\teta 0:00:12\tloss 0.8066 (0.8066)\tacc 78.1250 (78.1250)\tlr 3.625760e-04\n",
            "epoch [38/50][2/2]\ttime 0.068 (0.290)\tdata 0.000 (0.223)\teta 0:00:06\tloss 1.0977 (0.9521)\tacc 62.5000 (70.3125)\tlr 3.154529e-04\n",
            "epoch [39/50][1/2]\ttime 0.512 (0.512)\tdata 0.447 (0.447)\teta 0:00:11\tloss 1.2529 (1.2529)\tacc 59.3750 (59.3750)\tlr 3.154529e-04\n",
            "epoch [39/50][2/2]\ttime 0.067 (0.290)\tdata 0.000 (0.224)\teta 0:00:06\tloss 0.7437 (0.9983)\tacc 81.2500 (70.3125)\tlr 2.710314e-04\n",
            "epoch [40/50][1/2]\ttime 0.511 (0.511)\tdata 0.447 (0.447)\teta 0:00:10\tloss 0.8428 (0.8428)\tacc 71.8750 (71.8750)\tlr 2.710314e-04\n",
            "epoch [40/50][2/2]\ttime 0.067 (0.289)\tdata 0.000 (0.223)\teta 0:00:05\tloss 1.1133 (0.9780)\tacc 53.1250 (62.5000)\tlr 2.294868e-04\n",
            "epoch [41/50][1/2]\ttime 0.511 (0.511)\tdata 0.447 (0.447)\teta 0:00:09\tloss 0.9463 (0.9463)\tacc 65.6250 (65.6250)\tlr 2.294868e-04\n",
            "epoch [41/50][2/2]\ttime 0.067 (0.289)\tdata 0.000 (0.224)\teta 0:00:05\tloss 1.1006 (1.0234)\tacc 53.1250 (59.3750)\tlr 1.909830e-04\n",
            "epoch [42/50][1/2]\ttime 0.507 (0.507)\tdata 0.442 (0.442)\teta 0:00:08\tloss 0.9868 (0.9868)\tacc 65.6250 (65.6250)\tlr 1.909830e-04\n",
            "epoch [42/50][2/2]\ttime 0.069 (0.288)\tdata 0.000 (0.221)\teta 0:00:04\tloss 1.1699 (1.0784)\tacc 59.3750 (62.5000)\tlr 1.556721e-04\n",
            "epoch [43/50][1/2]\ttime 0.522 (0.522)\tdata 0.457 (0.457)\teta 0:00:07\tloss 0.8374 (0.8374)\tacc 75.0000 (75.0000)\tlr 1.556721e-04\n",
            "epoch [43/50][2/2]\ttime 0.069 (0.295)\tdata 0.000 (0.229)\teta 0:00:04\tloss 0.8970 (0.8672)\tacc 71.8750 (73.4375)\tlr 1.236933e-04\n",
            "epoch [44/50][1/2]\ttime 0.516 (0.516)\tdata 0.447 (0.447)\teta 0:00:06\tloss 0.8804 (0.8804)\tacc 68.7500 (68.7500)\tlr 1.236933e-04\n",
            "epoch [44/50][2/2]\ttime 0.068 (0.292)\tdata 0.000 (0.224)\teta 0:00:03\tloss 0.9834 (0.9319)\tacc 68.7500 (68.7500)\tlr 9.517295e-05\n",
            "epoch [45/50][1/2]\ttime 0.535 (0.535)\tdata 0.471 (0.471)\teta 0:00:05\tloss 0.9033 (0.9033)\tacc 68.7500 (68.7500)\tlr 9.517295e-05\n",
            "epoch [45/50][2/2]\ttime 0.068 (0.301)\tdata 0.000 (0.235)\teta 0:00:03\tloss 0.8716 (0.8875)\tacc 65.6250 (67.1875)\tlr 7.022351e-05\n",
            "epoch [46/50][1/2]\ttime 0.520 (0.520)\tdata 0.456 (0.456)\teta 0:00:04\tloss 0.9258 (0.9258)\tacc 71.8750 (71.8750)\tlr 7.022351e-05\n",
            "epoch [46/50][2/2]\ttime 0.068 (0.294)\tdata 0.000 (0.228)\teta 0:00:02\tloss 0.8408 (0.8833)\tacc 75.0000 (73.4375)\tlr 4.894348e-05\n",
            "epoch [47/50][1/2]\ttime 0.515 (0.515)\tdata 0.450 (0.450)\teta 0:00:03\tloss 0.7920 (0.7920)\tacc 78.1250 (78.1250)\tlr 4.894348e-05\n",
            "epoch [47/50][2/2]\ttime 0.069 (0.292)\tdata 0.000 (0.225)\teta 0:00:01\tloss 0.7856 (0.7888)\tacc 78.1250 (78.1250)\tlr 3.141684e-05\n",
            "epoch [48/50][1/2]\ttime 0.518 (0.518)\tdata 0.453 (0.453)\teta 0:00:02\tloss 0.8086 (0.8086)\tacc 75.0000 (75.0000)\tlr 3.141684e-05\n",
            "epoch [48/50][2/2]\ttime 0.068 (0.293)\tdata 0.000 (0.227)\teta 0:00:01\tloss 0.9614 (0.8850)\tacc 71.8750 (73.4375)\tlr 1.771275e-05\n",
            "epoch [49/50][1/2]\ttime 0.514 (0.514)\tdata 0.450 (0.450)\teta 0:00:01\tloss 0.7109 (0.7109)\tacc 78.1250 (78.1250)\tlr 1.771275e-05\n",
            "epoch [49/50][2/2]\ttime 0.067 (0.291)\tdata 0.000 (0.225)\teta 0:00:00\tloss 0.8662 (0.7886)\tacc 71.8750 (75.0000)\tlr 7.885299e-06\n",
            "epoch [50/50][1/2]\ttime 0.518 (0.518)\tdata 0.452 (0.452)\teta 0:00:00\tloss 1.0586 (1.0586)\tacc 59.3750 (59.3750)\tlr 7.885299e-06\n",
            "epoch [50/50][2/2]\ttime 0.068 (0.293)\tdata 0.000 (0.226)\teta 0:00:00\tloss 0.8618 (0.9602)\tacc 71.8750 (65.6250)\tlr 1.973272e-06\n",
            "Checkpoint saved to \"./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True__multiple_models_random_init/nctx16_cscFalse_ctpend/seed16/prompt_learner/model-best-0.pth.tar\"\n",
            "Finished training\n",
            "Do evaluation on test set\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 32\n",
            "* accuracy: 50.00%\n",
            "* error: 50.00%\n",
            "* macro_f1: 47.62%\n",
            "=> per-class result\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 6\tacc: 66.67%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 2\tacc: 22.22%\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 6\tacc: 60.00%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 4\tacc: 44.44%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 6\tacc: 66.67%\n",
            "* average: 49.84%\n",
            "Elapsed: 0:00:41\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 bash upl_train.sh ssjaffe rn50_ep50 end 16 16 False True multiple_models_random_init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SkNMPi4IYlJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ad9d72-14c1-4450-a59e-54a4289fef77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in jaffe\n",
            "in jaffe\n",
            "Setting fixed seed: 1\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/rn50_ep50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.CLASS_EQULE', 'True']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True_CONF_THRESHOLD__RN50_temp/nctx16_cscFalse_ctpend/seed\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 1\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: 16\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: ['RN50x64']\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/rn50_ep50_16shots_EQULE_True_CONF_THRESHOLD__RN50_temp/nctx16_cscFalse_ctpend/seed\n",
            "RESUME: \n",
            "SEED: 1\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: \n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "SHOTS: 16 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "loss\n",
            "3  shots ensemble\n",
            "Do evaluation on test set\n",
            "torch.Size([64])\n",
            "=> result\n",
            "* total: 64\n",
            "* correct: 35\n",
            "* accuracy: 54.69%\n",
            "* error: 45.31%\n",
            "* macro_f1: 52.85%\n",
            "=> per-class result\n",
            "* class: 2 (fear)\ttotal: 10\tcorrect: 6\tacc: 60.00%\n",
            "* class: 4 (neutral)\ttotal: 9\tcorrect: 7\tacc: 77.78%\n",
            "* class: 6 (surprised)\ttotal: 9\tcorrect: 8\tacc: 88.89%\n",
            "* class: 1 (disgusting)\ttotal: 9\tcorrect: 0\tacc: 0.00%\n",
            "* class: 3 (happy)\ttotal: 9\tcorrect: 7\tacc: 77.78%\n",
            "* class: 0 (annoyed)\ttotal: 9\tcorrect: 3\tacc: 33.33%\n",
            "* class: 5 (sad)\ttotal: 9\tcorrect: 4\tacc: 44.44%\n",
            "* average: 54.60%\n",
            "ensemble: 54.69\n"
          ]
        }
      ],
      "source": [
        "!bash upl_test_existing_logits.sh ssjaffe rn50_ep50 end 16 16 False True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4j8pO65YVMG",
        "outputId": "119bc143-9540-46e2-a47b-d175daeba910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run this job and save the output to ./output/ssjaffe/UPLTrainer/anay_rn50_-1shots_random_init/nctx16_cscFalse_ctpend/seed1\n",
            "in jaffe\n",
            "in jaffe\n",
            "Setting fixed seed: 1\n",
            "***************\n",
            "** Arguments **\n",
            "***************\n",
            "backbone: \n",
            "config_file: configs/trainers/UPLTrainer/anay_rn50.yaml\n",
            "dataset_config_file: configs/datasets/ssjaffe.yaml\n",
            "eval_only: False\n",
            "head: \n",
            "hh_config_file: \n",
            "load_epoch: None\n",
            "model_dir: \n",
            "no_train: False\n",
            "opts: ['TRAINER.UPLTrainer.N_CTX', '16', 'TRAINER.UPLTrainer.CSC', 'False', 'TRAINER.UPLTrainer.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '-1']\n",
            "output_dir: ./output/ssjaffe/UPLTrainer/anay_rn50_-1shots_random_init/nctx16_cscFalse_ctpend/seed1\n",
            "resume: \n",
            "root: ./data\n",
            "seed: 1\n",
            "source_domains: None\n",
            "target_domains: None\n",
            "trainer: UPLTrainer\n",
            "transforms: None\n",
            "************\n",
            "** Config **\n",
            "************\n",
            "DATALOADER:\n",
            "  K_TRANSFORMS: 1\n",
            "  NUM_WORKERS: 8\n",
            "  OPEN_SETTING: False\n",
            "  RETURN_IMG0: False\n",
            "  TEST:\n",
            "    BATCH_SIZE: 100\n",
            "    SAMPLER: SequentialSampler\n",
            "  TRAIN_U:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAME_AS_X: True\n",
            "    SAMPLER: RandomSampler\n",
            "  TRAIN_X:\n",
            "    BATCH_SIZE: 32\n",
            "    N_DOMAIN: 0\n",
            "    N_INS: 16\n",
            "    SAMPLER: RandomSampler\n",
            "DATASET:\n",
            "  ALL_AS_UNLABELED: False\n",
            "  CIFAR_C_LEVEL: 1\n",
            "  CIFAR_C_TYPE: \n",
            "  CLASS_EQULE: True\n",
            "  CONF_THRESHOLD: 0.9\n",
            "  IGNORE_FILE: \n",
            "  IGNORE_NUM: 0\n",
            "  NAME: SSJaffe\n",
            "  NUM_LABELED: -1\n",
            "  NUM_SHOTS: -1\n",
            "  ROOT: ./data\n",
            "  SOURCE_DOMAINS: ()\n",
            "  STL10_FOLD: -1\n",
            "  TARGET_DOMAINS: ()\n",
            "  VAL_PERCENT: 0.1\n",
            "INPUT:\n",
            "  COLORJITTER_B: 0.4\n",
            "  COLORJITTER_C: 0.4\n",
            "  COLORJITTER_H: 0.1\n",
            "  COLORJITTER_S: 0.4\n",
            "  CROP_PADDING: 4\n",
            "  CUTOUT_LEN: 16\n",
            "  CUTOUT_N: 1\n",
            "  GB_K: 21\n",
            "  GB_P: 0.5\n",
            "  GN_MEAN: 0.0\n",
            "  GN_STD: 0.15\n",
            "  INTERPOLATION: bicubic\n",
            "  NO_TRANSFORM: False\n",
            "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
            "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
            "  RANDAUGMENT_M: 10\n",
            "  RANDAUGMENT_N: 2\n",
            "  RGS_P: 0.2\n",
            "  SIZE: (224, 224)\n",
            "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    NAME: RN50\n",
            "    PRETRAINED: True\n",
            "  HEAD:\n",
            "    ACTIVATION: relu\n",
            "    BN: True\n",
            "    DROPOUT: 0.0\n",
            "    HIDDEN_LAYERS: ()\n",
            "    NAME: \n",
            "  INIT_WEIGHTS: \n",
            "  PSEUDO_LABEL_MODELS: []\n",
            "OPTIM:\n",
            "  ADAM_BETA1: 0.9\n",
            "  ADAM_BETA2: 0.999\n",
            "  BASE_LR_MULT: 0.1\n",
            "  GAMMA: 0.1\n",
            "  LR: 0.002\n",
            "  LR_SCHEDULER: cosine\n",
            "  MAX_EPOCH: 50\n",
            "  MOMENTUM: 0.9\n",
            "  NAME: sgd\n",
            "  NEW_LAYERS: ()\n",
            "  RMSPROP_ALPHA: 0.99\n",
            "  SGD_DAMPNING: 0\n",
            "  SGD_NESTEROV: False\n",
            "  STAGED_LR: False\n",
            "  STEPSIZE: (-1,)\n",
            "  WARMUP_CONS_LR: 1e-05\n",
            "  WARMUP_EPOCH: 1\n",
            "  WARMUP_MIN_LR: 1e-05\n",
            "  WARMUP_RECOUNT: True\n",
            "  WARMUP_TYPE: constant\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "OUTPUT_DIR: ./output/ssjaffe/UPLTrainer/anay_rn50_-1shots_random_init/nctx16_cscFalse_ctpend/seed1\n",
            "RESUME: \n",
            "SEED: 1\n",
            "TEST:\n",
            "  Analyze_Result_Path: ./analysis_results_test/\n",
            "  COMPUTE_CMAT: False\n",
            "  EVALUATOR: UPLClassification\n",
            "  FINAL_MODEL: last_val\n",
            "  NO_TEST: False\n",
            "  PER_CLASS_RESULT: True\n",
            "  SPLIT: test\n",
            "TRAIN:\n",
            "  CHECKPOINT_FREQ: 0\n",
            "  COUNT_ITER: train_x\n",
            "  PRINT_FREQ: 5\n",
            "TRAINER:\n",
            "  CG:\n",
            "    ALPHA_D: 0.5\n",
            "    ALPHA_F: 0.5\n",
            "    EPS_D: 1.0\n",
            "    EPS_F: 1.0\n",
            "  DAEL:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 0.5\n",
            "  DDAIG:\n",
            "    ALPHA: 0.5\n",
            "    CLAMP: False\n",
            "    CLAMP_MAX: 1.0\n",
            "    CLAMP_MIN: -1.0\n",
            "    G_ARCH: \n",
            "    LMDA: 0.3\n",
            "    WARMUP: 0\n",
            "  ENSEMBLE_NUM: 1\n",
            "  ENTMIN:\n",
            "    LMDA: 0.001\n",
            "  FIXMATCH:\n",
            "    CONF_THRE: 0.95\n",
            "    STRONG_TRANSFORMS: ()\n",
            "    WEIGHT_U: 1.0\n",
            "  M3SDA:\n",
            "    LMDA: 0.5\n",
            "    N_STEP_F: 4\n",
            "  MCD:\n",
            "    N_STEP_F: 4\n",
            "  MEANTEA:\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 5\n",
            "    WEIGHT_U: 1.0\n",
            "  MIXMATCH:\n",
            "    MIXUP_BETA: 0.75\n",
            "    RAMPUP: 20000\n",
            "    TEMP: 2.0\n",
            "    WEIGHT_U: 100.0\n",
            "  MME:\n",
            "    LMDA: 0.1\n",
            "  NAME: UPLTrainer\n",
            "  SE:\n",
            "    CONF_THRE: 0.95\n",
            "    EMA_ALPHA: 0.999\n",
            "    RAMPUP: 300\n",
            "  UPLTrainer:\n",
            "    CLASS_TOKEN_POSITION: end\n",
            "    CSC: False\n",
            "    CTX_INIT: a photo of a\n",
            "    N_CTX: 16\n",
            "    PREC: fp16\n",
            "USE_CUDA: True\n",
            "VERBOSE: True\n",
            "VERSION: 1\n",
            "Collecting env info ...\n",
            "** System info **\n",
            "PyTorch version: 1.8.1\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 10.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.8.1\n",
            "[pip3] torchvision==0.9.0a0\n",
            "[conda] blas                      2.116                       mkl    conda-forge\n",
            "[conda] blas-devel                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] cudatoolkit               10.1.243            h8cb64d8_10    conda-forge\n",
            "[conda] libblas                   3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] libcblas                  3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapack                 3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] liblapacke                3.9.0            16_linux64_mkl    conda-forge\n",
            "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] mkl-devel                 2022.1.0           ha770c72_916    conda-forge\n",
            "[conda] mkl-include               2022.1.0           h84fe81f_915    conda-forge\n",
            "[conda] numpy                     1.21.6           py37h976b520_0    conda-forge\n",
            "[conda] pytorch                   1.8.1           py3.7_cuda10.1_cudnn7.6.3_0    pytorch\n",
            "[conda] pytorch-cpu               1.1.0               py3.7_cpu_0    pytorch\n",
            "[conda] torchvision               0.9.1           py37h9e046cd_1_cpu    conda-forge\n",
            "        Pillow (7.2.0)\n",
            "\n",
            "Loading trainer: UPLTrainer\n",
            "Loading dataset: SSJaffe\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Reading split from /content/UPL/data/jaffe/split_jaffe.json\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "***** Dataset statistics *****\n",
            "  Dataset: SSJaffe\n",
            "  # classes: 7\n",
            "  # train_x: 107\n",
            "  # val: 42\n",
            "  # test: 64\n",
            "Building transform_test\n",
            "+ resize to 224x224\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_train\n",
            "+ resize to 224x224\n",
            "+ random flip\n",
            "+ random resized crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Loading CLIP (backbone: RN50)\n",
            "Building custom CLIP\n",
            "Initial context: \"a photo of a\"\n",
            "Number of context words (tokens): 4\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: UPLClassification\n",
            "4it [00:02,  1.67it/s]\n",
            "image_features torch.Size([107, 1024])\n",
            "text_features torch.Size([7, 1024])\n",
            "100% 7/7 [00:00<00:00, 8032.87it/s]\n",
            "Acc Rate 0.4766\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 bash get_info.sh ssjaffe anay_rn50 end 16 -1 False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzxa0Oa6YaxX"
      },
      "outputs": [],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 bash upl_train.sh ssjafee rn50_ep50 end 16 16 False True multiple_models_random_init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvVt5kfQvDmi"
      },
      "outputs": [],
      "source": [
        "!bash upl_test_existing_logits.sh ssjaffe rn50_ep50 end 16 16 False True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pdxim1fYhIX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}